{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\JOELA\\python_projects\\ff_data_science\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# data\n",
    "import nfl_data_py as nfl\n",
    "\n",
    "# data loading and plotting\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# models\n",
    "import xgboost as xgb\n",
    "from xgboost import XGBRegressor, XGBClassifier, plot_importance\n",
    "\n",
    "# interpretation\n",
    "import shap\n",
    "from interpret import show\n",
    "\n",
    "# pipeline\n",
    "from sklearn.model_selection import train_test_split, TimeSeriesSplit, GridSearchCV\n",
    "from sklearn.feature_selection import RFECV, RFE\n",
    "from sklearn.impute import SimpleImputer, KNNImputer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler, LabelEncoder, OrdinalEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, root_mean_squared_error, r2_score, confusion_matrix, accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, nan_euclidean_distances\n",
    "\n",
    "pd.set_option('display.max_columns', None)  # None zeigt alle Spalten\n",
    "pd.set_option('display.max_rows', None)  # Alle Zeilen anzeigen, vorsichtig bei gro√üen DataFrames\n",
    "pd.set_option('display.width', 1000)  # Breite anpassen\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downcasting floats.\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 35195 entries, 0 to 35194\n",
      "Data columns (total 47 columns):\n",
      " #   Column                     Non-Null Count  Dtype  \n",
      "---  ------                     --------------  -----  \n",
      " 0   player_id                  35195 non-null  object \n",
      " 1   position                   35195 non-null  object \n",
      " 2   season                     35195 non-null  int32  \n",
      " 3   week                       35195 non-null  int32  \n",
      " 4   recent_team                35195 non-null  object \n",
      " 5   opponent_team              35195 non-null  object \n",
      " 6   completions                35195 non-null  int32  \n",
      " 7   attempts                   35195 non-null  int32  \n",
      " 8   passing_yards              35195 non-null  float32\n",
      " 9   passing_tds                35195 non-null  int32  \n",
      " 10  passing_2pt_conversions    35195 non-null  int32  \n",
      " 11  interceptions              35195 non-null  float32\n",
      " 12  sack_fumbles_lost          35195 non-null  int32  \n",
      " 13  sacks                      35195 non-null  float32\n",
      " 14  sack_yards                 35195 non-null  float32\n",
      " 15  passing_air_yards          35195 non-null  float32\n",
      " 16  passing_epa                4446 non-null   float32\n",
      " 17  pacr                       4383 non-null   float32\n",
      " 18  carries                    35195 non-null  int32  \n",
      " 19  rushing_yards              35195 non-null  float32\n",
      " 20  rushing_tds                35195 non-null  int32  \n",
      " 21  rushing_2pt_conversions    35195 non-null  int32  \n",
      " 22  rushing_fumbles_lost       35195 non-null  float32\n",
      " 23  rushing_epa                14761 non-null  float32\n",
      " 24  receptions                 35195 non-null  int32  \n",
      " 25  targets                    35195 non-null  int32  \n",
      " 26  receiving_yards            35195 non-null  float32\n",
      " 27  receiving_tds              35195 non-null  int32  \n",
      " 28  receiving_2pt_conversions  35195 non-null  int32  \n",
      " 29  receiving_fumbles_lost     35195 non-null  float32\n",
      " 30  racr                       28455 non-null  float32\n",
      " 31  wopr                       28633 non-null  float32\n",
      " 32  receiving_epa              28633 non-null  float32\n",
      " 33  fantasy_points             35195 non-null  float32\n",
      " 34  draft_pick                 28189 non-null  float64\n",
      " 35  draft_year                 35195 non-null  float64\n",
      " 36  dom                        28148 non-null  float64\n",
      " 37  home_team                  35195 non-null  object \n",
      " 38  passing_bad_throws         4287 non-null   float64\n",
      " 39  times_pressured            4287 non-null   float64\n",
      " 40  receiving_rat              27769 non-null  float64\n",
      " 41  rushing_broken_tackles     14413 non-null  float64\n",
      " 42  passer_rating              3660 non-null   float64\n",
      " 43  aggressiveness             3660 non-null   float64\n",
      " 44  catch_percentage           8853 non-null   float64\n",
      " 45  efficiency                 3653 non-null   float64\n",
      " 46  offense_snaps              34096 non-null  float64\n",
      "dtypes: float32(16), float64(12), int32(14), object(5)\n",
      "memory usage: 8.6+ MB\n"
     ]
    }
   ],
   "source": [
    "df_ids = nfl.import_ids()\n",
    "df_weekly = nfl.import_weekly_data(list(range(2018, 2025)))\n",
    "df_seasonal = nfl.import_seasonal_data(list(range(2017,2024)))\n",
    "df_schedule = nfl.import_schedules(list(range(2018, 2025)))\n",
    "df_pass_pfr = nfl.import_weekly_pfr('pass', list(range(2018, 2025)))\n",
    "df_rush_pfr = nfl.import_weekly_pfr('rush', list(range(2018, 2025)))\n",
    "df_rec_pfr = nfl.import_weekly_pfr('rec', list(range(2018, 2025)))\n",
    "df_pass_ngs = nfl.import_ngs_data('passing',list(range(2018, 2025)))\n",
    "df_rush_ngs = nfl.import_ngs_data('rushing',list(range(2018, 2025)))\n",
    "df_rec_ngs = nfl.import_ngs_data('receiving',list(range(2018, 2025)))\n",
    "df_snap_counts = nfl.import_snap_counts(list(range(2018, 2025)))\n",
    "\n",
    "df_weekly = df_weekly[(df_weekly['season_type'] == 'REG') & (df_weekly['position'].isin(['QB', 'WR', 'RB', 'TE']))]\n",
    "\n",
    "df_weekly['game_id_home_away'] = df_weekly['season'].astype(str) + '_' + df_weekly['week'].apply(lambda x: f\"{x:02d}\")+'_'+df_weekly['recent_team']+'_'+df_weekly['opponent_team']\n",
    "df_weekly['game_id_away_home'] = df_weekly['season'].astype(str) + '_' + df_weekly['week'].apply(lambda x: f\"{x:02d}\")+'_'+df_weekly['opponent_team']+'_'+df_weekly['recent_team']\n",
    "\n",
    "df_ids = df_ids.rename(columns={'gsis_id': 'player_id', 'pfr_id': 'pfr_player_id'})\n",
    "df_pass_ngs = df_pass_ngs.rename(columns={'player_gsis_id': 'player_id'})\n",
    "df_rush_ngs = df_rush_ngs.rename(columns={'player_gsis_id': 'player_id'})\n",
    "df_rec_ngs = df_rec_ngs.rename(columns={'player_gsis_id': 'player_id'})\n",
    "\n",
    "df_seasonal['season'] = df_seasonal['season'] + 1\n",
    "\n",
    "df_merged = pd.melt(\n",
    "    df_weekly,\n",
    "    id_vars=['player_id', 'position', 'season', 'week', 'recent_team', 'opponent_team', 'completions', 'attempts', 'passing_yards', 'passing_tds', 'passing_2pt_conversions', 'interceptions', 'sack_fumbles_lost', 'sacks', 'sack_yards', 'passing_air_yards', 'passing_epa', 'pacr', 'carries', 'rushing_yards', 'rushing_tds', 'rushing_2pt_conversions', 'rushing_fumbles_lost', 'rushing_epa', 'receptions', 'targets', 'receiving_yards', 'receiving_tds', 'receiving_2pt_conversions', 'receiving_fumbles_lost', 'racr', 'wopr', 'receiving_epa', 'fantasy_points'],\n",
    "    value_vars=['game_id_home_away', 'game_id_away_home'],\n",
    "    var_name='game_id_type',\n",
    "    value_name='game_id'\n",
    ")\n",
    "\n",
    "df_merged = pd.merge(df_merged, df_ids[['player_id', 'pfr_player_id', 'draft_pick', 'draft_year']], on = 'player_id', how = 'inner')\n",
    "df_merged = pd.merge(df_merged, df_seasonal[['player_id', 'season', 'dom']], on = ['player_id', 'season'], how = 'left')\n",
    "df_merged = pd.merge(df_merged, df_schedule[['game_id', 'home_team']], on='game_id', how='inner')\n",
    "df_merged = pd.merge(df_merged, df_pass_pfr[['pfr_player_id', 'season', 'week', 'passing_bad_throws', 'times_pressured']], on = ['pfr_player_id', 'season', 'week'], how = 'left')\n",
    "df_merged = pd.merge(df_merged, df_rec_pfr[['pfr_player_id', 'season', 'week', 'receiving_rat']], on = ['pfr_player_id', 'season', 'week'], how = 'left')\n",
    "df_merged = pd.merge(df_merged, df_rush_pfr[['pfr_player_id', 'season', 'week', 'rushing_broken_tackles']], on = ['pfr_player_id', 'season', 'week'], how = 'left')\n",
    "df_merged = pd.merge(df_merged, df_pass_ngs[['player_id', 'season', 'week', 'passer_rating', 'aggressiveness']], on = ['player_id', 'season', 'week'], how = 'left')\n",
    "df_merged = pd.merge(df_merged, df_rec_ngs[['player_id', 'season', 'week', 'catch_percentage']], on = ['player_id', 'season', 'week'], how = 'left')\n",
    "df_merged = pd.merge(df_merged, df_rush_ngs[['player_id', 'season', 'week', 'efficiency']], on = ['player_id', 'season', 'week'], how = 'left')\n",
    "df_merged = pd.merge(df_merged, df_snap_counts[['pfr_player_id', 'season', 'week', 'offense_snaps']], on = ['pfr_player_id', 'season', 'week'], how = 'left')\n",
    "\n",
    "df_merged = df_merged.drop(columns=['game_id', 'game_id_type', 'pfr_player_id'])\n",
    "\n",
    "df_merged.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged = df_merged.fillna(0)\n",
    "\n",
    "df_merged['rookie_flag'] = (df_merged['season'] == df_merged['draft_year']).astype(int)\n",
    "df_merged['last_season_data_flag'] = (df_merged['week'] < 6).astype(int)\n",
    "\n",
    "recent_team_means = df_merged.groupby(['recent_team', 'season', 'week'])['fantasy_points'].mean().reset_index()\n",
    "opponent_team_means = df_merged.groupby(['opponent_team', 'season', 'week'])['fantasy_points'].mean().reset_index()\n",
    "position_means = df_merged.groupby(['position', 'season', 'week'])['fantasy_points'].mean().reset_index()\n",
    "\n",
    "recent_team_means.rename(columns={'fantasy_points': 'recent_team_encoded'}, inplace=True)\n",
    "opponent_team_means.rename(columns={'fantasy_points': 'opponent_team_encoded'}, inplace=True)\n",
    "position_means.rename(columns={'fantasy_points': 'position_encoded'}, inplace=True)\n",
    "\n",
    "df_merged = pd.merge(df_merged, recent_team_means, on=['recent_team', 'season', 'week'], how='left')\n",
    "df_merged = pd.merge(df_merged, opponent_team_means, on=['opponent_team', 'season', 'week'], how='left')\n",
    "df_merged = pd.merge(df_merged, position_means, on=['position', 'season', 'week'], how='left')\n",
    "\n",
    "df_merged['turnover'] = (\n",
    "    df_merged['interceptions'] +\n",
    "    df_merged['sack_fumbles_lost'] +\n",
    "    df_merged['rushing_fumbles_lost'] +\n",
    "    df_merged['receiving_fumbles_lost']\n",
    ")\n",
    "\n",
    "df_merged['rushing_pts'] = (df_merged['rushing_tds'] * 6) + (df_merged['rushing_2pt_conversions'] * 2)\n",
    "df_merged['receiving_pts'] = (df_merged['receiving_tds'] * 6) + (df_merged['receiving_2pt_conversions'] * 2)\n",
    "df_merged['passing_pts'] = (df_merged['passing_tds'] * 6) + (df_merged['passing_2pt_conversions'] * 2)\n",
    "\n",
    "df_merged['epa_total'] = df_merged['passing_epa'] + df_merged['rushing_epa'] + df_merged['receiving_epa']\n",
    "\n",
    "df_merged = df_merged.drop(columns=['draft_year', 'interceptions', 'sack_fumbles_lost', 'rushing_fumbles_lost', 'receiving_fumbles_lost', \n",
    "                                    'rushing_tds', 'rushing_2pt_conversions', 'receiving_tds', 'receiving_2pt_conversions', 'passing_tds', \n",
    "                                    'passing_2pt_conversions', 'passing_epa', 'rushing_epa', 'receiving_epa'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\JOELA\\AppData\\Local\\Temp\\ipykernel_24140\\1093346278.py:49: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[feature_name_3] = rolling_result_3w\n",
      "C:\\Users\\JOELA\\AppData\\Local\\Temp\\ipykernel_24140\\1093346278.py:24: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[feature_name_1] = (\n",
      "C:\\Users\\JOELA\\AppData\\Local\\Temp\\ipykernel_24140\\1093346278.py:38: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[feature_name_2] = rolling_result_5w\n",
      "C:\\Users\\JOELA\\AppData\\Local\\Temp\\ipykernel_24140\\1093346278.py:38: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[feature_name_2] = rolling_result_5w\n",
      "C:\\Users\\JOELA\\AppData\\Local\\Temp\\ipykernel_24140\\1093346278.py:38: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[feature_name_2] = rolling_result_5w\n",
      "C:\\Users\\JOELA\\AppData\\Local\\Temp\\ipykernel_24140\\1093346278.py:49: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[feature_name_3] = rolling_result_3w\n",
      "C:\\Users\\JOELA\\AppData\\Local\\Temp\\ipykernel_24140\\1093346278.py:49: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[feature_name_3] = rolling_result_3w\n",
      "C:\\Users\\JOELA\\AppData\\Local\\Temp\\ipykernel_24140\\1093346278.py:24: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[feature_name_1] = (\n",
      "C:\\Users\\JOELA\\AppData\\Local\\Temp\\ipykernel_24140\\1093346278.py:38: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[feature_name_2] = rolling_result_5w\n",
      "C:\\Users\\JOELA\\AppData\\Local\\Temp\\ipykernel_24140\\1093346278.py:38: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[feature_name_2] = rolling_result_5w\n",
      "C:\\Users\\JOELA\\AppData\\Local\\Temp\\ipykernel_24140\\1093346278.py:38: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[feature_name_2] = rolling_result_5w\n",
      "C:\\Users\\JOELA\\AppData\\Local\\Temp\\ipykernel_24140\\1093346278.py:49: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[feature_name_3] = rolling_result_3w\n",
      "C:\\Users\\JOELA\\AppData\\Local\\Temp\\ipykernel_24140\\1093346278.py:49: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[feature_name_3] = rolling_result_3w\n",
      "C:\\Users\\JOELA\\AppData\\Local\\Temp\\ipykernel_24140\\1093346278.py:24: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[feature_name_1] = (\n",
      "C:\\Users\\JOELA\\AppData\\Local\\Temp\\ipykernel_24140\\1093346278.py:38: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[feature_name_2] = rolling_result_5w\n",
      "C:\\Users\\JOELA\\AppData\\Local\\Temp\\ipykernel_24140\\1093346278.py:38: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[feature_name_2] = rolling_result_5w\n",
      "C:\\Users\\JOELA\\AppData\\Local\\Temp\\ipykernel_24140\\1093346278.py:38: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[feature_name_2] = rolling_result_5w\n",
      "C:\\Users\\JOELA\\AppData\\Local\\Temp\\ipykernel_24140\\1093346278.py:49: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[feature_name_3] = rolling_result_3w\n",
      "C:\\Users\\JOELA\\AppData\\Local\\Temp\\ipykernel_24140\\1093346278.py:49: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[feature_name_3] = rolling_result_3w\n",
      "C:\\Users\\JOELA\\AppData\\Local\\Temp\\ipykernel_24140\\1093346278.py:24: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[feature_name_1] = (\n",
      "C:\\Users\\JOELA\\AppData\\Local\\Temp\\ipykernel_24140\\1093346278.py:38: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[feature_name_2] = rolling_result_5w\n",
      "C:\\Users\\JOELA\\AppData\\Local\\Temp\\ipykernel_24140\\1093346278.py:38: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[feature_name_2] = rolling_result_5w\n",
      "C:\\Users\\JOELA\\AppData\\Local\\Temp\\ipykernel_24140\\1093346278.py:38: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[feature_name_2] = rolling_result_5w\n",
      "C:\\Users\\JOELA\\AppData\\Local\\Temp\\ipykernel_24140\\1093346278.py:49: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[feature_name_3] = rolling_result_3w\n",
      "C:\\Users\\JOELA\\AppData\\Local\\Temp\\ipykernel_24140\\1093346278.py:49: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[feature_name_3] = rolling_result_3w\n",
      "C:\\Users\\JOELA\\AppData\\Local\\Temp\\ipykernel_24140\\1093346278.py:24: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[feature_name_1] = (\n",
      "C:\\Users\\JOELA\\AppData\\Local\\Temp\\ipykernel_24140\\1093346278.py:38: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[feature_name_2] = rolling_result_5w\n",
      "C:\\Users\\JOELA\\AppData\\Local\\Temp\\ipykernel_24140\\1093346278.py:38: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[feature_name_2] = rolling_result_5w\n",
      "C:\\Users\\JOELA\\AppData\\Local\\Temp\\ipykernel_24140\\1093346278.py:38: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[feature_name_2] = rolling_result_5w\n",
      "C:\\Users\\JOELA\\AppData\\Local\\Temp\\ipykernel_24140\\1093346278.py:49: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[feature_name_3] = rolling_result_3w\n",
      "C:\\Users\\JOELA\\AppData\\Local\\Temp\\ipykernel_24140\\1093346278.py:49: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[feature_name_3] = rolling_result_3w\n",
      "C:\\Users\\JOELA\\AppData\\Local\\Temp\\ipykernel_24140\\1093346278.py:24: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[feature_name_1] = (\n",
      "C:\\Users\\JOELA\\AppData\\Local\\Temp\\ipykernel_24140\\1093346278.py:38: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[feature_name_2] = rolling_result_5w\n",
      "C:\\Users\\JOELA\\AppData\\Local\\Temp\\ipykernel_24140\\1093346278.py:38: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[feature_name_2] = rolling_result_5w\n",
      "C:\\Users\\JOELA\\AppData\\Local\\Temp\\ipykernel_24140\\1093346278.py:38: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[feature_name_2] = rolling_result_5w\n",
      "C:\\Users\\JOELA\\AppData\\Local\\Temp\\ipykernel_24140\\1093346278.py:49: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[feature_name_3] = rolling_result_3w\n",
      "C:\\Users\\JOELA\\AppData\\Local\\Temp\\ipykernel_24140\\1093346278.py:49: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[feature_name_3] = rolling_result_3w\n",
      "C:\\Users\\JOELA\\AppData\\Local\\Temp\\ipykernel_24140\\1093346278.py:24: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[feature_name_1] = (\n",
      "C:\\Users\\JOELA\\AppData\\Local\\Temp\\ipykernel_24140\\1093346278.py:38: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[feature_name_2] = rolling_result_5w\n",
      "C:\\Users\\JOELA\\AppData\\Local\\Temp\\ipykernel_24140\\1093346278.py:38: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[feature_name_2] = rolling_result_5w\n",
      "C:\\Users\\JOELA\\AppData\\Local\\Temp\\ipykernel_24140\\1093346278.py:38: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[feature_name_2] = rolling_result_5w\n",
      "C:\\Users\\JOELA\\AppData\\Local\\Temp\\ipykernel_24140\\1093346278.py:49: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[feature_name_3] = rolling_result_3w\n",
      "C:\\Users\\JOELA\\AppData\\Local\\Temp\\ipykernel_24140\\1093346278.py:49: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[feature_name_3] = rolling_result_3w\n",
      "C:\\Users\\JOELA\\AppData\\Local\\Temp\\ipykernel_24140\\1093346278.py:24: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[feature_name_1] = (\n",
      "C:\\Users\\JOELA\\AppData\\Local\\Temp\\ipykernel_24140\\1093346278.py:38: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[feature_name_2] = rolling_result_5w\n",
      "C:\\Users\\JOELA\\AppData\\Local\\Temp\\ipykernel_24140\\1093346278.py:38: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[feature_name_2] = rolling_result_5w\n",
      "C:\\Users\\JOELA\\AppData\\Local\\Temp\\ipykernel_24140\\1093346278.py:38: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[feature_name_2] = rolling_result_5w\n",
      "C:\\Users\\JOELA\\AppData\\Local\\Temp\\ipykernel_24140\\1093346278.py:49: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[feature_name_3] = rolling_result_3w\n",
      "C:\\Users\\JOELA\\AppData\\Local\\Temp\\ipykernel_24140\\1093346278.py:49: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[feature_name_3] = rolling_result_3w\n",
      "C:\\Users\\JOELA\\AppData\\Local\\Temp\\ipykernel_24140\\1093346278.py:24: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[feature_name_1] = (\n",
      "C:\\Users\\JOELA\\AppData\\Local\\Temp\\ipykernel_24140\\1093346278.py:38: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[feature_name_2] = rolling_result_5w\n",
      "C:\\Users\\JOELA\\AppData\\Local\\Temp\\ipykernel_24140\\1093346278.py:38: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[feature_name_2] = rolling_result_5w\n",
      "C:\\Users\\JOELA\\AppData\\Local\\Temp\\ipykernel_24140\\1093346278.py:38: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[feature_name_2] = rolling_result_5w\n",
      "C:\\Users\\JOELA\\AppData\\Local\\Temp\\ipykernel_24140\\1093346278.py:49: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[feature_name_3] = rolling_result_3w\n",
      "C:\\Users\\JOELA\\AppData\\Local\\Temp\\ipykernel_24140\\1093346278.py:49: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[feature_name_3] = rolling_result_3w\n",
      "C:\\Users\\JOELA\\AppData\\Local\\Temp\\ipykernel_24140\\1093346278.py:24: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[feature_name_1] = (\n",
      "C:\\Users\\JOELA\\AppData\\Local\\Temp\\ipykernel_24140\\1093346278.py:38: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[feature_name_2] = rolling_result_5w\n",
      "C:\\Users\\JOELA\\AppData\\Local\\Temp\\ipykernel_24140\\1093346278.py:38: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[feature_name_2] = rolling_result_5w\n",
      "C:\\Users\\JOELA\\AppData\\Local\\Temp\\ipykernel_24140\\1093346278.py:38: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[feature_name_2] = rolling_result_5w\n",
      "C:\\Users\\JOELA\\AppData\\Local\\Temp\\ipykernel_24140\\1093346278.py:49: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[feature_name_3] = rolling_result_3w\n",
      "C:\\Users\\JOELA\\AppData\\Local\\Temp\\ipykernel_24140\\1093346278.py:49: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[feature_name_3] = rolling_result_3w\n",
      "C:\\Users\\JOELA\\AppData\\Local\\Temp\\ipykernel_24140\\1093346278.py:24: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[feature_name_1] = (\n",
      "C:\\Users\\JOELA\\AppData\\Local\\Temp\\ipykernel_24140\\1093346278.py:38: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[feature_name_2] = rolling_result_5w\n",
      "C:\\Users\\JOELA\\AppData\\Local\\Temp\\ipykernel_24140\\1093346278.py:38: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[feature_name_2] = rolling_result_5w\n",
      "C:\\Users\\JOELA\\AppData\\Local\\Temp\\ipykernel_24140\\1093346278.py:38: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[feature_name_2] = rolling_result_5w\n",
      "C:\\Users\\JOELA\\AppData\\Local\\Temp\\ipykernel_24140\\1093346278.py:49: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[feature_name_3] = rolling_result_3w\n",
      "C:\\Users\\JOELA\\AppData\\Local\\Temp\\ipykernel_24140\\1093346278.py:49: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[feature_name_3] = rolling_result_3w\n",
      "C:\\Users\\JOELA\\AppData\\Local\\Temp\\ipykernel_24140\\1093346278.py:24: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[feature_name_1] = (\n",
      "C:\\Users\\JOELA\\AppData\\Local\\Temp\\ipykernel_24140\\1093346278.py:38: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[feature_name_2] = rolling_result_5w\n",
      "C:\\Users\\JOELA\\AppData\\Local\\Temp\\ipykernel_24140\\1093346278.py:38: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[feature_name_2] = rolling_result_5w\n",
      "C:\\Users\\JOELA\\AppData\\Local\\Temp\\ipykernel_24140\\1093346278.py:38: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[feature_name_2] = rolling_result_5w\n",
      "C:\\Users\\JOELA\\AppData\\Local\\Temp\\ipykernel_24140\\1093346278.py:49: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[feature_name_3] = rolling_result_3w\n",
      "C:\\Users\\JOELA\\AppData\\Local\\Temp\\ipykernel_24140\\1093346278.py:49: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[feature_name_3] = rolling_result_3w\n",
      "C:\\Users\\JOELA\\AppData\\Local\\Temp\\ipykernel_24140\\1093346278.py:24: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[feature_name_1] = (\n",
      "C:\\Users\\JOELA\\AppData\\Local\\Temp\\ipykernel_24140\\1093346278.py:38: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[feature_name_2] = rolling_result_5w\n",
      "C:\\Users\\JOELA\\AppData\\Local\\Temp\\ipykernel_24140\\1093346278.py:38: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[feature_name_2] = rolling_result_5w\n",
      "C:\\Users\\JOELA\\AppData\\Local\\Temp\\ipykernel_24140\\1093346278.py:38: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[feature_name_2] = rolling_result_5w\n",
      "C:\\Users\\JOELA\\AppData\\Local\\Temp\\ipykernel_24140\\1093346278.py:49: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[feature_name_3] = rolling_result_3w\n",
      "C:\\Users\\JOELA\\AppData\\Local\\Temp\\ipykernel_24140\\1093346278.py:49: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[feature_name_3] = rolling_result_3w\n",
      "C:\\Users\\JOELA\\AppData\\Local\\Temp\\ipykernel_24140\\1093346278.py:24: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[feature_name_1] = (\n",
      "C:\\Users\\JOELA\\AppData\\Local\\Temp\\ipykernel_24140\\1093346278.py:38: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[feature_name_2] = rolling_result_5w\n",
      "C:\\Users\\JOELA\\AppData\\Local\\Temp\\ipykernel_24140\\1093346278.py:38: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[feature_name_2] = rolling_result_5w\n",
      "C:\\Users\\JOELA\\AppData\\Local\\Temp\\ipykernel_24140\\1093346278.py:38: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[feature_name_2] = rolling_result_5w\n",
      "C:\\Users\\JOELA\\AppData\\Local\\Temp\\ipykernel_24140\\1093346278.py:49: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[feature_name_3] = rolling_result_3w\n",
      "C:\\Users\\JOELA\\AppData\\Local\\Temp\\ipykernel_24140\\1093346278.py:49: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[feature_name_3] = rolling_result_3w\n",
      "C:\\Users\\JOELA\\AppData\\Local\\Temp\\ipykernel_24140\\1093346278.py:24: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[feature_name_1] = (\n",
      "C:\\Users\\JOELA\\AppData\\Local\\Temp\\ipykernel_24140\\1093346278.py:38: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[feature_name_2] = rolling_result_5w\n",
      "C:\\Users\\JOELA\\AppData\\Local\\Temp\\ipykernel_24140\\1093346278.py:38: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[feature_name_2] = rolling_result_5w\n",
      "C:\\Users\\JOELA\\AppData\\Local\\Temp\\ipykernel_24140\\1093346278.py:38: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[feature_name_2] = rolling_result_5w\n",
      "C:\\Users\\JOELA\\AppData\\Local\\Temp\\ipykernel_24140\\1093346278.py:49: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[feature_name_3] = rolling_result_3w\n",
      "C:\\Users\\JOELA\\AppData\\Local\\Temp\\ipykernel_24140\\1093346278.py:49: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[feature_name_3] = rolling_result_3w\n",
      "C:\\Users\\JOELA\\AppData\\Local\\Temp\\ipykernel_24140\\1093346278.py:24: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[feature_name_1] = (\n",
      "C:\\Users\\JOELA\\AppData\\Local\\Temp\\ipykernel_24140\\1093346278.py:38: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[feature_name_2] = rolling_result_5w\n",
      "C:\\Users\\JOELA\\AppData\\Local\\Temp\\ipykernel_24140\\1093346278.py:38: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[feature_name_2] = rolling_result_5w\n",
      "C:\\Users\\JOELA\\AppData\\Local\\Temp\\ipykernel_24140\\1093346278.py:38: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[feature_name_2] = rolling_result_5w\n",
      "C:\\Users\\JOELA\\AppData\\Local\\Temp\\ipykernel_24140\\1093346278.py:49: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[feature_name_3] = rolling_result_3w\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 35195 entries, 0 to 35194\n",
      "Columns: 236 entries, player_id to min_passing_pts_l3w\n",
      "dtypes: float32(14), float64(205), int32(12), object(5)\n",
      "memory usage: 59.9+ MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\JOELA\\AppData\\Local\\Temp\\ipykernel_24140\\1093346278.py:49: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[feature_name_3] = rolling_result_3w\n"
     ]
    }
   ],
   "source": [
    "# Liste der Spalten, f√ºr die Rolling-Features erstellt werden sollen\n",
    "columns_to_roll = ['completions', 'attempts', 'passing_yards', 'sacks', 'passer_rating', 'aggressiveness', 'catch_percentage', 'efficiency',\n",
    "                   'sack_yards', 'passing_air_yards', 'pacr', 'carries', 'offense_snaps', 'recent_team_encoded', 'opponent_team_encoded', \n",
    "                   'rushing_yards', 'receptions', 'targets', 'receiving_yards', 'racr', 'wopr', 'fantasy_points', 'passing_bad_throws', \n",
    "                   'times_pressured', 'position_encoded', 'epa_total', 'receiving_rat', 'rushing_broken_tackles', 'turnover', 'rushing_pts', \n",
    "                   'receiving_pts', 'passing_pts']\n",
    "\n",
    "# Funktion zum Erstellen von Rolling-Features\n",
    "def create_rolling_features(df):\n",
    "\n",
    "    # Sortiere nach player_id, season und week\n",
    "    df = df.sort_values(by=['player_id', 'season', 'week']).reset_index(drop=True)\n",
    "\n",
    "    df['cnt_games_over_20ffpts_l5w'] = (\n",
    "        df.groupby('player_id')['fantasy_points']\n",
    "        .apply(lambda x: x.shift(1).rolling(window=5, min_periods=5).apply(lambda y: (y > 20).sum()))\n",
    "        .reset_index(level=0, drop=True)\n",
    "    )\n",
    "\n",
    "    # Rolling-Features erstellen\n",
    "    for col in columns_to_roll:\n",
    "\n",
    "        feature_name_1 = f\"ewm_{col}_l5w\"\n",
    "        df[feature_name_1] = (\n",
    "            df.groupby('player_id')[col]\n",
    "            .apply(lambda x: x.shift(1).ewm(span=5, min_periods=5).mean())\n",
    "            .reset_index(level=0, drop=True)\n",
    "        )\n",
    "\n",
    "        for metric in ['mean', 'median', 'std']:\n",
    "            feature_name_2 = f\"{metric}_{col}_l5w\"\n",
    "            rolling_result_5w = (\n",
    "                df.groupby('player_id')[col]\n",
    "                  .apply(lambda x: x.shift(1).rolling(window=5, min_periods=5).agg(metric))  # shift(1) schlie√üt aktuelle Woche aus\n",
    "                  .reset_index(level=0, drop=True)  # Index zur√ºcksetzen\n",
    "            )\n",
    "            # Einf√ºgen der Rolling-Metrik\n",
    "            df[feature_name_2] = rolling_result_5w\n",
    "\n",
    "        for metric in ['max', 'min']:\n",
    "            feature_name_3 = f\"{metric}_{col}_l3w\"\n",
    "            # Berechnung der Rolling-Metrik (ohne aktuelle Woche)\n",
    "            rolling_result_3w = (\n",
    "                df.groupby('player_id')[col]\n",
    "                  .apply(lambda x: x.shift(1).rolling(window=3, min_periods=3).agg(metric))  # shift(1) schlie√üt aktuelle Woche aus\n",
    "                  .reset_index(level=0, drop=True)  # Index zur√ºcksetzen\n",
    "            )\n",
    "            # Einf√ºgen der Rolling-Metrik\n",
    "            df[feature_name_3] = rolling_result_3w\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "# Anwendung auf df_merged\n",
    "df_merged = create_rolling_features(df_merged)\n",
    "\n",
    "df_merged.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 29633 entries, 5 to 35194\n",
      "Columns: 201 entries, player_id to min_passing_pts_l3w\n",
      "dtypes: float32(1), float64(195), int32(4), object(1)\n",
      "memory usage: 45.1+ MB\n"
     ]
    }
   ],
   "source": [
    "df_merged = df_merged.dropna()\n",
    "\n",
    "df_merged = df_merged.drop(columns=['completions', 'attempts', 'passing_yards', 'sacks', 'sack_yards', 'passing_air_yards',  \n",
    "                                    'pacr', 'carries', 'rushing_yards', 'receptions', 'targets', 'receiving_yards', 'racr', \n",
    "                                    'wopr', 'passing_bad_throws', 'times_pressured', 'receiving_rat', 'rushing_broken_tackles', 'turnover', \n",
    "                                    'rushing_pts', 'receiving_pts', 'passing_pts', 'home_team', 'passer_rating', 'aggressiveness',\n",
    "                                    'catch_percentage', 'efficiency', 'offense_snaps', 'recent_team_encoded', 'opponent_team_encoded', \n",
    "                                    'position_encoded', 'recent_team', 'opponent_team', 'position', 'epa_total'])\n",
    "\n",
    "df_merged.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged = df_merged.sort_values(['player_id', 'season', 'week'])\n",
    "df_merged['did_play'] = 1\n",
    "\n",
    "player_seasons = df_merged[['player_id', 'season']].drop_duplicates()\n",
    "\n",
    "all_weeks = []\n",
    "\n",
    "for _, row in player_seasons.iterrows():\n",
    "    # Assuming weeks go from 1 to 18 for NFL season\n",
    "    weeks = pd.DataFrame({\n",
    "        'player_id': row['player_id'],\n",
    "        'season': row['season'],\n",
    "        'week': range(1, 19),\n",
    "    })\n",
    "    all_weeks.append(weeks)\n",
    "    \n",
    "complete_weeks = pd.concat(all_weeks, ignore_index=True)\n",
    "\n",
    "df_merged = pd.merge(\n",
    "    complete_weeks,\n",
    "    df_merged,\n",
    "    on=['player_id', 'season', 'week'],\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "df_merged = df_merged.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_seq = df_merged.copy()\n",
    "\n",
    "df_seq['time_index'] = df_seq['season'] * 100 + df_seq['week']\n",
    "\n",
    "df_seq = df_seq.sort_values(['player_id', 'time_index'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "import tensorflow as tf\n",
    "\n",
    "def create_sequences(df, sequence_length, feature_columns, target_column='fantasy_points'):\n",
    "    \"\"\"\n",
    "    Create sequences for LSTM model from scaled data.\n",
    "    \"\"\"\n",
    "    sequences = []\n",
    "    targets = []\n",
    "\n",
    "    # Sort the data by 'player_id' and a time column (optional for predictability)\n",
    "    df = df.sort_values(by=['player_id', 'time_index'])\n",
    "    \n",
    "    # Group by player_id\n",
    "    for player_id, player_data in df.groupby('player_id'):\n",
    "        # Extract feature and target arrays\n",
    "        player_features = player_data[feature_columns].values\n",
    "        player_targets = player_data[target_column].values\n",
    "\n",
    "        # Create sequences for this player\n",
    "        for i in range(len(player_features) - sequence_length):\n",
    "            sequences.append(player_features[i:i + sequence_length])\n",
    "            targets.append(player_targets[i + sequence_length])\n",
    "\n",
    "    return np.array(sequences), np.array(targets)\n",
    "\n",
    "\n",
    "def prepare_data(df, feature_columns, target_column, sequence_length, train_cutoff):\n",
    "    \"\"\"\n",
    "    Prepare data for LSTM model including scaling and sequence creation.\n",
    "    \"\"\"\n",
    "    # Split into train and test\n",
    "    train_df = df[df['time_index'] <= train_cutoff]\n",
    "    test_df = df[df['time_index'] > train_cutoff]\n",
    "    \n",
    "    # Scale features\n",
    "    scaler = StandardScaler()\n",
    "    scaler.fit(train_df[feature_columns])\n",
    "    \n",
    "    train_scaled = pd.DataFrame(scaler.transform(train_df[feature_columns]), \n",
    "                                columns=feature_columns)\n",
    "    test_scaled = pd.DataFrame(scaler.transform(test_df[feature_columns]), \n",
    "                               columns=feature_columns)\n",
    "    \n",
    "    # Add back non-feature columns (e.g., 'player_id' and 'time_index')\n",
    "    train_scaled['player_id'] = train_df['player_id'].values\n",
    "    train_scaled['time_index'] = train_df['time_index'].values\n",
    "    train_scaled[target_column] = train_df[target_column].values\n",
    "\n",
    "    test_scaled['player_id'] = test_df['player_id'].values\n",
    "    test_scaled['time_index'] = test_df['time_index'].values\n",
    "    test_scaled[target_column] = test_df[target_column].values\n",
    "\n",
    "    # Create sequences using scaled data\n",
    "    X_train, y_train = create_sequences(\n",
    "        train_scaled,\n",
    "        sequence_length=sequence_length,\n",
    "        feature_columns=feature_columns,\n",
    "        target_column=target_column\n",
    "    )\n",
    "    \n",
    "    X_test, y_test = create_sequences(\n",
    "        test_scaled,\n",
    "        sequence_length=sequence_length,\n",
    "        feature_columns=feature_columns,\n",
    "        target_column=target_column\n",
    "    )\n",
    "    \n",
    "    return X_train, X_test, y_train, y_test, scaler\n",
    "\n",
    "\n",
    "def create_model(sequence_length, n_features):\n",
    "    \"\"\"\n",
    "    Create LSTM model architecture.\n",
    "    \"\"\"\n",
    "    model = Sequential([\n",
    "        LSTM(256, input_shape=(sequence_length, n_features), return_sequences=True),\n",
    "        Dropout(0.4),\n",
    "        LSTM(128),\n",
    "        Dropout(0.4),\n",
    "        Dense(64, activation='relu'),\n",
    "        Dropout(0.3),\n",
    "        Dense(32, activation='relu'),\n",
    "        Dropout(0.2),\n",
    "        Dense(1)\n",
    "    ])\n",
    "    \n",
    "    model.compile(\n",
    "        optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
    "        loss='mse',\n",
    "        metrics=['mae']\n",
    "    )\n",
    "    \n",
    "    return model\n",
    "\n",
    "# Get feature columns\n",
    "def get_feature_columns(df):\n",
    "    \"\"\"\n",
    "    Get list of feature columns excluding non-feature columns.\n",
    "    \"\"\"\n",
    "    # TODO should 'time_index' or other time indicators be a feature or not?\n",
    "    exclude_columns = [\n",
    "        'player_id', \n",
    "        'season', \n",
    "        'week', \n",
    "        'fantasy_points'\n",
    "    ]\n",
    "    \n",
    "    return [col for col in df.columns if col not in exclude_columns]\n",
    "\n",
    "# Main execution\n",
    "def train_lstm_model(df, target_column='fantasy_points'):\n",
    "    \"\"\"\n",
    "    Main function to train LSTM model with optimized parameters.\n",
    "    \"\"\"\n",
    "    # Set parameters\n",
    "    sequence_length = 6\n",
    "    train_cutoff = 202318\n",
    "    epochs = 100\n",
    "    batch_size = 64\n",
    "    validation_split = 0.15\n",
    "    \n",
    "    # Get feature columns\n",
    "    feature_columns = get_feature_columns(df)\n",
    "    print(f\"Number of features: {len(feature_columns)}\")\n",
    "    \n",
    "    # Prepare data\n",
    "    X_train, X_test, y_train, y_test, scaler = prepare_data(\n",
    "        df, \n",
    "        feature_columns, \n",
    "        target_column,\n",
    "        sequence_length, \n",
    "        train_cutoff\n",
    "    )\n",
    "    \n",
    "    # Create model\n",
    "    model = create_model(sequence_length, len(feature_columns))\n",
    "    \n",
    "    # Early stopping\n",
    "    early_stopping = EarlyStopping(\n",
    "        monitor='val_loss',\n",
    "        patience=10,\n",
    "        restore_best_weights=True,\n",
    "        min_delta=0.001\n",
    "    )\n",
    "    \n",
    "    # Train model\n",
    "    history = model.fit(\n",
    "        X_train, y_train,\n",
    "        validation_split=validation_split,\n",
    "        epochs=epochs,\n",
    "        batch_size=batch_size,\n",
    "        callbacks=[early_stopping],\n",
    "        verbose=1\n",
    "    )\n",
    "    \n",
    "    # Evaluate model\n",
    "    train_metrics = model.evaluate(X_train, y_train, verbose=0)\n",
    "    test_metrics = model.evaluate(X_test, y_test, verbose=0)\n",
    "    \n",
    "    print(\"\\nTraining Loss:\", train_metrics[0])\n",
    "    print(\"Training MAE:\", train_metrics[1])\n",
    "    print(\"Test Loss:\", test_metrics[0])\n",
    "    print(\"Test MAE:\", test_metrics[1])\n",
    "    \n",
    "    return model, history, scaler, feature_columns\n",
    "\n",
    "# Prediction function\n",
    "def predict_next_week(player_data, model, scaler, sequence_length, feature_columns):\n",
    "    \"\"\"\n",
    "    Predict next week's fantasy points for a player.\n",
    "    \"\"\"\n",
    "    # Get last sequence_length weeks of data\n",
    "    recent_data = player_data.tail(sequence_length)[feature_columns].values\n",
    "    \n",
    "    # Scale the data\n",
    "    scaled_data = scaler.transform(recent_data)\n",
    "    \n",
    "    # Reshape for prediction\n",
    "    X = scaled_data.reshape(1, sequence_length, len(feature_columns))\n",
    "    \n",
    "    # Make prediction\n",
    "    prediction = model.predict(X)\n",
    "    return prediction[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of features: 199\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\JOELA\\python_projects\\ff_data_science\\.venv\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m588/588\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 18ms/step - loss: 43.3915 - mae: 4.6436 - val_loss: 39.3294 - val_mae: 4.5248\n",
      "Epoch 2/100\n",
      "\u001b[1m588/588\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 16ms/step - loss: 44.1260 - mae: 4.8236 - val_loss: 39.7617 - val_mae: 4.3253\n",
      "Epoch 3/100\n",
      "\u001b[1m588/588\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 15ms/step - loss: 42.6614 - mae: 4.6977 - val_loss: 39.3308 - val_mae: 4.5228\n",
      "Epoch 4/100\n",
      "\u001b[1m588/588\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 16ms/step - loss: 42.5438 - mae: 4.7190 - val_loss: 39.4504 - val_mae: 4.4337\n",
      "Epoch 5/100\n",
      "\u001b[1m588/588\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 15ms/step - loss: 42.2233 - mae: 4.7179 - val_loss: 39.3289 - val_mae: 4.6336\n",
      "Epoch 6/100\n",
      "\u001b[1m588/588\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 15ms/step - loss: 42.3414 - mae: 4.7349 - val_loss: 39.3769 - val_mae: 4.4779\n",
      "Epoch 7/100\n",
      "\u001b[1m588/588\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 15ms/step - loss: 42.0802 - mae: 4.6984 - val_loss: 39.4017 - val_mae: 4.4608\n",
      "Epoch 8/100\n",
      "\u001b[1m588/588\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 15ms/step - loss: 42.1777 - mae: 4.7101 - val_loss: 39.3431 - val_mae: 4.5078\n",
      "Epoch 9/100\n",
      "\u001b[1m588/588\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 15ms/step - loss: 41.5232 - mae: 4.7318 - val_loss: 39.3501 - val_mae: 4.5005\n",
      "Epoch 10/100\n",
      "\u001b[1m588/588\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 15ms/step - loss: 41.9446 - mae: 4.7317 - val_loss: 39.3476 - val_mae: 4.6574\n",
      "Epoch 11/100\n",
      "\u001b[1m588/588\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 15ms/step - loss: 40.8367 - mae: 4.6840 - val_loss: 39.3124 - val_mae: 4.5944\n",
      "Epoch 12/100\n",
      "\u001b[1m588/588\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 15ms/step - loss: 41.1163 - mae: 4.6977 - val_loss: 39.3215 - val_mae: 4.5380\n",
      "Epoch 13/100\n",
      "\u001b[1m588/588\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 15ms/step - loss: 41.5773 - mae: 4.7189 - val_loss: 39.3124 - val_mae: 4.5945\n",
      "Epoch 14/100\n",
      "\u001b[1m588/588\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 15ms/step - loss: 41.6193 - mae: 4.7113 - val_loss: 39.3655 - val_mae: 4.6749\n",
      "Epoch 15/100\n",
      "\u001b[1m588/588\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 15ms/step - loss: 41.9007 - mae: 4.7434 - val_loss: 39.3212 - val_mae: 4.6200\n",
      "Epoch 16/100\n",
      "\u001b[1m588/588\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 15ms/step - loss: 41.2038 - mae: 4.7364 - val_loss: 39.3348 - val_mae: 4.6420\n",
      "Epoch 17/100\n",
      "\u001b[1m588/588\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 15ms/step - loss: 42.3210 - mae: 4.7793 - val_loss: 39.3713 - val_mae: 4.4822\n",
      "Epoch 18/100\n",
      "\u001b[1m588/588\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 15ms/step - loss: 42.8144 - mae: 4.7573 - val_loss: 39.3192 - val_mae: 4.6157\n",
      "Epoch 19/100\n",
      "\u001b[1m588/588\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 15ms/step - loss: 41.7905 - mae: 4.7558 - val_loss: 39.3179 - val_mae: 4.5457\n",
      "Epoch 20/100\n",
      "\u001b[1m588/588\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 15ms/step - loss: 40.7193 - mae: 4.6958 - val_loss: 39.3216 - val_mae: 4.6209\n",
      "Epoch 21/100\n",
      "\u001b[1m588/588\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 15ms/step - loss: 42.1646 - mae: 4.7779 - val_loss: 39.3288 - val_mae: 4.6333\n",
      "\n",
      "Training Loss: 41.39402770996094\n",
      "Training MAE: 4.705697059631348\n",
      "Test Loss: 41.72234344482422\n",
      "Test MAE: 4.709902763366699\n"
     ]
    }
   ],
   "source": [
    "model, history, scaler, feature_columns = train_lstm_model(df_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 175ms/step"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\JOELA\\python_projects\\ff_data_science\\.venv\\Lib\\site-packages\\sklearn\\base.py:493: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 177ms/step\n",
      "Predicted Fantasy Points for Player 00-0023459: 4.027355670928955\n"
     ]
    }
   ],
   "source": [
    "# Example player data\n",
    "specific_player_id = '00-0023459'\n",
    "player_data = df_seq[df_seq['player_id'] == specific_player_id]\n",
    "\n",
    "prediction = predict_next_week(player_data, model, scaler, sequence_length=6, feature_columns=feature_columns)\n",
    "print(f\"Predicted Fantasy Points for Player {specific_player_id}: {prediction}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predc"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
