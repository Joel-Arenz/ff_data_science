{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data\n",
    "import nfl_data_py as nfl\n",
    "\n",
    "# data loading and plotting\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# models\n",
    "import xgboost as xgb\n",
    "from xgboost import XGBRegressor, XGBClassifier, plot_importance\n",
    "\n",
    "# interpretation\n",
    "import shap\n",
    "from interpret import show\n",
    "\n",
    "# pipeline\n",
    "from sklearn.model_selection import train_test_split, TimeSeriesSplit, GridSearchCV\n",
    "from sklearn.feature_selection import RFECV, RFE\n",
    "from sklearn.impute import SimpleImputer, KNNImputer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler, LabelEncoder, OrdinalEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, root_mean_squared_error, r2_score, confusion_matrix, accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, nan_euclidean_distances\n",
    "\n",
    "pd.set_option('display.max_columns', None)  # None zeigt alle Spalten\n",
    "pd.set_option('display.max_rows', None)  # Alle Zeilen anzeigen, vorsichtig bei gro√üen DataFrames\n",
    "pd.set_option('display.width', 1000)  # Breite anpassen\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downcasting floats.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/sn/54gnf37x14l2fsfqr_hj0dnc0000gn/T/ipykernel_3805/1575219447.py:188: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_merged[feature_name_3] = rolling_result_3w\n",
      "/var/folders/sn/54gnf37x14l2fsfqr_hj0dnc0000gn/T/ipykernel_3805/1575219447.py:188: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_merged[feature_name_3] = rolling_result_3w\n",
      "/var/folders/sn/54gnf37x14l2fsfqr_hj0dnc0000gn/T/ipykernel_3805/1575219447.py:163: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_merged[feature_name_1] = (\n",
      "/var/folders/sn/54gnf37x14l2fsfqr_hj0dnc0000gn/T/ipykernel_3805/1575219447.py:177: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_merged[feature_name_2] = rolling_result_5w\n",
      "/var/folders/sn/54gnf37x14l2fsfqr_hj0dnc0000gn/T/ipykernel_3805/1575219447.py:177: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_merged[feature_name_2] = rolling_result_5w\n",
      "/var/folders/sn/54gnf37x14l2fsfqr_hj0dnc0000gn/T/ipykernel_3805/1575219447.py:177: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_merged[feature_name_2] = rolling_result_5w\n",
      "/var/folders/sn/54gnf37x14l2fsfqr_hj0dnc0000gn/T/ipykernel_3805/1575219447.py:188: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_merged[feature_name_3] = rolling_result_3w\n",
      "/var/folders/sn/54gnf37x14l2fsfqr_hj0dnc0000gn/T/ipykernel_3805/1575219447.py:188: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_merged[feature_name_3] = rolling_result_3w\n",
      "/var/folders/sn/54gnf37x14l2fsfqr_hj0dnc0000gn/T/ipykernel_3805/1575219447.py:163: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_merged[feature_name_1] = (\n",
      "/var/folders/sn/54gnf37x14l2fsfqr_hj0dnc0000gn/T/ipykernel_3805/1575219447.py:177: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_merged[feature_name_2] = rolling_result_5w\n",
      "/var/folders/sn/54gnf37x14l2fsfqr_hj0dnc0000gn/T/ipykernel_3805/1575219447.py:177: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_merged[feature_name_2] = rolling_result_5w\n",
      "/var/folders/sn/54gnf37x14l2fsfqr_hj0dnc0000gn/T/ipykernel_3805/1575219447.py:177: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_merged[feature_name_2] = rolling_result_5w\n",
      "/var/folders/sn/54gnf37x14l2fsfqr_hj0dnc0000gn/T/ipykernel_3805/1575219447.py:188: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_merged[feature_name_3] = rolling_result_3w\n",
      "/var/folders/sn/54gnf37x14l2fsfqr_hj0dnc0000gn/T/ipykernel_3805/1575219447.py:188: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_merged[feature_name_3] = rolling_result_3w\n",
      "/var/folders/sn/54gnf37x14l2fsfqr_hj0dnc0000gn/T/ipykernel_3805/1575219447.py:163: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_merged[feature_name_1] = (\n",
      "/var/folders/sn/54gnf37x14l2fsfqr_hj0dnc0000gn/T/ipykernel_3805/1575219447.py:177: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_merged[feature_name_2] = rolling_result_5w\n",
      "/var/folders/sn/54gnf37x14l2fsfqr_hj0dnc0000gn/T/ipykernel_3805/1575219447.py:177: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_merged[feature_name_2] = rolling_result_5w\n",
      "/var/folders/sn/54gnf37x14l2fsfqr_hj0dnc0000gn/T/ipykernel_3805/1575219447.py:177: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_merged[feature_name_2] = rolling_result_5w\n",
      "/var/folders/sn/54gnf37x14l2fsfqr_hj0dnc0000gn/T/ipykernel_3805/1575219447.py:188: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_merged[feature_name_3] = rolling_result_3w\n",
      "/var/folders/sn/54gnf37x14l2fsfqr_hj0dnc0000gn/T/ipykernel_3805/1575219447.py:188: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_merged[feature_name_3] = rolling_result_3w\n",
      "/var/folders/sn/54gnf37x14l2fsfqr_hj0dnc0000gn/T/ipykernel_3805/1575219447.py:163: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_merged[feature_name_1] = (\n",
      "/var/folders/sn/54gnf37x14l2fsfqr_hj0dnc0000gn/T/ipykernel_3805/1575219447.py:177: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_merged[feature_name_2] = rolling_result_5w\n",
      "/var/folders/sn/54gnf37x14l2fsfqr_hj0dnc0000gn/T/ipykernel_3805/1575219447.py:177: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_merged[feature_name_2] = rolling_result_5w\n",
      "/var/folders/sn/54gnf37x14l2fsfqr_hj0dnc0000gn/T/ipykernel_3805/1575219447.py:177: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_merged[feature_name_2] = rolling_result_5w\n",
      "/var/folders/sn/54gnf37x14l2fsfqr_hj0dnc0000gn/T/ipykernel_3805/1575219447.py:188: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_merged[feature_name_3] = rolling_result_3w\n",
      "/var/folders/sn/54gnf37x14l2fsfqr_hj0dnc0000gn/T/ipykernel_3805/1575219447.py:188: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_merged[feature_name_3] = rolling_result_3w\n",
      "/var/folders/sn/54gnf37x14l2fsfqr_hj0dnc0000gn/T/ipykernel_3805/1575219447.py:163: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_merged[feature_name_1] = (\n",
      "/var/folders/sn/54gnf37x14l2fsfqr_hj0dnc0000gn/T/ipykernel_3805/1575219447.py:177: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_merged[feature_name_2] = rolling_result_5w\n",
      "/var/folders/sn/54gnf37x14l2fsfqr_hj0dnc0000gn/T/ipykernel_3805/1575219447.py:177: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_merged[feature_name_2] = rolling_result_5w\n",
      "/var/folders/sn/54gnf37x14l2fsfqr_hj0dnc0000gn/T/ipykernel_3805/1575219447.py:177: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_merged[feature_name_2] = rolling_result_5w\n",
      "/var/folders/sn/54gnf37x14l2fsfqr_hj0dnc0000gn/T/ipykernel_3805/1575219447.py:188: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_merged[feature_name_3] = rolling_result_3w\n",
      "/var/folders/sn/54gnf37x14l2fsfqr_hj0dnc0000gn/T/ipykernel_3805/1575219447.py:188: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_merged[feature_name_3] = rolling_result_3w\n",
      "/var/folders/sn/54gnf37x14l2fsfqr_hj0dnc0000gn/T/ipykernel_3805/1575219447.py:163: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_merged[feature_name_1] = (\n",
      "/var/folders/sn/54gnf37x14l2fsfqr_hj0dnc0000gn/T/ipykernel_3805/1575219447.py:177: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_merged[feature_name_2] = rolling_result_5w\n",
      "/var/folders/sn/54gnf37x14l2fsfqr_hj0dnc0000gn/T/ipykernel_3805/1575219447.py:177: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_merged[feature_name_2] = rolling_result_5w\n",
      "/var/folders/sn/54gnf37x14l2fsfqr_hj0dnc0000gn/T/ipykernel_3805/1575219447.py:177: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_merged[feature_name_2] = rolling_result_5w\n",
      "/var/folders/sn/54gnf37x14l2fsfqr_hj0dnc0000gn/T/ipykernel_3805/1575219447.py:188: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_merged[feature_name_3] = rolling_result_3w\n",
      "/var/folders/sn/54gnf37x14l2fsfqr_hj0dnc0000gn/T/ipykernel_3805/1575219447.py:188: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_merged[feature_name_3] = rolling_result_3w\n",
      "/var/folders/sn/54gnf37x14l2fsfqr_hj0dnc0000gn/T/ipykernel_3805/1575219447.py:163: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_merged[feature_name_1] = (\n",
      "/var/folders/sn/54gnf37x14l2fsfqr_hj0dnc0000gn/T/ipykernel_3805/1575219447.py:177: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_merged[feature_name_2] = rolling_result_5w\n",
      "/var/folders/sn/54gnf37x14l2fsfqr_hj0dnc0000gn/T/ipykernel_3805/1575219447.py:177: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_merged[feature_name_2] = rolling_result_5w\n",
      "/var/folders/sn/54gnf37x14l2fsfqr_hj0dnc0000gn/T/ipykernel_3805/1575219447.py:177: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_merged[feature_name_2] = rolling_result_5w\n",
      "/var/folders/sn/54gnf37x14l2fsfqr_hj0dnc0000gn/T/ipykernel_3805/1575219447.py:188: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_merged[feature_name_3] = rolling_result_3w\n",
      "/var/folders/sn/54gnf37x14l2fsfqr_hj0dnc0000gn/T/ipykernel_3805/1575219447.py:188: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_merged[feature_name_3] = rolling_result_3w\n",
      "/var/folders/sn/54gnf37x14l2fsfqr_hj0dnc0000gn/T/ipykernel_3805/1575219447.py:163: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_merged[feature_name_1] = (\n",
      "/var/folders/sn/54gnf37x14l2fsfqr_hj0dnc0000gn/T/ipykernel_3805/1575219447.py:177: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_merged[feature_name_2] = rolling_result_5w\n",
      "/var/folders/sn/54gnf37x14l2fsfqr_hj0dnc0000gn/T/ipykernel_3805/1575219447.py:177: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_merged[feature_name_2] = rolling_result_5w\n",
      "/var/folders/sn/54gnf37x14l2fsfqr_hj0dnc0000gn/T/ipykernel_3805/1575219447.py:177: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_merged[feature_name_2] = rolling_result_5w\n",
      "/var/folders/sn/54gnf37x14l2fsfqr_hj0dnc0000gn/T/ipykernel_3805/1575219447.py:188: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_merged[feature_name_3] = rolling_result_3w\n",
      "/var/folders/sn/54gnf37x14l2fsfqr_hj0dnc0000gn/T/ipykernel_3805/1575219447.py:188: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_merged[feature_name_3] = rolling_result_3w\n",
      "/var/folders/sn/54gnf37x14l2fsfqr_hj0dnc0000gn/T/ipykernel_3805/1575219447.py:163: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_merged[feature_name_1] = (\n",
      "/var/folders/sn/54gnf37x14l2fsfqr_hj0dnc0000gn/T/ipykernel_3805/1575219447.py:177: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_merged[feature_name_2] = rolling_result_5w\n",
      "/var/folders/sn/54gnf37x14l2fsfqr_hj0dnc0000gn/T/ipykernel_3805/1575219447.py:177: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_merged[feature_name_2] = rolling_result_5w\n",
      "/var/folders/sn/54gnf37x14l2fsfqr_hj0dnc0000gn/T/ipykernel_3805/1575219447.py:177: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_merged[feature_name_2] = rolling_result_5w\n",
      "/var/folders/sn/54gnf37x14l2fsfqr_hj0dnc0000gn/T/ipykernel_3805/1575219447.py:188: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_merged[feature_name_3] = rolling_result_3w\n",
      "/var/folders/sn/54gnf37x14l2fsfqr_hj0dnc0000gn/T/ipykernel_3805/1575219447.py:188: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_merged[feature_name_3] = rolling_result_3w\n",
      "/var/folders/sn/54gnf37x14l2fsfqr_hj0dnc0000gn/T/ipykernel_3805/1575219447.py:163: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_merged[feature_name_1] = (\n",
      "/var/folders/sn/54gnf37x14l2fsfqr_hj0dnc0000gn/T/ipykernel_3805/1575219447.py:177: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_merged[feature_name_2] = rolling_result_5w\n",
      "/var/folders/sn/54gnf37x14l2fsfqr_hj0dnc0000gn/T/ipykernel_3805/1575219447.py:177: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_merged[feature_name_2] = rolling_result_5w\n",
      "/var/folders/sn/54gnf37x14l2fsfqr_hj0dnc0000gn/T/ipykernel_3805/1575219447.py:177: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_merged[feature_name_2] = rolling_result_5w\n",
      "/var/folders/sn/54gnf37x14l2fsfqr_hj0dnc0000gn/T/ipykernel_3805/1575219447.py:188: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_merged[feature_name_3] = rolling_result_3w\n",
      "/var/folders/sn/54gnf37x14l2fsfqr_hj0dnc0000gn/T/ipykernel_3805/1575219447.py:188: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_merged[feature_name_3] = rolling_result_3w\n",
      "/var/folders/sn/54gnf37x14l2fsfqr_hj0dnc0000gn/T/ipykernel_3805/1575219447.py:163: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_merged[feature_name_1] = (\n",
      "/var/folders/sn/54gnf37x14l2fsfqr_hj0dnc0000gn/T/ipykernel_3805/1575219447.py:177: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_merged[feature_name_2] = rolling_result_5w\n",
      "/var/folders/sn/54gnf37x14l2fsfqr_hj0dnc0000gn/T/ipykernel_3805/1575219447.py:177: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_merged[feature_name_2] = rolling_result_5w\n",
      "/var/folders/sn/54gnf37x14l2fsfqr_hj0dnc0000gn/T/ipykernel_3805/1575219447.py:177: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_merged[feature_name_2] = rolling_result_5w\n",
      "/var/folders/sn/54gnf37x14l2fsfqr_hj0dnc0000gn/T/ipykernel_3805/1575219447.py:188: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_merged[feature_name_3] = rolling_result_3w\n",
      "/var/folders/sn/54gnf37x14l2fsfqr_hj0dnc0000gn/T/ipykernel_3805/1575219447.py:188: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_merged[feature_name_3] = rolling_result_3w\n",
      "/var/folders/sn/54gnf37x14l2fsfqr_hj0dnc0000gn/T/ipykernel_3805/1575219447.py:163: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_merged[feature_name_1] = (\n",
      "/var/folders/sn/54gnf37x14l2fsfqr_hj0dnc0000gn/T/ipykernel_3805/1575219447.py:177: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_merged[feature_name_2] = rolling_result_5w\n",
      "/var/folders/sn/54gnf37x14l2fsfqr_hj0dnc0000gn/T/ipykernel_3805/1575219447.py:177: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_merged[feature_name_2] = rolling_result_5w\n",
      "/var/folders/sn/54gnf37x14l2fsfqr_hj0dnc0000gn/T/ipykernel_3805/1575219447.py:177: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_merged[feature_name_2] = rolling_result_5w\n",
      "/var/folders/sn/54gnf37x14l2fsfqr_hj0dnc0000gn/T/ipykernel_3805/1575219447.py:188: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_merged[feature_name_3] = rolling_result_3w\n",
      "/var/folders/sn/54gnf37x14l2fsfqr_hj0dnc0000gn/T/ipykernel_3805/1575219447.py:188: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_merged[feature_name_3] = rolling_result_3w\n",
      "/var/folders/sn/54gnf37x14l2fsfqr_hj0dnc0000gn/T/ipykernel_3805/1575219447.py:163: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_merged[feature_name_1] = (\n",
      "/var/folders/sn/54gnf37x14l2fsfqr_hj0dnc0000gn/T/ipykernel_3805/1575219447.py:177: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_merged[feature_name_2] = rolling_result_5w\n",
      "/var/folders/sn/54gnf37x14l2fsfqr_hj0dnc0000gn/T/ipykernel_3805/1575219447.py:177: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_merged[feature_name_2] = rolling_result_5w\n",
      "/var/folders/sn/54gnf37x14l2fsfqr_hj0dnc0000gn/T/ipykernel_3805/1575219447.py:177: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_merged[feature_name_2] = rolling_result_5w\n",
      "/var/folders/sn/54gnf37x14l2fsfqr_hj0dnc0000gn/T/ipykernel_3805/1575219447.py:188: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_merged[feature_name_3] = rolling_result_3w\n",
      "/var/folders/sn/54gnf37x14l2fsfqr_hj0dnc0000gn/T/ipykernel_3805/1575219447.py:188: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_merged[feature_name_3] = rolling_result_3w\n",
      "/var/folders/sn/54gnf37x14l2fsfqr_hj0dnc0000gn/T/ipykernel_3805/1575219447.py:163: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_merged[feature_name_1] = (\n",
      "/var/folders/sn/54gnf37x14l2fsfqr_hj0dnc0000gn/T/ipykernel_3805/1575219447.py:177: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_merged[feature_name_2] = rolling_result_5w\n",
      "/var/folders/sn/54gnf37x14l2fsfqr_hj0dnc0000gn/T/ipykernel_3805/1575219447.py:177: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_merged[feature_name_2] = rolling_result_5w\n",
      "/var/folders/sn/54gnf37x14l2fsfqr_hj0dnc0000gn/T/ipykernel_3805/1575219447.py:177: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_merged[feature_name_2] = rolling_result_5w\n",
      "/var/folders/sn/54gnf37x14l2fsfqr_hj0dnc0000gn/T/ipykernel_3805/1575219447.py:188: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_merged[feature_name_3] = rolling_result_3w\n",
      "/var/folders/sn/54gnf37x14l2fsfqr_hj0dnc0000gn/T/ipykernel_3805/1575219447.py:188: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_merged[feature_name_3] = rolling_result_3w\n",
      "/var/folders/sn/54gnf37x14l2fsfqr_hj0dnc0000gn/T/ipykernel_3805/1575219447.py:163: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_merged[feature_name_1] = (\n",
      "/var/folders/sn/54gnf37x14l2fsfqr_hj0dnc0000gn/T/ipykernel_3805/1575219447.py:177: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_merged[feature_name_2] = rolling_result_5w\n",
      "/var/folders/sn/54gnf37x14l2fsfqr_hj0dnc0000gn/T/ipykernel_3805/1575219447.py:177: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_merged[feature_name_2] = rolling_result_5w\n",
      "/var/folders/sn/54gnf37x14l2fsfqr_hj0dnc0000gn/T/ipykernel_3805/1575219447.py:177: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_merged[feature_name_2] = rolling_result_5w\n",
      "/var/folders/sn/54gnf37x14l2fsfqr_hj0dnc0000gn/T/ipykernel_3805/1575219447.py:188: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_merged[feature_name_3] = rolling_result_3w\n",
      "/var/folders/sn/54gnf37x14l2fsfqr_hj0dnc0000gn/T/ipykernel_3805/1575219447.py:188: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_merged[feature_name_3] = rolling_result_3w\n",
      "/var/folders/sn/54gnf37x14l2fsfqr_hj0dnc0000gn/T/ipykernel_3805/1575219447.py:163: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_merged[feature_name_1] = (\n",
      "/var/folders/sn/54gnf37x14l2fsfqr_hj0dnc0000gn/T/ipykernel_3805/1575219447.py:177: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_merged[feature_name_2] = rolling_result_5w\n",
      "/var/folders/sn/54gnf37x14l2fsfqr_hj0dnc0000gn/T/ipykernel_3805/1575219447.py:177: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_merged[feature_name_2] = rolling_result_5w\n",
      "/var/folders/sn/54gnf37x14l2fsfqr_hj0dnc0000gn/T/ipykernel_3805/1575219447.py:177: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_merged[feature_name_2] = rolling_result_5w\n",
      "/var/folders/sn/54gnf37x14l2fsfqr_hj0dnc0000gn/T/ipykernel_3805/1575219447.py:188: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_merged[feature_name_3] = rolling_result_3w\n",
      "/var/folders/sn/54gnf37x14l2fsfqr_hj0dnc0000gn/T/ipykernel_3805/1575219447.py:188: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_merged[feature_name_3] = rolling_result_3w\n",
      "/var/folders/sn/54gnf37x14l2fsfqr_hj0dnc0000gn/T/ipykernel_3805/1575219447.py:163: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_merged[feature_name_1] = (\n",
      "/var/folders/sn/54gnf37x14l2fsfqr_hj0dnc0000gn/T/ipykernel_3805/1575219447.py:177: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_merged[feature_name_2] = rolling_result_5w\n",
      "/var/folders/sn/54gnf37x14l2fsfqr_hj0dnc0000gn/T/ipykernel_3805/1575219447.py:177: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_merged[feature_name_2] = rolling_result_5w\n",
      "/var/folders/sn/54gnf37x14l2fsfqr_hj0dnc0000gn/T/ipykernel_3805/1575219447.py:177: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_merged[feature_name_2] = rolling_result_5w\n",
      "/var/folders/sn/54gnf37x14l2fsfqr_hj0dnc0000gn/T/ipykernel_3805/1575219447.py:188: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_merged[feature_name_3] = rolling_result_3w\n",
      "/var/folders/sn/54gnf37x14l2fsfqr_hj0dnc0000gn/T/ipykernel_3805/1575219447.py:188: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_merged[feature_name_3] = rolling_result_3w\n",
      "/var/folders/sn/54gnf37x14l2fsfqr_hj0dnc0000gn/T/ipykernel_3805/1575219447.py:163: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_merged[feature_name_1] = (\n",
      "/var/folders/sn/54gnf37x14l2fsfqr_hj0dnc0000gn/T/ipykernel_3805/1575219447.py:177: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_merged[feature_name_2] = rolling_result_5w\n",
      "/var/folders/sn/54gnf37x14l2fsfqr_hj0dnc0000gn/T/ipykernel_3805/1575219447.py:177: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_merged[feature_name_2] = rolling_result_5w\n",
      "/var/folders/sn/54gnf37x14l2fsfqr_hj0dnc0000gn/T/ipykernel_3805/1575219447.py:177: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_merged[feature_name_2] = rolling_result_5w\n",
      "/var/folders/sn/54gnf37x14l2fsfqr_hj0dnc0000gn/T/ipykernel_3805/1575219447.py:188: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_merged[feature_name_3] = rolling_result_3w\n",
      "/var/folders/sn/54gnf37x14l2fsfqr_hj0dnc0000gn/T/ipykernel_3805/1575219447.py:188: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_merged[feature_name_3] = rolling_result_3w\n",
      "/var/folders/sn/54gnf37x14l2fsfqr_hj0dnc0000gn/T/ipykernel_3805/1575219447.py:163: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_merged[feature_name_1] = (\n",
      "/var/folders/sn/54gnf37x14l2fsfqr_hj0dnc0000gn/T/ipykernel_3805/1575219447.py:177: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_merged[feature_name_2] = rolling_result_5w\n",
      "/var/folders/sn/54gnf37x14l2fsfqr_hj0dnc0000gn/T/ipykernel_3805/1575219447.py:177: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_merged[feature_name_2] = rolling_result_5w\n",
      "/var/folders/sn/54gnf37x14l2fsfqr_hj0dnc0000gn/T/ipykernel_3805/1575219447.py:177: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_merged[feature_name_2] = rolling_result_5w\n",
      "/var/folders/sn/54gnf37x14l2fsfqr_hj0dnc0000gn/T/ipykernel_3805/1575219447.py:188: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_merged[feature_name_3] = rolling_result_3w\n",
      "/var/folders/sn/54gnf37x14l2fsfqr_hj0dnc0000gn/T/ipykernel_3805/1575219447.py:188: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_merged[feature_name_3] = rolling_result_3w\n",
      "/var/folders/sn/54gnf37x14l2fsfqr_hj0dnc0000gn/T/ipykernel_3805/1575219447.py:163: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_merged[feature_name_1] = (\n",
      "/var/folders/sn/54gnf37x14l2fsfqr_hj0dnc0000gn/T/ipykernel_3805/1575219447.py:177: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_merged[feature_name_2] = rolling_result_5w\n",
      "/var/folders/sn/54gnf37x14l2fsfqr_hj0dnc0000gn/T/ipykernel_3805/1575219447.py:177: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_merged[feature_name_2] = rolling_result_5w\n",
      "/var/folders/sn/54gnf37x14l2fsfqr_hj0dnc0000gn/T/ipykernel_3805/1575219447.py:177: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_merged[feature_name_2] = rolling_result_5w\n",
      "/var/folders/sn/54gnf37x14l2fsfqr_hj0dnc0000gn/T/ipykernel_3805/1575219447.py:188: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_merged[feature_name_3] = rolling_result_3w\n",
      "/var/folders/sn/54gnf37x14l2fsfqr_hj0dnc0000gn/T/ipykernel_3805/1575219447.py:188: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_merged[feature_name_3] = rolling_result_3w\n",
      "/var/folders/sn/54gnf37x14l2fsfqr_hj0dnc0000gn/T/ipykernel_3805/1575219447.py:163: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_merged[feature_name_1] = (\n",
      "/var/folders/sn/54gnf37x14l2fsfqr_hj0dnc0000gn/T/ipykernel_3805/1575219447.py:177: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_merged[feature_name_2] = rolling_result_5w\n",
      "/var/folders/sn/54gnf37x14l2fsfqr_hj0dnc0000gn/T/ipykernel_3805/1575219447.py:177: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_merged[feature_name_2] = rolling_result_5w\n",
      "/var/folders/sn/54gnf37x14l2fsfqr_hj0dnc0000gn/T/ipykernel_3805/1575219447.py:177: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_merged[feature_name_2] = rolling_result_5w\n",
      "/var/folders/sn/54gnf37x14l2fsfqr_hj0dnc0000gn/T/ipykernel_3805/1575219447.py:188: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_merged[feature_name_3] = rolling_result_3w\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 30183 entries, 0 to 30182\n",
      "Columns: 245 entries, index to min_receiving_epa_l3w\n",
      "dtypes: float32(1), float64(237), int32(2), int64(5)\n",
      "memory usage: 56.1 MB\n",
      "index                                      0\n",
      "player_id                                  0\n",
      "season                                     0\n",
      "week                                       0\n",
      "fantasy_points                             0\n",
      "draft_pick                                 0\n",
      "dom                                        0\n",
      "rookie_flag                                0\n",
      "last_season_data_flag                      0\n",
      "home                                       0\n",
      "ewm_opponent_team_points_allowed_l5w       0\n",
      "mean_opponent_team_points_allowed_l5w      0\n",
      "median_opponent_team_points_allowed_l5w    0\n",
      "std_opponent_team_points_allowed_l5w       0\n",
      "min_opponent_team_points_allowed_l3w       0\n",
      "max_opponent_team_points_allowed_l3w       0\n",
      "ewm_recent_team_points_scored_l5w          0\n",
      "mean_recent_team_points_scored_l5w         0\n",
      "median_recent_team_points_scored_l5w       0\n",
      "std_recent_team_points_scored_l5w          0\n",
      "min_recent_team_points_scored_l3w          0\n",
      "max_recent_team_points_scored_l3w          0\n",
      "cnt_games_over_20ffpts_l5w                 0\n",
      "ewm_completions_l5w                        0\n",
      "mean_completions_l5w                       0\n",
      "median_completions_l5w                     0\n",
      "std_completions_l5w                        0\n",
      "max_completions_l3w                        0\n",
      "min_completions_l3w                        0\n",
      "ewm_attempts_l5w                           0\n",
      "mean_attempts_l5w                          0\n",
      "median_attempts_l5w                        0\n",
      "std_attempts_l5w                           0\n",
      "max_attempts_l3w                           0\n",
      "min_attempts_l3w                           0\n",
      "ewm_passing_yards_l5w                      0\n",
      "mean_passing_yards_l5w                     0\n",
      "median_passing_yards_l5w                   0\n",
      "std_passing_yards_l5w                      0\n",
      "max_passing_yards_l3w                      0\n",
      "min_passing_yards_l3w                      0\n",
      "ewm_sacks_l5w                              0\n",
      "mean_sacks_l5w                             0\n",
      "median_sacks_l5w                           0\n",
      "std_sacks_l5w                              0\n",
      "max_sacks_l3w                              0\n",
      "min_sacks_l3w                              0\n",
      "ewm_passer_rating_l5w                      0\n",
      "mean_passer_rating_l5w                     0\n",
      "median_passer_rating_l5w                   0\n",
      "std_passer_rating_l5w                      0\n",
      "max_passer_rating_l3w                      0\n",
      "min_passer_rating_l3w                      0\n",
      "ewm_aggressiveness_l5w                     0\n",
      "mean_aggressiveness_l5w                    0\n",
      "median_aggressiveness_l5w                  0\n",
      "std_aggressiveness_l5w                     0\n",
      "max_aggressiveness_l3w                     0\n",
      "min_aggressiveness_l3w                     0\n",
      "ewm_efficiency_l5w                         0\n",
      "mean_efficiency_l5w                        0\n",
      "median_efficiency_l5w                      0\n",
      "std_efficiency_l5w                         0\n",
      "max_efficiency_l3w                         0\n",
      "min_efficiency_l3w                         0\n",
      "ewm_sack_yards_l5w                         0\n",
      "mean_sack_yards_l5w                        0\n",
      "median_sack_yards_l5w                      0\n",
      "std_sack_yards_l5w                         0\n",
      "max_sack_yards_l3w                         0\n",
      "min_sack_yards_l3w                         0\n",
      "ewm_passing_air_yards_l5w                  0\n",
      "mean_passing_air_yards_l5w                 0\n",
      "median_passing_air_yards_l5w               0\n",
      "std_passing_air_yards_l5w                  0\n",
      "max_passing_air_yards_l3w                  0\n",
      "min_passing_air_yards_l3w                  0\n",
      "ewm_pacr_l5w                               0\n",
      "mean_pacr_l5w                              0\n",
      "median_pacr_l5w                            0\n",
      "std_pacr_l5w                               0\n",
      "max_pacr_l3w                               0\n",
      "min_pacr_l3w                               0\n",
      "ewm_carries_l5w                            0\n",
      "mean_carries_l5w                           0\n",
      "median_carries_l5w                         0\n",
      "std_carries_l5w                            0\n",
      "max_carries_l3w                            0\n",
      "min_carries_l3w                            0\n",
      "ewm_offense_snaps_l5w                      0\n",
      "mean_offense_snaps_l5w                     0\n",
      "median_offense_snaps_l5w                   0\n",
      "std_offense_snaps_l5w                      0\n",
      "max_offense_snaps_l3w                      0\n",
      "min_offense_snaps_l3w                      0\n",
      "ewm_rushing_yards_l5w                      0\n",
      "mean_rushing_yards_l5w                     0\n",
      "median_rushing_yards_l5w                   0\n",
      "std_rushing_yards_l5w                      0\n",
      "max_rushing_yards_l3w                      0\n",
      "min_rushing_yards_l3w                      0\n",
      "ewm_receptions_l5w                         0\n",
      "mean_receptions_l5w                        0\n",
      "median_receptions_l5w                      0\n",
      "std_receptions_l5w                         0\n",
      "max_receptions_l3w                         0\n",
      "min_receptions_l3w                         0\n",
      "ewm_targets_l5w                            0\n",
      "mean_targets_l5w                           0\n",
      "median_targets_l5w                         0\n",
      "std_targets_l5w                            0\n",
      "max_targets_l3w                            0\n",
      "min_targets_l3w                            0\n",
      "ewm_receiving_yards_l5w                    0\n",
      "mean_receiving_yards_l5w                   0\n",
      "median_receiving_yards_l5w                 0\n",
      "std_receiving_yards_l5w                    0\n",
      "max_receiving_yards_l3w                    0\n",
      "min_receiving_yards_l3w                    0\n",
      "ewm_racr_l5w                               0\n",
      "mean_racr_l5w                              0\n",
      "median_racr_l5w                            0\n",
      "std_racr_l5w                               0\n",
      "max_racr_l3w                               0\n",
      "min_racr_l3w                               0\n",
      "ewm_wopr_l5w                               0\n",
      "mean_wopr_l5w                              0\n",
      "median_wopr_l5w                            0\n",
      "std_wopr_l5w                               0\n",
      "max_wopr_l3w                               0\n",
      "min_wopr_l3w                               0\n",
      "ewm_fantasy_points_l5w                     0\n",
      "mean_fantasy_points_l5w                    0\n",
      "median_fantasy_points_l5w                  0\n",
      "std_fantasy_points_l5w                     0\n",
      "max_fantasy_points_l3w                     0\n",
      "min_fantasy_points_l3w                     0\n",
      "ewm_passing_bad_throws_l5w                 0\n",
      "mean_passing_bad_throws_l5w                0\n",
      "median_passing_bad_throws_l5w              0\n",
      "std_passing_bad_throws_l5w                 0\n",
      "max_passing_bad_throws_l3w                 0\n",
      "min_passing_bad_throws_l3w                 0\n",
      "ewm_times_pressured_l5w                    0\n",
      "mean_times_pressured_l5w                   0\n",
      "median_times_pressured_l5w                 0\n",
      "std_times_pressured_l5w                    0\n",
      "max_times_pressured_l3w                    0\n",
      "min_times_pressured_l3w                    0\n",
      "ewm_position_encoded_l5w                   0\n",
      "mean_position_encoded_l5w                  0\n",
      "median_position_encoded_l5w                0\n",
      "std_position_encoded_l5w                   0\n",
      "max_position_encoded_l3w                   0\n",
      "min_position_encoded_l3w                   0\n",
      "ewm_receiving_rat_l5w                      0\n",
      "mean_receiving_rat_l5w                     0\n",
      "median_receiving_rat_l5w                   0\n",
      "std_receiving_rat_l5w                      0\n",
      "max_receiving_rat_l3w                      0\n",
      "min_receiving_rat_l3w                      0\n",
      "ewm_rushing_broken_tackles_l5w             0\n",
      "mean_rushing_broken_tackles_l5w            0\n",
      "median_rushing_broken_tackles_l5w          0\n",
      "std_rushing_broken_tackles_l5w             0\n",
      "max_rushing_broken_tackles_l3w             0\n",
      "min_rushing_broken_tackles_l3w             0\n",
      "ewm_interceptions_l5w                      0\n",
      "mean_interceptions_l5w                     0\n",
      "median_interceptions_l5w                   0\n",
      "std_interceptions_l5w                      0\n",
      "max_interceptions_l3w                      0\n",
      "min_interceptions_l3w                      0\n",
      "ewm_sack_fumbles_lost_l5w                  0\n",
      "mean_sack_fumbles_lost_l5w                 0\n",
      "median_sack_fumbles_lost_l5w               0\n",
      "std_sack_fumbles_lost_l5w                  0\n",
      "max_sack_fumbles_lost_l3w                  0\n",
      "min_sack_fumbles_lost_l3w                  0\n",
      "ewm_rushing_fumbles_lost_l5w               0\n",
      "mean_rushing_fumbles_lost_l5w              0\n",
      "median_rushing_fumbles_lost_l5w            0\n",
      "std_rushing_fumbles_lost_l5w               0\n",
      "max_rushing_fumbles_lost_l3w               0\n",
      "min_rushing_fumbles_lost_l3w               0\n",
      "ewm_receiving_fumbles_lost_l5w             0\n",
      "mean_receiving_fumbles_lost_l5w            0\n",
      "median_receiving_fumbles_lost_l5w          0\n",
      "std_receiving_fumbles_lost_l5w             0\n",
      "max_receiving_fumbles_lost_l3w             0\n",
      "min_receiving_fumbles_lost_l3w             0\n",
      "ewm_rushing_tds_l5w                        0\n",
      "mean_rushing_tds_l5w                       0\n",
      "median_rushing_tds_l5w                     0\n",
      "std_rushing_tds_l5w                        0\n",
      "max_rushing_tds_l3w                        0\n",
      "min_rushing_tds_l3w                        0\n",
      "ewm_rushing_2pt_conversions_l5w            0\n",
      "mean_rushing_2pt_conversions_l5w           0\n",
      "median_rushing_2pt_conversions_l5w         0\n",
      "std_rushing_2pt_conversions_l5w            0\n",
      "max_rushing_2pt_conversions_l3w            0\n",
      "min_rushing_2pt_conversions_l3w            0\n",
      "ewm_receiving_tds_l5w                      0\n",
      "mean_receiving_tds_l5w                     0\n",
      "median_receiving_tds_l5w                   0\n",
      "std_receiving_tds_l5w                      0\n",
      "max_receiving_tds_l3w                      0\n",
      "min_receiving_tds_l3w                      0\n",
      "ewm_receiving_2pt_conversions_l5w          0\n",
      "mean_receiving_2pt_conversions_l5w         0\n",
      "median_receiving_2pt_conversions_l5w       0\n",
      "std_receiving_2pt_conversions_l5w          0\n",
      "max_receiving_2pt_conversions_l3w          0\n",
      "min_receiving_2pt_conversions_l3w          0\n",
      "ewm_passing_tds_l5w                        0\n",
      "mean_passing_tds_l5w                       0\n",
      "median_passing_tds_l5w                     0\n",
      "std_passing_tds_l5w                        0\n",
      "max_passing_tds_l3w                        0\n",
      "min_passing_tds_l3w                        0\n",
      "ewm_passing_2pt_conversions_l5w            0\n",
      "mean_passing_2pt_conversions_l5w           0\n",
      "median_passing_2pt_conversions_l5w         0\n",
      "std_passing_2pt_conversions_l5w            0\n",
      "max_passing_2pt_conversions_l3w            0\n",
      "min_passing_2pt_conversions_l3w            0\n",
      "ewm_passing_epa_l5w                        0\n",
      "mean_passing_epa_l5w                       0\n",
      "median_passing_epa_l5w                     0\n",
      "std_passing_epa_l5w                        0\n",
      "max_passing_epa_l3w                        0\n",
      "min_passing_epa_l3w                        0\n",
      "ewm_rushing_epa_l5w                        0\n",
      "mean_rushing_epa_l5w                       0\n",
      "median_rushing_epa_l5w                     0\n",
      "std_rushing_epa_l5w                        0\n",
      "max_rushing_epa_l3w                        0\n",
      "min_rushing_epa_l3w                        0\n",
      "ewm_receiving_epa_l5w                      0\n",
      "mean_receiving_epa_l5w                     0\n",
      "median_receiving_epa_l5w                   0\n",
      "std_receiving_epa_l5w                      0\n",
      "max_receiving_epa_l3w                      0\n",
      "min_receiving_epa_l3w                      0\n",
      "dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/sn/54gnf37x14l2fsfqr_hj0dnc0000gn/T/ipykernel_3805/1575219447.py:188: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_merged[feature_name_3] = rolling_result_3w\n"
     ]
    }
   ],
   "source": [
    "# Positionsspezifische Stats nicht zusammengefasst (passing, rushing und receiving jeweils eigene features)\n",
    "# Alle Metriken (ewm, mean, median, min, max, std)\n",
    "\n",
    "def load_merge_edit_data_1():   \n",
    "    \n",
    "    df_ids = nfl.import_ids()\n",
    "    df_weekly = nfl.import_weekly_data(list(range(2018, 2025)))\n",
    "    df_seasonal = nfl.import_seasonal_data(list(range(2017,2024)))\n",
    "    df_schedule = nfl.import_schedules(list(range(2018, 2025)))\n",
    "    df_pass_pfr = nfl.import_weekly_pfr('pass', list(range(2018, 2025)))\n",
    "    df_rush_pfr = nfl.import_weekly_pfr('rush', list(range(2018, 2025)))\n",
    "    df_rec_pfr = nfl.import_weekly_pfr('rec', list(range(2018, 2025)))\n",
    "    df_pass_ngs = nfl.import_ngs_data('passing',list(range(2018, 2025)))\n",
    "    df_rush_ngs = nfl.import_ngs_data('rushing',list(range(2018, 2025)))\n",
    "    df_snap_counts = nfl.import_snap_counts(list(range(2018, 2025)))\n",
    "\n",
    "    df_weekly = df_weekly[(df_weekly['season_type'] == 'REG') & (df_weekly['position'].isin(['QB', 'WR', 'RB', 'TE']))].reset_index()\n",
    "\n",
    "    df_seasonal['season'] = df_seasonal['season'] + 1\n",
    "\n",
    "    df_schedule = df_schedule[['game_id', 'home_team', 'home_score', 'away_score']].drop_duplicates()\n",
    "    df_schedule['game_id'] = df_schedule['game_id'].str.replace('OAK', 'LV', regex=False) # Umzug der Oakland Raiders nach Las Vegas in der Saison 2020\n",
    "    df_schedule['home_team'] = df_schedule['home_team'].str.replace('OAK', 'LV', regex=False) # Umzug der Oakland Raiders nach Las Vegas in der Saison 2020\n",
    "\n",
    "    df_weekly['game_id_home_away'] = df_weekly['season'].astype(str) + '_' + df_weekly['week'].apply(lambda x: f\"{x:02d}\")+'_'+df_weekly['recent_team']+'_'+df_weekly['opponent_team']\n",
    "    df_weekly['game_id_away_home'] = df_weekly['season'].astype(str) + '_' + df_weekly['week'].apply(lambda x: f\"{x:02d}\")+'_'+df_weekly['opponent_team']+'_'+df_weekly['recent_team']\n",
    "\n",
    "    df_merged = pd.melt(\n",
    "        df_weekly,\n",
    "        id_vars=['player_id', 'position', 'season', 'week', 'recent_team', 'opponent_team', 'completions', 'attempts', 'passing_yards', 'passing_tds', 'passing_2pt_conversions', 'interceptions', 'sack_fumbles_lost', 'sacks', 'sack_yards', 'passing_air_yards', 'passing_epa', 'pacr', 'carries', 'rushing_yards', 'rushing_tds', 'rushing_2pt_conversions', 'rushing_fumbles_lost', 'rushing_epa', 'receptions', 'targets', 'receiving_yards', 'receiving_tds', 'receiving_2pt_conversions', 'receiving_fumbles_lost', 'racr', 'wopr', 'receiving_epa', 'fantasy_points'],\n",
    "        value_vars=['game_id_home_away', 'game_id_away_home'],\n",
    "        var_name='game_id_type',\n",
    "        value_name='game_id'\n",
    "    )\n",
    "\n",
    "    df_ids = df_ids.rename(columns={'gsis_id': 'player_id', 'pfr_id': 'pfr_player_id'})\n",
    "    df_pass_ngs = df_pass_ngs.rename(columns={'player_gsis_id': 'player_id'})\n",
    "    df_rush_ngs = df_rush_ngs.rename(columns={'player_gsis_id': 'player_id'})\n",
    "\n",
    "    df_merged = pd.merge(df_merged, df_schedule, on='game_id', how='inner') # Bei ein paar Spielen: recent_team = opponent_team\n",
    "    df_merged = pd.merge(df_merged, df_ids[['player_id', 'pfr_player_id', 'draft_pick', 'draft_year']], on = 'player_id', how = 'inner') # Ein paar Spieler ohne draft_year\n",
    "    df_merged = pd.merge(df_merged, df_seasonal[['player_id', 'season', 'dom']], on = ['player_id', 'season'], how = 'left')\n",
    "    df_merged = pd.merge(df_merged, df_pass_pfr[['pfr_player_id', 'season', 'week', 'passing_bad_throws', 'times_pressured']], on = ['pfr_player_id', 'season', 'week'], how = 'left')\n",
    "    df_merged = pd.merge(df_merged, df_rec_pfr[['pfr_player_id', 'season', 'week', 'receiving_rat']], on = ['pfr_player_id', 'season', 'week'], how = 'left')\n",
    "    df_merged = pd.merge(df_merged, df_rush_pfr[['pfr_player_id', 'season', 'week', 'rushing_broken_tackles']], on = ['pfr_player_id', 'season', 'week'], how = 'left')\n",
    "    df_merged = pd.merge(df_merged, df_pass_ngs[['player_id', 'season', 'week', 'passer_rating', 'aggressiveness']], on = ['player_id', 'season', 'week'], how = 'left')\n",
    "    df_merged = pd.merge(df_merged, df_rush_ngs[['player_id', 'season', 'week', 'efficiency']], on = ['player_id', 'season', 'week'], how = 'left')\n",
    "    df_merged = pd.merge(df_merged, df_snap_counts[['pfr_player_id', 'season', 'week', 'offense_snaps']], on = ['pfr_player_id', 'season', 'week'], how = 'left')\n",
    "\n",
    "    df_merged = df_merged.drop(columns=['game_id_type', 'pfr_player_id'])\n",
    "\n",
    "    df_merged['draft_pick'] = df_merged['draft_pick'].fillna(260)\n",
    "    df_merged = df_merged.fillna(0)\n",
    "\n",
    "    df_merged['rookie_flag'] = (df_merged['season'] == df_merged['draft_year']).astype(int)\n",
    "    df_merged['last_season_data_flag'] = (df_merged['week'] < 6).astype(int)\n",
    "    df_merged['home'] = (df_merged['home_team'] == df_merged['recent_team']).astype(int)\n",
    "    df_merged['player_id'] = df_merged['player_id'].str.replace('00-00', '').astype(int)\n",
    "\n",
    "    # interceptions und fumbles als eigene features statt als turnover aggregiert\n",
    "    # df_merged['turnover'] = (\n",
    "    #     df_merged['interceptions'] +\n",
    "    #     df_merged['sack_fumbles_lost'] +\n",
    "    #     df_merged['rushing_fumbles_lost'] +\n",
    "    #     df_merged['receiving_fumbles_lost']\n",
    "    # )\n",
    "\n",
    "    # tds und 2pt conversions als eigene features statt als total points aggregiert\n",
    "    # df_merged['points_total'] = (\n",
    "    #     (df_merged['rushing_tds'] * 6) + \n",
    "    #     (df_merged['rushing_2pt_conversions'] * 2) + \n",
    "    #     (df_merged['receiving_tds'] * 6) + \n",
    "    #     (df_merged['receiving_2pt_conversions'] * 2) + \n",
    "    #     (df_merged['passing_tds'] * 6) + \n",
    "    #     (df_merged['passing_2pt_conversions'] * 2)\n",
    "    # )\n",
    "\n",
    "    # passing, rushing und receiving epa als eigene features statt als epa aggregiert\n",
    "    # df_merged['epa_total'] = df_merged['passing_epa'] + df_merged['rushing_epa'] + df_merged['receiving_epa']\n",
    "\n",
    "    # passing, rushing und receiving yards einzeln statt total yards aggregiert\n",
    "    # df_merged['yards_total'] = (\n",
    "    #     df_merged['passing_yards'] +\n",
    "    #     df_merged['rushing_yards'] +\n",
    "    #     df_merged['receiving_yards']\n",
    "    # )\n",
    "\n",
    "    # position target-encoded\n",
    "    position_means = df_merged.groupby(['position', 'season', 'week'])['fantasy_points'].mean().reset_index()\n",
    "    position_means.rename(columns={'fantasy_points': 'position_encoded'}, inplace=True)\n",
    "    df_merged = pd.merge(df_merged, position_means, on=['position', 'season', 'week'], how='left')\n",
    "\n",
    "    # points_scored und points_allowed als Ma√üstab f√ºr St√§rke eines Teams\n",
    "    df_merged['recent_team_points_scored'] = df_merged.apply(lambda row: row['home_score'] if row['home'] == 1 else row['away_score'], axis=1)\n",
    "    df_merged['opponent_team_points_allowed'] = df_merged['recent_team_points_scored']\n",
    "\n",
    "    df_unique_opponent_team_points_allowed = df_merged.drop_duplicates(subset=['game_id', 'opponent_team', 'opponent_team_points_allowed'])\n",
    "    df_unique_recent_team_points_scored = df_merged.drop_duplicates(subset=['game_id', 'recent_team', 'recent_team_points_scored'])\n",
    "\n",
    "    df_unique_opponent_team_points_allowed = df_unique_opponent_team_points_allowed.sort_values(by=['opponent_team', 'season', 'week']).reset_index(drop=True)\n",
    "    df_unique_recent_team_points_scored = df_unique_recent_team_points_scored.sort_values(by=['recent_team', 'season', 'week']).reset_index(drop=True)\n",
    "\n",
    "    df_unique_opponent_team_points_allowed['ewm_opponent_team_points_allowed_l5w'] = (\n",
    "        df_unique_opponent_team_points_allowed.groupby('opponent_team')['opponent_team_points_allowed']\n",
    "        .apply(lambda x: x.shift(1).ewm(span=5, min_periods=5).mean())\n",
    "        .reset_index(level=0, drop=True)\n",
    "    )\n",
    "\n",
    "    for metric in ['mean', 'median', 'std']:\n",
    "            df_unique_opponent_team_points_allowed[f\"{metric}_opponent_team_points_allowed_l5w\"] = (\n",
    "                df_unique_opponent_team_points_allowed.groupby('opponent_team')['opponent_team_points_allowed']\n",
    "                .apply(lambda x: x.shift(1).rolling(window=5, min_periods=5).agg(metric))  # shift(1) schlie√üt aktuelle Woche aus\n",
    "                .reset_index(level=0, drop=True)  # Index zur√ºcksetzen\n",
    "        )\n",
    "\n",
    "    for metric in ['min', 'max']:\n",
    "            df_unique_opponent_team_points_allowed[f\"{metric}_opponent_team_points_allowed_l3w\"] = (\n",
    "                df_unique_opponent_team_points_allowed.groupby('opponent_team')['opponent_team_points_allowed']\n",
    "                .apply(lambda x: x.shift(1).rolling(window=3, min_periods=3).agg(metric))  # shift(1) schlie√üt aktuelle Woche aus\n",
    "                .reset_index(level=0, drop=True)  # Index zur√ºcksetzen\n",
    "        )\n",
    "\n",
    "    df_unique_opponent_team_points_allowed = df_unique_opponent_team_points_allowed.drop(columns=['player_id', 'draft_year', 'interceptions', 'sack_fumbles_lost', 'rushing_fumbles_lost', 'receiving_fumbles_lost', 'rushing_tds', 'rushing_2pt_conversions', 'receiving_tds', 'receiving_2pt_conversions', 'passing_tds', 'passing_2pt_conversions', 'passing_epa', 'rushing_epa', 'receiving_epa', 'position', 'season', 'week', 'recent_team', 'home_team', 'completions', 'attempts', 'passing_yards', 'sacks', 'sack_yards', 'passing_air_yards', 'pacr', 'carries', 'rushing_yards', 'receptions', 'targets', 'receiving_yards', 'racr', 'wopr', 'fantasy_points', 'home_score', 'away_score', 'draft_pick', 'dom', 'passing_bad_throws', 'times_pressured', 'receiving_rat', 'rushing_broken_tackles', 'passer_rating', 'aggressiveness', 'efficiency', 'offense_snaps', 'rookie_flag', 'last_season_data_flag', 'home', 'position_encoded', 'recent_team_points_scored', 'opponent_team_points_allowed'])\n",
    "    df_merged = pd.merge(df_merged, df_unique_opponent_team_points_allowed, on=['game_id','opponent_team'], how='inner')\n",
    "\n",
    "    df_unique_recent_team_points_scored['ewm_recent_team_points_scored_l5w'] = (\n",
    "        df_unique_recent_team_points_scored.groupby('recent_team')['recent_team_points_scored']\n",
    "        .apply(lambda x: x.shift(1).ewm(span=5, min_periods=5).mean())\n",
    "        .reset_index(level=0, drop=True)\n",
    "    )\n",
    "\n",
    "    for metric in ['mean', 'median', 'std']:\n",
    "            df_unique_recent_team_points_scored[f\"{metric}_recent_team_points_scored_l5w\"] = (\n",
    "                df_unique_recent_team_points_scored.groupby('recent_team')['recent_team_points_scored']\n",
    "                .apply(lambda x: x.shift(1).rolling(window=5, min_periods=5).agg(metric))  # shift(1) schlie√üt aktuelle Woche aus\n",
    "                .reset_index(level=0, drop=True)  # Index zur√ºcksetzen\n",
    "        )\n",
    "\n",
    "    for metric in ['min', 'max']:\n",
    "            df_unique_recent_team_points_scored[f\"{metric}_recent_team_points_scored_l3w\"] = (\n",
    "                df_unique_recent_team_points_scored.groupby('recent_team')['recent_team_points_scored']\n",
    "                .apply(lambda x: x.shift(1).rolling(window=3, min_periods=3).agg(metric))  # shift(1) schlie√üt aktuelle Woche aus\n",
    "                .reset_index(level=0, drop=True)  # Index zur√ºcksetzen\n",
    "        )\n",
    "\n",
    "    df_unique_recent_team_points_scored = df_unique_recent_team_points_scored.drop(columns=['player_id', 'draft_year', 'interceptions', 'sack_fumbles_lost', 'rushing_fumbles_lost', 'receiving_fumbles_lost', 'rushing_tds', 'rushing_2pt_conversions', 'receiving_tds', 'receiving_2pt_conversions', 'passing_tds', 'passing_2pt_conversions', 'passing_epa', 'rushing_epa', 'receiving_epa', 'position', 'season', 'week', 'opponent_team', 'home_team', 'completions', 'attempts', 'passing_yards', 'sacks', 'sack_yards', 'passing_air_yards', 'pacr', 'carries', 'rushing_yards', 'receptions', 'targets', 'receiving_yards', 'racr', 'wopr', 'fantasy_points', 'home_score', 'away_score', 'draft_pick', 'dom', 'passing_bad_throws', 'times_pressured', 'receiving_rat', 'rushing_broken_tackles', 'passer_rating', 'aggressiveness', 'efficiency', 'offense_snaps', 'rookie_flag', 'last_season_data_flag', 'home', 'position_encoded', 'recent_team_points_scored', 'opponent_team_points_allowed'])\n",
    "    df_merged = pd.merge(df_merged, df_unique_recent_team_points_scored, on=['game_id','recent_team'], how='inner')\n",
    "\n",
    "    # Liste der Spalten mit Spielerspezifischen numerischen Daten, f√ºr die Rolling-Features erstellt werden sollen\n",
    "    columns_to_roll = ['completions', 'attempts', 'passing_yards', 'sacks', 'passer_rating', 'aggressiveness', 'efficiency', 'sack_yards', \n",
    "                    'passing_air_yards', 'pacr', 'carries', 'offense_snaps', 'rushing_yards', 'receptions', 'targets', 'receiving_yards', \n",
    "                    'racr', 'wopr', 'fantasy_points', 'passing_bad_throws', 'times_pressured', 'position_encoded', 'receiving_rat', \n",
    "                    'rushing_broken_tackles',  'interceptions', 'sack_fumbles_lost', 'rushing_fumbles_lost', 'receiving_fumbles_lost', 'rushing_tds', \n",
    "                    'rushing_2pt_conversions', 'receiving_tds', 'receiving_2pt_conversions', 'passing_tds', 'passing_2pt_conversions', 'passing_epa', \n",
    "                    'rushing_epa', 'receiving_epa']\n",
    "\n",
    "\n",
    "    # Sortiere nach player_id, season und week\n",
    "    df_merged = df_merged.sort_values(by=['player_id', 'season', 'week']).reset_index(drop=True)\n",
    "\n",
    "\n",
    "    df_merged['cnt_games_over_20ffpts_l5w'] = (\n",
    "        df_merged.groupby('player_id')['fantasy_points']\n",
    "        .apply(lambda x: x.shift(1).rolling(window=5, min_periods=5).apply(lambda y: (y > 20).sum()))\n",
    "        .reset_index(level=0, drop=True)\n",
    "    )\n",
    "\n",
    "    # Rolling-Features erstellen\n",
    "    for col in columns_to_roll:\n",
    "\n",
    "        feature_name_1 = f\"ewm_{col}_l5w\"\n",
    "        df_merged[feature_name_1] = (\n",
    "            df_merged.groupby('player_id')[col]\n",
    "            .apply(lambda x: x.shift(1).ewm(span=5, min_periods=5).mean())\n",
    "            .reset_index(level=0, drop=True)\n",
    "        )\n",
    "\n",
    "        for metric in ['mean', 'median', 'std']:\n",
    "            feature_name_2 = f\"{metric}_{col}_l5w\"\n",
    "            rolling_result_5w = (\n",
    "                df_merged.groupby('player_id')[col]\n",
    "                    .apply(lambda x: x.shift(1).rolling(window=5, min_periods=5).agg(metric))  # shift(1) schlie√üt aktuelle Woche aus\n",
    "                    .reset_index(level=0, drop=True)  # Index zur√ºcksetzen\n",
    "            )\n",
    "            # Einf√ºgen der Rolling-Metrik\n",
    "            df_merged[feature_name_2] = rolling_result_5w\n",
    "\n",
    "        for metric in ['max', 'min']:\n",
    "            feature_name_3 = f\"{metric}_{col}_l3w\"\n",
    "            # Berechnung der Rolling-Metrik (ohne aktuelle Woche)\n",
    "            rolling_result_3w = (\n",
    "                df_merged.groupby('player_id')[col]\n",
    "                    .apply(lambda x: x.shift(1).rolling(window=3, min_periods=3).agg(metric))  # shift(1) schlie√üt aktuelle Woche aus\n",
    "                    .reset_index(level=0, drop=True)  # Index zur√ºcksetzen\n",
    "            )\n",
    "            # Einf√ºgen der Rolling-Metrik\n",
    "            df_merged[feature_name_3] = rolling_result_3w\n",
    "\n",
    "    df_merged = df_merged.drop(columns=['completions', 'attempts', 'passing_yards', 'sacks', 'sack_yards', 'passing_air_yards', 'pacr', 'carries', \n",
    "                                        'rushing_yards', 'receptions', 'targets', 'receiving_yards', 'racr', 'wopr', 'passing_bad_throws', \n",
    "                                        'times_pressured', 'receiving_rat', 'rushing_broken_tackles', 'draft_year', 'home_team', \n",
    "                                        'passer_rating', 'aggressiveness', 'efficiency', 'offense_snaps', 'game_id',  'interceptions', 'sack_fumbles_lost', \n",
    "                                        'rushing_fumbles_lost', 'receiving_fumbles_lost', 'rushing_tds', 'rushing_2pt_conversions', 'receiving_tds', \n",
    "                                        'receiving_2pt_conversions', 'passing_tds', 'passing_2pt_conversions', 'passing_epa', 'rushing_epa', 'receiving_epa',\n",
    "                                        'position_encoded', 'recent_team', 'opponent_team', 'position', 'home_score', 'away_score',\n",
    "                                        'recent_team_points_scored', 'opponent_team_points_allowed'])\n",
    "\n",
    "    df_merged = df_merged.dropna().reset_index()\n",
    "\n",
    "    return df_merged\n",
    "\n",
    "df_1 = load_merge_edit_data_1()\n",
    "\n",
    "df_1.info()\n",
    "print(df_1.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downcasting floats.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/sn/54gnf37x14l2fsfqr_hj0dnc0000gn/T/ipykernel_6060/1877537103.py:199: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_merged[feature_name_3] = rolling_result_3w\n",
      "/var/folders/sn/54gnf37x14l2fsfqr_hj0dnc0000gn/T/ipykernel_6060/1877537103.py:199: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_merged[feature_name_3] = rolling_result_3w\n",
      "/var/folders/sn/54gnf37x14l2fsfqr_hj0dnc0000gn/T/ipykernel_6060/1877537103.py:174: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_merged[feature_name_1] = (\n",
      "/var/folders/sn/54gnf37x14l2fsfqr_hj0dnc0000gn/T/ipykernel_6060/1877537103.py:188: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_merged[feature_name_2] = rolling_result_5w\n",
      "/var/folders/sn/54gnf37x14l2fsfqr_hj0dnc0000gn/T/ipykernel_6060/1877537103.py:188: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_merged[feature_name_2] = rolling_result_5w\n",
      "/var/folders/sn/54gnf37x14l2fsfqr_hj0dnc0000gn/T/ipykernel_6060/1877537103.py:188: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_merged[feature_name_2] = rolling_result_5w\n",
      "/var/folders/sn/54gnf37x14l2fsfqr_hj0dnc0000gn/T/ipykernel_6060/1877537103.py:199: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_merged[feature_name_3] = rolling_result_3w\n",
      "/var/folders/sn/54gnf37x14l2fsfqr_hj0dnc0000gn/T/ipykernel_6060/1877537103.py:199: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_merged[feature_name_3] = rolling_result_3w\n",
      "/var/folders/sn/54gnf37x14l2fsfqr_hj0dnc0000gn/T/ipykernel_6060/1877537103.py:174: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_merged[feature_name_1] = (\n",
      "/var/folders/sn/54gnf37x14l2fsfqr_hj0dnc0000gn/T/ipykernel_6060/1877537103.py:188: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_merged[feature_name_2] = rolling_result_5w\n",
      "/var/folders/sn/54gnf37x14l2fsfqr_hj0dnc0000gn/T/ipykernel_6060/1877537103.py:188: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_merged[feature_name_2] = rolling_result_5w\n",
      "/var/folders/sn/54gnf37x14l2fsfqr_hj0dnc0000gn/T/ipykernel_6060/1877537103.py:188: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_merged[feature_name_2] = rolling_result_5w\n",
      "/var/folders/sn/54gnf37x14l2fsfqr_hj0dnc0000gn/T/ipykernel_6060/1877537103.py:199: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_merged[feature_name_3] = rolling_result_3w\n",
      "/var/folders/sn/54gnf37x14l2fsfqr_hj0dnc0000gn/T/ipykernel_6060/1877537103.py:199: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_merged[feature_name_3] = rolling_result_3w\n",
      "/var/folders/sn/54gnf37x14l2fsfqr_hj0dnc0000gn/T/ipykernel_6060/1877537103.py:174: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_merged[feature_name_1] = (\n",
      "/var/folders/sn/54gnf37x14l2fsfqr_hj0dnc0000gn/T/ipykernel_6060/1877537103.py:188: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_merged[feature_name_2] = rolling_result_5w\n",
      "/var/folders/sn/54gnf37x14l2fsfqr_hj0dnc0000gn/T/ipykernel_6060/1877537103.py:188: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_merged[feature_name_2] = rolling_result_5w\n",
      "/var/folders/sn/54gnf37x14l2fsfqr_hj0dnc0000gn/T/ipykernel_6060/1877537103.py:188: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_merged[feature_name_2] = rolling_result_5w\n",
      "/var/folders/sn/54gnf37x14l2fsfqr_hj0dnc0000gn/T/ipykernel_6060/1877537103.py:199: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_merged[feature_name_3] = rolling_result_3w\n",
      "/var/folders/sn/54gnf37x14l2fsfqr_hj0dnc0000gn/T/ipykernel_6060/1877537103.py:199: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_merged[feature_name_3] = rolling_result_3w\n",
      "/var/folders/sn/54gnf37x14l2fsfqr_hj0dnc0000gn/T/ipykernel_6060/1877537103.py:174: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_merged[feature_name_1] = (\n",
      "/var/folders/sn/54gnf37x14l2fsfqr_hj0dnc0000gn/T/ipykernel_6060/1877537103.py:188: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_merged[feature_name_2] = rolling_result_5w\n",
      "/var/folders/sn/54gnf37x14l2fsfqr_hj0dnc0000gn/T/ipykernel_6060/1877537103.py:188: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_merged[feature_name_2] = rolling_result_5w\n",
      "/var/folders/sn/54gnf37x14l2fsfqr_hj0dnc0000gn/T/ipykernel_6060/1877537103.py:188: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_merged[feature_name_2] = rolling_result_5w\n",
      "/var/folders/sn/54gnf37x14l2fsfqr_hj0dnc0000gn/T/ipykernel_6060/1877537103.py:199: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_merged[feature_name_3] = rolling_result_3w\n",
      "/var/folders/sn/54gnf37x14l2fsfqr_hj0dnc0000gn/T/ipykernel_6060/1877537103.py:199: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_merged[feature_name_3] = rolling_result_3w\n",
      "/var/folders/sn/54gnf37x14l2fsfqr_hj0dnc0000gn/T/ipykernel_6060/1877537103.py:174: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_merged[feature_name_1] = (\n",
      "/var/folders/sn/54gnf37x14l2fsfqr_hj0dnc0000gn/T/ipykernel_6060/1877537103.py:188: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_merged[feature_name_2] = rolling_result_5w\n",
      "/var/folders/sn/54gnf37x14l2fsfqr_hj0dnc0000gn/T/ipykernel_6060/1877537103.py:188: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_merged[feature_name_2] = rolling_result_5w\n",
      "/var/folders/sn/54gnf37x14l2fsfqr_hj0dnc0000gn/T/ipykernel_6060/1877537103.py:188: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_merged[feature_name_2] = rolling_result_5w\n",
      "/var/folders/sn/54gnf37x14l2fsfqr_hj0dnc0000gn/T/ipykernel_6060/1877537103.py:199: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_merged[feature_name_3] = rolling_result_3w\n",
      "/var/folders/sn/54gnf37x14l2fsfqr_hj0dnc0000gn/T/ipykernel_6060/1877537103.py:199: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_merged[feature_name_3] = rolling_result_3w\n",
      "/var/folders/sn/54gnf37x14l2fsfqr_hj0dnc0000gn/T/ipykernel_6060/1877537103.py:174: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_merged[feature_name_1] = (\n",
      "/var/folders/sn/54gnf37x14l2fsfqr_hj0dnc0000gn/T/ipykernel_6060/1877537103.py:188: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_merged[feature_name_2] = rolling_result_5w\n",
      "/var/folders/sn/54gnf37x14l2fsfqr_hj0dnc0000gn/T/ipykernel_6060/1877537103.py:188: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_merged[feature_name_2] = rolling_result_5w\n",
      "/var/folders/sn/54gnf37x14l2fsfqr_hj0dnc0000gn/T/ipykernel_6060/1877537103.py:188: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_merged[feature_name_2] = rolling_result_5w\n",
      "/var/folders/sn/54gnf37x14l2fsfqr_hj0dnc0000gn/T/ipykernel_6060/1877537103.py:199: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_merged[feature_name_3] = rolling_result_3w\n",
      "/var/folders/sn/54gnf37x14l2fsfqr_hj0dnc0000gn/T/ipykernel_6060/1877537103.py:199: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_merged[feature_name_3] = rolling_result_3w\n",
      "/var/folders/sn/54gnf37x14l2fsfqr_hj0dnc0000gn/T/ipykernel_6060/1877537103.py:174: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_merged[feature_name_1] = (\n",
      "/var/folders/sn/54gnf37x14l2fsfqr_hj0dnc0000gn/T/ipykernel_6060/1877537103.py:188: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_merged[feature_name_2] = rolling_result_5w\n",
      "/var/folders/sn/54gnf37x14l2fsfqr_hj0dnc0000gn/T/ipykernel_6060/1877537103.py:188: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_merged[feature_name_2] = rolling_result_5w\n",
      "/var/folders/sn/54gnf37x14l2fsfqr_hj0dnc0000gn/T/ipykernel_6060/1877537103.py:188: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_merged[feature_name_2] = rolling_result_5w\n",
      "/var/folders/sn/54gnf37x14l2fsfqr_hj0dnc0000gn/T/ipykernel_6060/1877537103.py:199: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_merged[feature_name_3] = rolling_result_3w\n",
      "/var/folders/sn/54gnf37x14l2fsfqr_hj0dnc0000gn/T/ipykernel_6060/1877537103.py:199: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_merged[feature_name_3] = rolling_result_3w\n",
      "/var/folders/sn/54gnf37x14l2fsfqr_hj0dnc0000gn/T/ipykernel_6060/1877537103.py:174: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_merged[feature_name_1] = (\n",
      "/var/folders/sn/54gnf37x14l2fsfqr_hj0dnc0000gn/T/ipykernel_6060/1877537103.py:188: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_merged[feature_name_2] = rolling_result_5w\n",
      "/var/folders/sn/54gnf37x14l2fsfqr_hj0dnc0000gn/T/ipykernel_6060/1877537103.py:188: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_merged[feature_name_2] = rolling_result_5w\n",
      "/var/folders/sn/54gnf37x14l2fsfqr_hj0dnc0000gn/T/ipykernel_6060/1877537103.py:188: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_merged[feature_name_2] = rolling_result_5w\n",
      "/var/folders/sn/54gnf37x14l2fsfqr_hj0dnc0000gn/T/ipykernel_6060/1877537103.py:199: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_merged[feature_name_3] = rolling_result_3w\n",
      "/var/folders/sn/54gnf37x14l2fsfqr_hj0dnc0000gn/T/ipykernel_6060/1877537103.py:199: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_merged[feature_name_3] = rolling_result_3w\n",
      "/var/folders/sn/54gnf37x14l2fsfqr_hj0dnc0000gn/T/ipykernel_6060/1877537103.py:174: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_merged[feature_name_1] = (\n",
      "/var/folders/sn/54gnf37x14l2fsfqr_hj0dnc0000gn/T/ipykernel_6060/1877537103.py:188: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_merged[feature_name_2] = rolling_result_5w\n",
      "/var/folders/sn/54gnf37x14l2fsfqr_hj0dnc0000gn/T/ipykernel_6060/1877537103.py:188: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_merged[feature_name_2] = rolling_result_5w\n",
      "/var/folders/sn/54gnf37x14l2fsfqr_hj0dnc0000gn/T/ipykernel_6060/1877537103.py:188: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_merged[feature_name_2] = rolling_result_5w\n",
      "/var/folders/sn/54gnf37x14l2fsfqr_hj0dnc0000gn/T/ipykernel_6060/1877537103.py:199: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_merged[feature_name_3] = rolling_result_3w\n",
      "/var/folders/sn/54gnf37x14l2fsfqr_hj0dnc0000gn/T/ipykernel_6060/1877537103.py:199: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_merged[feature_name_3] = rolling_result_3w\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 30183 entries, 0 to 30182\n",
      "Columns: 173 entries, index to min_epa_total_l3w\n",
      "dtypes: float32(1), float64(165), int32(2), int64(5)\n",
      "memory usage: 39.5 MB\n",
      "index                                      0\n",
      "player_id                                  0\n",
      "season                                     0\n",
      "week                                       0\n",
      "fantasy_points                             0\n",
      "draft_pick                                 0\n",
      "dom                                        0\n",
      "rookie_flag                                0\n",
      "last_season_data_flag                      0\n",
      "home                                       0\n",
      "ewm_opponent_team_points_allowed_l5w       0\n",
      "mean_opponent_team_points_allowed_l5w      0\n",
      "median_opponent_team_points_allowed_l5w    0\n",
      "std_opponent_team_points_allowed_l5w       0\n",
      "min_opponent_team_points_allowed_l3w       0\n",
      "max_opponent_team_points_allowed_l3w       0\n",
      "ewm_recent_team_points_scored_l5w          0\n",
      "mean_recent_team_points_scored_l5w         0\n",
      "median_recent_team_points_scored_l5w       0\n",
      "std_recent_team_points_scored_l5w          0\n",
      "min_recent_team_points_scored_l3w          0\n",
      "max_recent_team_points_scored_l3w          0\n",
      "cnt_games_over_20ffpts_l5w                 0\n",
      "ewm_completions_l5w                        0\n",
      "mean_completions_l5w                       0\n",
      "median_completions_l5w                     0\n",
      "std_completions_l5w                        0\n",
      "max_completions_l3w                        0\n",
      "min_completions_l3w                        0\n",
      "ewm_attempts_l5w                           0\n",
      "mean_attempts_l5w                          0\n",
      "median_attempts_l5w                        0\n",
      "std_attempts_l5w                           0\n",
      "max_attempts_l3w                           0\n",
      "min_attempts_l3w                           0\n",
      "ewm_sacks_l5w                              0\n",
      "mean_sacks_l5w                             0\n",
      "median_sacks_l5w                           0\n",
      "std_sacks_l5w                              0\n",
      "max_sacks_l3w                              0\n",
      "min_sacks_l3w                              0\n",
      "ewm_passer_rating_l5w                      0\n",
      "mean_passer_rating_l5w                     0\n",
      "median_passer_rating_l5w                   0\n",
      "std_passer_rating_l5w                      0\n",
      "max_passer_rating_l3w                      0\n",
      "min_passer_rating_l3w                      0\n",
      "ewm_aggressiveness_l5w                     0\n",
      "mean_aggressiveness_l5w                    0\n",
      "median_aggressiveness_l5w                  0\n",
      "std_aggressiveness_l5w                     0\n",
      "max_aggressiveness_l3w                     0\n",
      "min_aggressiveness_l3w                     0\n",
      "ewm_efficiency_l5w                         0\n",
      "mean_efficiency_l5w                        0\n",
      "median_efficiency_l5w                      0\n",
      "std_efficiency_l5w                         0\n",
      "max_efficiency_l3w                         0\n",
      "min_efficiency_l3w                         0\n",
      "ewm_sack_yards_l5w                         0\n",
      "mean_sack_yards_l5w                        0\n",
      "median_sack_yards_l5w                      0\n",
      "std_sack_yards_l5w                         0\n",
      "max_sack_yards_l3w                         0\n",
      "min_sack_yards_l3w                         0\n",
      "ewm_passing_air_yards_l5w                  0\n",
      "mean_passing_air_yards_l5w                 0\n",
      "median_passing_air_yards_l5w               0\n",
      "std_passing_air_yards_l5w                  0\n",
      "max_passing_air_yards_l3w                  0\n",
      "min_passing_air_yards_l3w                  0\n",
      "ewm_pacr_l5w                               0\n",
      "mean_pacr_l5w                              0\n",
      "median_pacr_l5w                            0\n",
      "std_pacr_l5w                               0\n",
      "max_pacr_l3w                               0\n",
      "min_pacr_l3w                               0\n",
      "ewm_carries_l5w                            0\n",
      "mean_carries_l5w                           0\n",
      "median_carries_l5w                         0\n",
      "std_carries_l5w                            0\n",
      "max_carries_l3w                            0\n",
      "min_carries_l3w                            0\n",
      "ewm_offense_snaps_l5w                      0\n",
      "mean_offense_snaps_l5w                     0\n",
      "median_offense_snaps_l5w                   0\n",
      "std_offense_snaps_l5w                      0\n",
      "max_offense_snaps_l3w                      0\n",
      "min_offense_snaps_l3w                      0\n",
      "ewm_yards_total_l5w                        0\n",
      "mean_yards_total_l5w                       0\n",
      "median_yards_total_l5w                     0\n",
      "std_yards_total_l5w                        0\n",
      "max_yards_total_l3w                        0\n",
      "min_yards_total_l3w                        0\n",
      "ewm_receptions_l5w                         0\n",
      "mean_receptions_l5w                        0\n",
      "median_receptions_l5w                      0\n",
      "std_receptions_l5w                         0\n",
      "max_receptions_l3w                         0\n",
      "min_receptions_l3w                         0\n",
      "ewm_targets_l5w                            0\n",
      "mean_targets_l5w                           0\n",
      "median_targets_l5w                         0\n",
      "std_targets_l5w                            0\n",
      "max_targets_l3w                            0\n",
      "min_targets_l3w                            0\n",
      "ewm_racr_l5w                               0\n",
      "mean_racr_l5w                              0\n",
      "median_racr_l5w                            0\n",
      "std_racr_l5w                               0\n",
      "max_racr_l3w                               0\n",
      "min_racr_l3w                               0\n",
      "ewm_wopr_l5w                               0\n",
      "mean_wopr_l5w                              0\n",
      "median_wopr_l5w                            0\n",
      "std_wopr_l5w                               0\n",
      "max_wopr_l3w                               0\n",
      "min_wopr_l3w                               0\n",
      "ewm_fantasy_points_l5w                     0\n",
      "mean_fantasy_points_l5w                    0\n",
      "median_fantasy_points_l5w                  0\n",
      "std_fantasy_points_l5w                     0\n",
      "max_fantasy_points_l3w                     0\n",
      "min_fantasy_points_l3w                     0\n",
      "ewm_passing_bad_throws_l5w                 0\n",
      "mean_passing_bad_throws_l5w                0\n",
      "median_passing_bad_throws_l5w              0\n",
      "std_passing_bad_throws_l5w                 0\n",
      "max_passing_bad_throws_l3w                 0\n",
      "min_passing_bad_throws_l3w                 0\n",
      "ewm_times_pressured_l5w                    0\n",
      "mean_times_pressured_l5w                   0\n",
      "median_times_pressured_l5w                 0\n",
      "std_times_pressured_l5w                    0\n",
      "max_times_pressured_l3w                    0\n",
      "min_times_pressured_l3w                    0\n",
      "ewm_position_encoded_l5w                   0\n",
      "mean_position_encoded_l5w                  0\n",
      "median_position_encoded_l5w                0\n",
      "std_position_encoded_l5w                   0\n",
      "max_position_encoded_l3w                   0\n",
      "min_position_encoded_l3w                   0\n",
      "ewm_receiving_rat_l5w                      0\n",
      "mean_receiving_rat_l5w                     0\n",
      "median_receiving_rat_l5w                   0\n",
      "std_receiving_rat_l5w                      0\n",
      "max_receiving_rat_l3w                      0\n",
      "min_receiving_rat_l3w                      0\n",
      "ewm_rushing_broken_tackles_l5w             0\n",
      "mean_rushing_broken_tackles_l5w            0\n",
      "median_rushing_broken_tackles_l5w          0\n",
      "std_rushing_broken_tackles_l5w             0\n",
      "max_rushing_broken_tackles_l3w             0\n",
      "min_rushing_broken_tackles_l3w             0\n",
      "ewm_turnover_l5w                           0\n",
      "mean_turnover_l5w                          0\n",
      "median_turnover_l5w                        0\n",
      "std_turnover_l5w                           0\n",
      "max_turnover_l3w                           0\n",
      "min_turnover_l3w                           0\n",
      "ewm_points_total_l5w                       0\n",
      "mean_points_total_l5w                      0\n",
      "median_points_total_l5w                    0\n",
      "std_points_total_l5w                       0\n",
      "max_points_total_l3w                       0\n",
      "min_points_total_l3w                       0\n",
      "ewm_epa_total_l5w                          0\n",
      "mean_epa_total_l5w                         0\n",
      "median_epa_total_l5w                       0\n",
      "std_epa_total_l5w                          0\n",
      "max_epa_total_l3w                          0\n",
      "min_epa_total_l3w                          0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Positionsspezifische Stats zusammengefasst (passing, rushing und receiving zu total_features zusammengefasst)\n",
    "# Alle Metriken (ewm, mean, median, min, max, std)\n",
    "\n",
    "def load_merge_edit_data_2():  \n",
    "\n",
    "    df_ids = nfl.import_ids()\n",
    "    df_weekly = nfl.import_weekly_data(list(range(2018, 2025)))\n",
    "    df_seasonal = nfl.import_seasonal_data(list(range(2017,2024)))\n",
    "    df_schedule = nfl.import_schedules(list(range(2018, 2025)))\n",
    "    df_pass_pfr = nfl.import_weekly_pfr('pass', list(range(2018, 2025)))\n",
    "    df_rush_pfr = nfl.import_weekly_pfr('rush', list(range(2018, 2025)))\n",
    "    df_rec_pfr = nfl.import_weekly_pfr('rec', list(range(2018, 2025)))\n",
    "    df_pass_ngs = nfl.import_ngs_data('passing',list(range(2018, 2025)))\n",
    "    df_rush_ngs = nfl.import_ngs_data('rushing',list(range(2018, 2025)))\n",
    "    df_snap_counts = nfl.import_snap_counts(list(range(2018, 2025)))\n",
    "\n",
    "    df_weekly = df_weekly[(df_weekly['season_type'] == 'REG') & (df_weekly['position'].isin(['QB', 'WR', 'RB', 'TE']))].reset_index()\n",
    "\n",
    "    df_seasonal['season'] = df_seasonal['season'] + 1\n",
    "\n",
    "    df_schedule = df_schedule[['game_id', 'home_team', 'home_score', 'away_score']].drop_duplicates()\n",
    "    df_schedule['game_id'] = df_schedule['game_id'].str.replace('OAK', 'LV', regex=False) # Umzug der Oakland Raiders nach Las Vegas in der Saison 2020\n",
    "    df_schedule['home_team'] = df_schedule['home_team'].str.replace('OAK', 'LV', regex=False) # Umzug der Oakland Raiders nach Las Vegas in der Saison 2020\n",
    "\n",
    "    df_weekly['game_id_home_away'] = df_weekly['season'].astype(str) + '_' + df_weekly['week'].apply(lambda x: f\"{x:02d}\")+'_'+df_weekly['recent_team']+'_'+df_weekly['opponent_team']\n",
    "    df_weekly['game_id_away_home'] = df_weekly['season'].astype(str) + '_' + df_weekly['week'].apply(lambda x: f\"{x:02d}\")+'_'+df_weekly['opponent_team']+'_'+df_weekly['recent_team']\n",
    "\n",
    "    df_merged = pd.melt(\n",
    "        df_weekly,\n",
    "        id_vars=['player_id', 'position', 'season', 'week', 'recent_team', 'opponent_team', 'completions', 'attempts', 'passing_yards', 'passing_tds', 'passing_2pt_conversions', 'interceptions', 'sack_fumbles_lost', 'sacks', 'sack_yards', 'passing_air_yards', 'passing_epa', 'pacr', 'carries', 'rushing_yards', 'rushing_tds', 'rushing_2pt_conversions', 'rushing_fumbles_lost', 'rushing_epa', 'receptions', 'targets', 'receiving_yards', 'receiving_tds', 'receiving_2pt_conversions', 'receiving_fumbles_lost', 'racr', 'wopr', 'receiving_epa', 'fantasy_points'],\n",
    "        value_vars=['game_id_home_away', 'game_id_away_home'],\n",
    "        var_name='game_id_type',\n",
    "        value_name='game_id'\n",
    "    )\n",
    "\n",
    "    df_ids = df_ids.rename(columns={'gsis_id': 'player_id', 'pfr_id': 'pfr_player_id'})\n",
    "    df_pass_ngs = df_pass_ngs.rename(columns={'player_gsis_id': 'player_id'})\n",
    "    df_rush_ngs = df_rush_ngs.rename(columns={'player_gsis_id': 'player_id'})\n",
    "\n",
    "    df_merged = pd.merge(df_merged, df_schedule, on='game_id', how='inner') # Bei ein paar Spielen: recent_team = opponent_team\n",
    "    df_merged = pd.merge(df_merged, df_ids[['player_id', 'pfr_player_id', 'draft_pick', 'draft_year']], on = 'player_id', how = 'inner') # Ein paar Spieler ohne draft_year\n",
    "    df_merged = pd.merge(df_merged, df_seasonal[['player_id', 'season', 'dom']], on = ['player_id', 'season'], how = 'left')\n",
    "    df_merged = pd.merge(df_merged, df_pass_pfr[['pfr_player_id', 'season', 'week', 'passing_bad_throws', 'times_pressured']], on = ['pfr_player_id', 'season', 'week'], how = 'left')\n",
    "    df_merged = pd.merge(df_merged, df_rec_pfr[['pfr_player_id', 'season', 'week', 'receiving_rat']], on = ['pfr_player_id', 'season', 'week'], how = 'left')\n",
    "    df_merged = pd.merge(df_merged, df_rush_pfr[['pfr_player_id', 'season', 'week', 'rushing_broken_tackles']], on = ['pfr_player_id', 'season', 'week'], how = 'left')\n",
    "    df_merged = pd.merge(df_merged, df_pass_ngs[['player_id', 'season', 'week', 'passer_rating', 'aggressiveness']], on = ['player_id', 'season', 'week'], how = 'left')\n",
    "    df_merged = pd.merge(df_merged, df_rush_ngs[['player_id', 'season', 'week', 'efficiency']], on = ['player_id', 'season', 'week'], how = 'left')\n",
    "    df_merged = pd.merge(df_merged, df_snap_counts[['pfr_player_id', 'season', 'week', 'offense_snaps']], on = ['pfr_player_id', 'season', 'week'], how = 'left')\n",
    "\n",
    "    df_merged = df_merged.drop(columns=['game_id_type', 'pfr_player_id'])\n",
    "\n",
    "    df_merged['draft_pick'] = df_merged['draft_pick'].fillna(260)\n",
    "    df_merged = df_merged.fillna(0)\n",
    "\n",
    "    df_merged['rookie_flag'] = (df_merged['season'] == df_merged['draft_year']).astype(int)\n",
    "    df_merged['last_season_data_flag'] = (df_merged['week'] < 6).astype(int)\n",
    "    df_merged['home'] = (df_merged['home_team'] == df_merged['recent_team']).astype(int)\n",
    "    df_merged['player_id'] = df_merged['player_id'].str.replace('00-00', '').astype(int)\n",
    "\n",
    "    # interceptions und fumbles als eigene features statt als turnover aggregiert\n",
    "    df_merged['turnover'] = (\n",
    "        df_merged['interceptions'] +\n",
    "        df_merged['sack_fumbles_lost'] +\n",
    "        df_merged['rushing_fumbles_lost'] +\n",
    "        df_merged['receiving_fumbles_lost']\n",
    "    )\n",
    "\n",
    "    # total epa aggregiert statt passing, rushing und receiving einzeln\n",
    "    df_merged['epa_total'] = (\n",
    "        df_merged['passing_epa'] + \n",
    "        df_merged['rushing_epa'] + \n",
    "        df_merged['receiving_epa']\n",
    "    )\n",
    "\n",
    "    # total points aggregiert statt passing, rushing und receiving tds und 2pt conversions einzeln\n",
    "    df_merged['points_total'] = (\n",
    "        (df_merged['rushing_tds'] * 6) + \n",
    "        (df_merged['rushing_2pt_conversions'] * 2) + \n",
    "        (df_merged['receiving_tds'] * 6) + \n",
    "        (df_merged['receiving_2pt_conversions'] * 2) + \n",
    "        (df_merged['passing_tds'] * 6) + \n",
    "        (df_merged['passing_2pt_conversions'] * 2)\n",
    "    )\n",
    "\n",
    "    # total yards aggregiert statt passing, rushing und receiving einzeln\n",
    "    df_merged['yards_total'] = (\n",
    "        df_merged['passing_yards'] +\n",
    "        df_merged['rushing_yards'] +\n",
    "        df_merged['receiving_yards']\n",
    "    )\n",
    "\n",
    "    # position target-encoded\n",
    "    position_means = df_merged.groupby(['position', 'season', 'week'])['fantasy_points'].mean().reset_index()\n",
    "    position_means.rename(columns={'fantasy_points': 'position_encoded'}, inplace=True)\n",
    "    df_merged = pd.merge(df_merged, position_means, on=['position', 'season', 'week'], how='left')\n",
    "\n",
    "    # points_scored und points_allowed als Ma√üstab f√ºr St√§rke eines Teams\n",
    "    df_merged['recent_team_points_scored'] = df_merged.apply(lambda row: row['home_score'] if row['home'] == 1 else row['away_score'], axis=1)\n",
    "    df_merged['opponent_team_points_allowed'] = df_merged['recent_team_points_scored']\n",
    "\n",
    "    df_unique_opponent_team_points_allowed = df_merged.drop_duplicates(subset=['game_id', 'opponent_team', 'opponent_team_points_allowed'])\n",
    "    df_unique_recent_team_points_scored = df_merged.drop_duplicates(subset=['game_id', 'recent_team', 'recent_team_points_scored'])\n",
    "\n",
    "    df_unique_opponent_team_points_allowed = df_unique_opponent_team_points_allowed.sort_values(by=['opponent_team', 'season', 'week']).reset_index(drop=True)\n",
    "    df_unique_recent_team_points_scored = df_unique_recent_team_points_scored.sort_values(by=['recent_team', 'season', 'week']).reset_index(drop=True)\n",
    "\n",
    "    df_unique_opponent_team_points_allowed['ewm_opponent_team_points_allowed_l5w'] = (\n",
    "        df_unique_opponent_team_points_allowed.groupby('opponent_team')['opponent_team_points_allowed']\n",
    "        .apply(lambda x: x.shift(1).ewm(span=5, min_periods=5).mean())\n",
    "        .reset_index(level=0, drop=True)\n",
    "    )\n",
    "\n",
    "    for metric in ['mean', 'median', 'std']:\n",
    "            df_unique_opponent_team_points_allowed[f\"{metric}_opponent_team_points_allowed_l5w\"] = (\n",
    "                df_unique_opponent_team_points_allowed.groupby('opponent_team')['opponent_team_points_allowed']\n",
    "                .apply(lambda x: x.shift(1).rolling(window=5, min_periods=5).agg(metric))  # shift(1) schlie√üt aktuelle Woche aus\n",
    "                .reset_index(level=0, drop=True)  # Index zur√ºcksetzen\n",
    "        )\n",
    "\n",
    "    for metric in ['min', 'max']:\n",
    "            df_unique_opponent_team_points_allowed[f\"{metric}_opponent_team_points_allowed_l3w\"] = (\n",
    "                df_unique_opponent_team_points_allowed.groupby('opponent_team')['opponent_team_points_allowed']\n",
    "                .apply(lambda x: x.shift(1).rolling(window=3, min_periods=3).agg(metric))  # shift(1) schlie√üt aktuelle Woche aus\n",
    "                .reset_index(level=0, drop=True)  # Index zur√ºcksetzen\n",
    "        )\n",
    "\n",
    "    df_unique_opponent_team_points_allowed = df_unique_opponent_team_points_allowed.drop(columns=['player_id', 'draft_year', 'turnover', 'interceptions', 'sack_fumbles_lost', 'rushing_fumbles_lost', 'receiving_fumbles_lost', 'points_total', 'rushing_tds', 'rushing_2pt_conversions', 'receiving_tds', 'receiving_2pt_conversions', 'passing_tds', 'passing_2pt_conversions', 'epa_total', 'passing_epa', 'rushing_epa', 'receiving_epa', 'position', 'season', 'week', 'recent_team', 'home_team', 'completions', 'attempts', 'passing_yards', 'sacks', 'sack_yards', 'passing_air_yards', 'pacr', 'carries', 'rushing_yards', 'receptions', 'targets', 'yards_total', 'receiving_yards', 'racr', 'wopr', 'fantasy_points', 'home_score', 'away_score', 'draft_pick', 'dom', 'passing_bad_throws', 'times_pressured', 'receiving_rat', 'rushing_broken_tackles', 'passer_rating', 'aggressiveness', 'efficiency', 'offense_snaps', 'rookie_flag', 'last_season_data_flag', 'home', 'position_encoded', 'recent_team_points_scored', 'opponent_team_points_allowed'])\n",
    "    df_merged = pd.merge(df_merged, df_unique_opponent_team_points_allowed, on=['game_id','opponent_team'], how='inner')\n",
    "\n",
    "    df_unique_recent_team_points_scored['ewm_recent_team_points_scored_l5w'] = (\n",
    "        df_unique_recent_team_points_scored.groupby('recent_team')['recent_team_points_scored']\n",
    "        .apply(lambda x: x.shift(1).ewm(span=5, min_periods=5).mean())\n",
    "        .reset_index(level=0, drop=True)\n",
    "    )\n",
    "\n",
    "    for metric in ['mean', 'median', 'std']:\n",
    "            df_unique_recent_team_points_scored[f\"{metric}_recent_team_points_scored_l5w\"] = (\n",
    "                df_unique_recent_team_points_scored.groupby('recent_team')['recent_team_points_scored']\n",
    "                .apply(lambda x: x.shift(1).rolling(window=5, min_periods=5).agg(metric))  # shift(1) schlie√üt aktuelle Woche aus\n",
    "                .reset_index(level=0, drop=True)  # Index zur√ºcksetzen\n",
    "        )\n",
    "\n",
    "    for metric in ['min', 'max']:\n",
    "            df_unique_recent_team_points_scored[f\"{metric}_recent_team_points_scored_l3w\"] = (\n",
    "                df_unique_recent_team_points_scored.groupby('recent_team')['recent_team_points_scored']\n",
    "                .apply(lambda x: x.shift(1).rolling(window=3, min_periods=3).agg(metric))  # shift(1) schlie√üt aktuelle Woche aus\n",
    "                .reset_index(level=0, drop=True)  # Index zur√ºcksetzen\n",
    "        )\n",
    "\n",
    "    df_unique_recent_team_points_scored = df_unique_recent_team_points_scored.drop(columns=['player_id', 'draft_year', 'turnover', 'interceptions', 'sack_fumbles_lost', 'rushing_fumbles_lost', 'receiving_fumbles_lost', 'points_total', 'rushing_tds', 'rushing_2pt_conversions', 'receiving_tds', 'receiving_2pt_conversions', 'passing_tds', 'passing_2pt_conversions', 'epa_total', 'passing_epa', 'rushing_epa', 'receiving_epa', 'position', 'season', 'week', 'opponent_team', 'home_team', 'completions', 'attempts', 'yards_total', 'passing_yards', 'sacks', 'sack_yards', 'passing_air_yards', 'pacr', 'carries', 'rushing_yards', 'receptions', 'targets', 'receiving_yards', 'racr', 'wopr', 'fantasy_points', 'home_score', 'away_score', 'draft_pick', 'dom', 'passing_bad_throws', 'times_pressured', 'receiving_rat', 'rushing_broken_tackles', 'passer_rating', 'aggressiveness', 'efficiency', 'offense_snaps', 'rookie_flag', 'last_season_data_flag', 'home', 'position_encoded', 'recent_team_points_scored', 'opponent_team_points_allowed'])\n",
    "    df_merged = pd.merge(df_merged, df_unique_recent_team_points_scored, on=['game_id','recent_team'], how='inner')\n",
    "\n",
    "    # Liste der Spalten mit Spielerspezifischen numerischen Daten, f√ºr die Rolling-Features erstellt werden sollen\n",
    "    columns_to_roll = ['completions', 'attempts', 'sacks', 'passer_rating', 'aggressiveness', 'efficiency', 'sack_yards', \n",
    "                    'passing_air_yards', 'pacr', 'carries', 'offense_snaps', 'yards_total', 'receptions', 'targets',\n",
    "                    'racr', 'wopr', 'fantasy_points', 'passing_bad_throws', 'times_pressured', 'position_encoded', 'receiving_rat', \n",
    "                    'rushing_broken_tackles', 'turnover', 'points_total', 'epa_total']\n",
    "\n",
    "\n",
    "    # Sortiere nach player_id, season und week\n",
    "    df_merged = df_merged.sort_values(by=['player_id', 'season', 'week']).reset_index(drop=True)\n",
    "\n",
    "\n",
    "    df_merged['cnt_games_over_20ffpts_l5w'] = (\n",
    "        df_merged.groupby('player_id')['fantasy_points']\n",
    "        .apply(lambda x: x.shift(1).rolling(window=5, min_periods=5).apply(lambda y: (y > 20).sum()))\n",
    "        .reset_index(level=0, drop=True)\n",
    "    )\n",
    "\n",
    "    # Rolling-Features erstellen\n",
    "    for col in columns_to_roll:\n",
    "\n",
    "        feature_name_1 = f\"ewm_{col}_l5w\"\n",
    "        df_merged[feature_name_1] = (\n",
    "            df_merged.groupby('player_id')[col]\n",
    "            .apply(lambda x: x.shift(1).ewm(span=5, min_periods=5).mean())\n",
    "            .reset_index(level=0, drop=True)\n",
    "        )\n",
    "\n",
    "        for metric in ['mean', 'median', 'std']:\n",
    "            feature_name_2 = f\"{metric}_{col}_l5w\"\n",
    "            rolling_result_5w = (\n",
    "                df_merged.groupby('player_id')[col]\n",
    "                    .apply(lambda x: x.shift(1).rolling(window=5, min_periods=5).agg(metric))  # shift(1) schlie√üt aktuelle Woche aus\n",
    "                    .reset_index(level=0, drop=True)  # Index zur√ºcksetzen\n",
    "            )\n",
    "            # Einf√ºgen der Rolling-Metrik\n",
    "            df_merged[feature_name_2] = rolling_result_5w\n",
    "\n",
    "        for metric in ['max', 'min']:\n",
    "            feature_name_3 = f\"{metric}_{col}_l3w\"\n",
    "            # Berechnung der Rolling-Metrik (ohne aktuelle Woche)\n",
    "            rolling_result_3w = (\n",
    "                df_merged.groupby('player_id')[col]\n",
    "                    .apply(lambda x: x.shift(1).rolling(window=3, min_periods=3).agg(metric))  # shift(1) schlie√üt aktuelle Woche aus\n",
    "                    .reset_index(level=0, drop=True)  # Index zur√ºcksetzen\n",
    "            )\n",
    "            # Einf√ºgen der Rolling-Metrik\n",
    "            df_merged[feature_name_3] = rolling_result_3w\n",
    "\n",
    "    df_merged = df_merged.drop(columns=['completions', 'attempts', 'passing_yards', 'sacks', 'sack_yards', 'passing_air_yards', 'pacr', 'carries', \n",
    "                                        'rushing_yards', 'receptions', 'targets', 'receiving_yards', 'racr', 'wopr', 'passing_bad_throws', \n",
    "                                        'times_pressured', 'receiving_rat', 'rushing_broken_tackles', 'draft_year', 'home_team', \n",
    "                                        'passer_rating', 'aggressiveness', 'efficiency', 'offense_snaps', 'game_id',  'interceptions', 'sack_fumbles_lost', \n",
    "                                        'rushing_fumbles_lost', 'receiving_fumbles_lost', 'rushing_tds', 'rushing_2pt_conversions', 'receiving_tds', \n",
    "                                        'receiving_2pt_conversions', 'passing_tds', 'passing_2pt_conversions', 'passing_epa', 'rushing_epa', 'receiving_epa',\n",
    "                                        'position_encoded', 'recent_team', 'opponent_team', 'position', 'home_score', 'away_score',\n",
    "                                        'recent_team_points_scored', 'opponent_team_points_allowed', 'turnover', 'points_total', 'yards_total',\n",
    "                                        'epa_total'])\n",
    "\n",
    "    df_merged = df_merged.dropna().reset_index()\n",
    "\n",
    "    return df_merged\n",
    "\n",
    "df_2 = load_merge_edit_data_2()\n",
    "\n",
    "df_2.info()\n",
    "print(df_2.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downcasting floats.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/sn/54gnf37x14l2fsfqr_hj0dnc0000gn/T/ipykernel_6060/3064007903.py:192: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_merged[feature_name_3] = rolling_result_3w\n",
      "/var/folders/sn/54gnf37x14l2fsfqr_hj0dnc0000gn/T/ipykernel_6060/3064007903.py:192: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_merged[feature_name_3] = rolling_result_3w\n",
      "/var/folders/sn/54gnf37x14l2fsfqr_hj0dnc0000gn/T/ipykernel_6060/3064007903.py:170: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_merged[feature_name_1] = (\n",
      "/var/folders/sn/54gnf37x14l2fsfqr_hj0dnc0000gn/T/ipykernel_6060/3064007903.py:177: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_merged[feature_name_2] = (\n",
      "/var/folders/sn/54gnf37x14l2fsfqr_hj0dnc0000gn/T/ipykernel_6060/3064007903.py:192: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_merged[feature_name_3] = rolling_result_3w\n",
      "/var/folders/sn/54gnf37x14l2fsfqr_hj0dnc0000gn/T/ipykernel_6060/3064007903.py:192: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_merged[feature_name_3] = rolling_result_3w\n",
      "/var/folders/sn/54gnf37x14l2fsfqr_hj0dnc0000gn/T/ipykernel_6060/3064007903.py:170: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_merged[feature_name_1] = (\n",
      "/var/folders/sn/54gnf37x14l2fsfqr_hj0dnc0000gn/T/ipykernel_6060/3064007903.py:177: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_merged[feature_name_2] = (\n",
      "/var/folders/sn/54gnf37x14l2fsfqr_hj0dnc0000gn/T/ipykernel_6060/3064007903.py:192: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_merged[feature_name_3] = rolling_result_3w\n",
      "/var/folders/sn/54gnf37x14l2fsfqr_hj0dnc0000gn/T/ipykernel_6060/3064007903.py:192: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_merged[feature_name_3] = rolling_result_3w\n",
      "/var/folders/sn/54gnf37x14l2fsfqr_hj0dnc0000gn/T/ipykernel_6060/3064007903.py:170: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_merged[feature_name_1] = (\n",
      "/var/folders/sn/54gnf37x14l2fsfqr_hj0dnc0000gn/T/ipykernel_6060/3064007903.py:177: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_merged[feature_name_2] = (\n",
      "/var/folders/sn/54gnf37x14l2fsfqr_hj0dnc0000gn/T/ipykernel_6060/3064007903.py:192: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_merged[feature_name_3] = rolling_result_3w\n",
      "/var/folders/sn/54gnf37x14l2fsfqr_hj0dnc0000gn/T/ipykernel_6060/3064007903.py:192: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_merged[feature_name_3] = rolling_result_3w\n",
      "/var/folders/sn/54gnf37x14l2fsfqr_hj0dnc0000gn/T/ipykernel_6060/3064007903.py:170: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_merged[feature_name_1] = (\n",
      "/var/folders/sn/54gnf37x14l2fsfqr_hj0dnc0000gn/T/ipykernel_6060/3064007903.py:177: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_merged[feature_name_2] = (\n",
      "/var/folders/sn/54gnf37x14l2fsfqr_hj0dnc0000gn/T/ipykernel_6060/3064007903.py:192: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_merged[feature_name_3] = rolling_result_3w\n",
      "/var/folders/sn/54gnf37x14l2fsfqr_hj0dnc0000gn/T/ipykernel_6060/3064007903.py:192: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_merged[feature_name_3] = rolling_result_3w\n",
      "/var/folders/sn/54gnf37x14l2fsfqr_hj0dnc0000gn/T/ipykernel_6060/3064007903.py:170: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_merged[feature_name_1] = (\n",
      "/var/folders/sn/54gnf37x14l2fsfqr_hj0dnc0000gn/T/ipykernel_6060/3064007903.py:177: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_merged[feature_name_2] = (\n",
      "/var/folders/sn/54gnf37x14l2fsfqr_hj0dnc0000gn/T/ipykernel_6060/3064007903.py:192: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_merged[feature_name_3] = rolling_result_3w\n",
      "/var/folders/sn/54gnf37x14l2fsfqr_hj0dnc0000gn/T/ipykernel_6060/3064007903.py:192: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_merged[feature_name_3] = rolling_result_3w\n",
      "/var/folders/sn/54gnf37x14l2fsfqr_hj0dnc0000gn/T/ipykernel_6060/3064007903.py:170: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_merged[feature_name_1] = (\n",
      "/var/folders/sn/54gnf37x14l2fsfqr_hj0dnc0000gn/T/ipykernel_6060/3064007903.py:177: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_merged[feature_name_2] = (\n",
      "/var/folders/sn/54gnf37x14l2fsfqr_hj0dnc0000gn/T/ipykernel_6060/3064007903.py:192: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_merged[feature_name_3] = rolling_result_3w\n",
      "/var/folders/sn/54gnf37x14l2fsfqr_hj0dnc0000gn/T/ipykernel_6060/3064007903.py:192: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_merged[feature_name_3] = rolling_result_3w\n",
      "/var/folders/sn/54gnf37x14l2fsfqr_hj0dnc0000gn/T/ipykernel_6060/3064007903.py:170: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_merged[feature_name_1] = (\n",
      "/var/folders/sn/54gnf37x14l2fsfqr_hj0dnc0000gn/T/ipykernel_6060/3064007903.py:177: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_merged[feature_name_2] = (\n",
      "/var/folders/sn/54gnf37x14l2fsfqr_hj0dnc0000gn/T/ipykernel_6060/3064007903.py:192: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_merged[feature_name_3] = rolling_result_3w\n",
      "/var/folders/sn/54gnf37x14l2fsfqr_hj0dnc0000gn/T/ipykernel_6060/3064007903.py:192: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_merged[feature_name_3] = rolling_result_3w\n",
      "/var/folders/sn/54gnf37x14l2fsfqr_hj0dnc0000gn/T/ipykernel_6060/3064007903.py:170: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_merged[feature_name_1] = (\n",
      "/var/folders/sn/54gnf37x14l2fsfqr_hj0dnc0000gn/T/ipykernel_6060/3064007903.py:177: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_merged[feature_name_2] = (\n",
      "/var/folders/sn/54gnf37x14l2fsfqr_hj0dnc0000gn/T/ipykernel_6060/3064007903.py:192: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_merged[feature_name_3] = rolling_result_3w\n",
      "/var/folders/sn/54gnf37x14l2fsfqr_hj0dnc0000gn/T/ipykernel_6060/3064007903.py:192: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_merged[feature_name_3] = rolling_result_3w\n",
      "/var/folders/sn/54gnf37x14l2fsfqr_hj0dnc0000gn/T/ipykernel_6060/3064007903.py:170: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_merged[feature_name_1] = (\n",
      "/var/folders/sn/54gnf37x14l2fsfqr_hj0dnc0000gn/T/ipykernel_6060/3064007903.py:177: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_merged[feature_name_2] = (\n",
      "/var/folders/sn/54gnf37x14l2fsfqr_hj0dnc0000gn/T/ipykernel_6060/3064007903.py:192: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_merged[feature_name_3] = rolling_result_3w\n",
      "/var/folders/sn/54gnf37x14l2fsfqr_hj0dnc0000gn/T/ipykernel_6060/3064007903.py:192: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_merged[feature_name_3] = rolling_result_3w\n",
      "/var/folders/sn/54gnf37x14l2fsfqr_hj0dnc0000gn/T/ipykernel_6060/3064007903.py:170: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_merged[feature_name_1] = (\n",
      "/var/folders/sn/54gnf37x14l2fsfqr_hj0dnc0000gn/T/ipykernel_6060/3064007903.py:177: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_merged[feature_name_2] = (\n",
      "/var/folders/sn/54gnf37x14l2fsfqr_hj0dnc0000gn/T/ipykernel_6060/3064007903.py:192: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_merged[feature_name_3] = rolling_result_3w\n",
      "/var/folders/sn/54gnf37x14l2fsfqr_hj0dnc0000gn/T/ipykernel_6060/3064007903.py:192: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_merged[feature_name_3] = rolling_result_3w\n",
      "/var/folders/sn/54gnf37x14l2fsfqr_hj0dnc0000gn/T/ipykernel_6060/3064007903.py:170: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_merged[feature_name_1] = (\n",
      "/var/folders/sn/54gnf37x14l2fsfqr_hj0dnc0000gn/T/ipykernel_6060/3064007903.py:177: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_merged[feature_name_2] = (\n",
      "/var/folders/sn/54gnf37x14l2fsfqr_hj0dnc0000gn/T/ipykernel_6060/3064007903.py:192: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_merged[feature_name_3] = rolling_result_3w\n",
      "/var/folders/sn/54gnf37x14l2fsfqr_hj0dnc0000gn/T/ipykernel_6060/3064007903.py:192: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_merged[feature_name_3] = rolling_result_3w\n",
      "/var/folders/sn/54gnf37x14l2fsfqr_hj0dnc0000gn/T/ipykernel_6060/3064007903.py:170: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_merged[feature_name_1] = (\n",
      "/var/folders/sn/54gnf37x14l2fsfqr_hj0dnc0000gn/T/ipykernel_6060/3064007903.py:177: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_merged[feature_name_2] = (\n",
      "/var/folders/sn/54gnf37x14l2fsfqr_hj0dnc0000gn/T/ipykernel_6060/3064007903.py:192: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_merged[feature_name_3] = rolling_result_3w\n",
      "/var/folders/sn/54gnf37x14l2fsfqr_hj0dnc0000gn/T/ipykernel_6060/3064007903.py:192: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_merged[feature_name_3] = rolling_result_3w\n",
      "/var/folders/sn/54gnf37x14l2fsfqr_hj0dnc0000gn/T/ipykernel_6060/3064007903.py:170: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_merged[feature_name_1] = (\n",
      "/var/folders/sn/54gnf37x14l2fsfqr_hj0dnc0000gn/T/ipykernel_6060/3064007903.py:177: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_merged[feature_name_2] = (\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 30183 entries, 0 to 30182\n",
      "Columns: 167 entries, index to min_receiving_epa_l3w\n",
      "dtypes: float32(1), float64(159), int32(2), int64(5)\n",
      "memory usage: 38.1 MB\n",
      "index                                      0\n",
      "player_id                                  0\n",
      "season                                     0\n",
      "week                                       0\n",
      "fantasy_points                             0\n",
      "draft_pick                                 0\n",
      "dom                                        0\n",
      "rookie_flag                                0\n",
      "last_season_data_flag                      0\n",
      "home                                       0\n",
      "ewm_opponent_team_points_allowed_l5w       0\n",
      "median_opponent_team_points_allowed_l5w    0\n",
      "min_opponent_team_points_allowed_l3w       0\n",
      "max_opponent_team_points_allowed_l3w       0\n",
      "ewm_recent_team_points_scored_l5w          0\n",
      "median_recent_team_points_scored_l5w       0\n",
      "min_recent_team_points_scored_l3w          0\n",
      "max_recent_team_points_scored_l3w          0\n",
      "cnt_games_over_20ffpts_l5w                 0\n",
      "ewm_completions_l5w                        0\n",
      "median_completions_l5w                     0\n",
      "max_completions_l3w                        0\n",
      "min_completions_l3w                        0\n",
      "ewm_attempts_l5w                           0\n",
      "median_attempts_l5w                        0\n",
      "max_attempts_l3w                           0\n",
      "min_attempts_l3w                           0\n",
      "ewm_passing_yards_l5w                      0\n",
      "median_passing_yards_l5w                   0\n",
      "max_passing_yards_l3w                      0\n",
      "min_passing_yards_l3w                      0\n",
      "ewm_sacks_l5w                              0\n",
      "median_sacks_l5w                           0\n",
      "max_sacks_l3w                              0\n",
      "min_sacks_l3w                              0\n",
      "ewm_passer_rating_l5w                      0\n",
      "median_passer_rating_l5w                   0\n",
      "max_passer_rating_l3w                      0\n",
      "min_passer_rating_l3w                      0\n",
      "ewm_aggressiveness_l5w                     0\n",
      "median_aggressiveness_l5w                  0\n",
      "max_aggressiveness_l3w                     0\n",
      "min_aggressiveness_l3w                     0\n",
      "ewm_efficiency_l5w                         0\n",
      "median_efficiency_l5w                      0\n",
      "max_efficiency_l3w                         0\n",
      "min_efficiency_l3w                         0\n",
      "ewm_sack_yards_l5w                         0\n",
      "median_sack_yards_l5w                      0\n",
      "max_sack_yards_l3w                         0\n",
      "min_sack_yards_l3w                         0\n",
      "ewm_passing_air_yards_l5w                  0\n",
      "median_passing_air_yards_l5w               0\n",
      "max_passing_air_yards_l3w                  0\n",
      "min_passing_air_yards_l3w                  0\n",
      "ewm_pacr_l5w                               0\n",
      "median_pacr_l5w                            0\n",
      "max_pacr_l3w                               0\n",
      "min_pacr_l3w                               0\n",
      "ewm_carries_l5w                            0\n",
      "median_carries_l5w                         0\n",
      "max_carries_l3w                            0\n",
      "min_carries_l3w                            0\n",
      "ewm_offense_snaps_l5w                      0\n",
      "median_offense_snaps_l5w                   0\n",
      "max_offense_snaps_l3w                      0\n",
      "min_offense_snaps_l3w                      0\n",
      "ewm_rushing_yards_l5w                      0\n",
      "median_rushing_yards_l5w                   0\n",
      "max_rushing_yards_l3w                      0\n",
      "min_rushing_yards_l3w                      0\n",
      "ewm_receptions_l5w                         0\n",
      "median_receptions_l5w                      0\n",
      "max_receptions_l3w                         0\n",
      "min_receptions_l3w                         0\n",
      "ewm_targets_l5w                            0\n",
      "median_targets_l5w                         0\n",
      "max_targets_l3w                            0\n",
      "min_targets_l3w                            0\n",
      "ewm_receiving_yards_l5w                    0\n",
      "median_receiving_yards_l5w                 0\n",
      "max_receiving_yards_l3w                    0\n",
      "min_receiving_yards_l3w                    0\n",
      "ewm_racr_l5w                               0\n",
      "median_racr_l5w                            0\n",
      "max_racr_l3w                               0\n",
      "min_racr_l3w                               0\n",
      "ewm_wopr_l5w                               0\n",
      "median_wopr_l5w                            0\n",
      "max_wopr_l3w                               0\n",
      "min_wopr_l3w                               0\n",
      "ewm_fantasy_points_l5w                     0\n",
      "median_fantasy_points_l5w                  0\n",
      "max_fantasy_points_l3w                     0\n",
      "min_fantasy_points_l3w                     0\n",
      "ewm_passing_bad_throws_l5w                 0\n",
      "median_passing_bad_throws_l5w              0\n",
      "max_passing_bad_throws_l3w                 0\n",
      "min_passing_bad_throws_l3w                 0\n",
      "ewm_times_pressured_l5w                    0\n",
      "median_times_pressured_l5w                 0\n",
      "max_times_pressured_l3w                    0\n",
      "min_times_pressured_l3w                    0\n",
      "ewm_position_encoded_l5w                   0\n",
      "median_position_encoded_l5w                0\n",
      "max_position_encoded_l3w                   0\n",
      "min_position_encoded_l3w                   0\n",
      "ewm_receiving_rat_l5w                      0\n",
      "median_receiving_rat_l5w                   0\n",
      "max_receiving_rat_l3w                      0\n",
      "min_receiving_rat_l3w                      0\n",
      "ewm_rushing_broken_tackles_l5w             0\n",
      "median_rushing_broken_tackles_l5w          0\n",
      "max_rushing_broken_tackles_l3w             0\n",
      "min_rushing_broken_tackles_l3w             0\n",
      "ewm_interceptions_l5w                      0\n",
      "median_interceptions_l5w                   0\n",
      "max_interceptions_l3w                      0\n",
      "min_interceptions_l3w                      0\n",
      "ewm_sack_fumbles_lost_l5w                  0\n",
      "median_sack_fumbles_lost_l5w               0\n",
      "max_sack_fumbles_lost_l3w                  0\n",
      "min_sack_fumbles_lost_l3w                  0\n",
      "ewm_rushing_fumbles_lost_l5w               0\n",
      "median_rushing_fumbles_lost_l5w            0\n",
      "max_rushing_fumbles_lost_l3w               0\n",
      "min_rushing_fumbles_lost_l3w               0\n",
      "ewm_receiving_fumbles_lost_l5w             0\n",
      "median_receiving_fumbles_lost_l5w          0\n",
      "max_receiving_fumbles_lost_l3w             0\n",
      "min_receiving_fumbles_lost_l3w             0\n",
      "ewm_rushing_tds_l5w                        0\n",
      "median_rushing_tds_l5w                     0\n",
      "max_rushing_tds_l3w                        0\n",
      "min_rushing_tds_l3w                        0\n",
      "ewm_rushing_2pt_conversions_l5w            0\n",
      "median_rushing_2pt_conversions_l5w         0\n",
      "max_rushing_2pt_conversions_l3w            0\n",
      "min_rushing_2pt_conversions_l3w            0\n",
      "ewm_receiving_tds_l5w                      0\n",
      "median_receiving_tds_l5w                   0\n",
      "max_receiving_tds_l3w                      0\n",
      "min_receiving_tds_l3w                      0\n",
      "ewm_receiving_2pt_conversions_l5w          0\n",
      "median_receiving_2pt_conversions_l5w       0\n",
      "max_receiving_2pt_conversions_l3w          0\n",
      "min_receiving_2pt_conversions_l3w          0\n",
      "ewm_passing_tds_l5w                        0\n",
      "median_passing_tds_l5w                     0\n",
      "max_passing_tds_l3w                        0\n",
      "min_passing_tds_l3w                        0\n",
      "ewm_passing_2pt_conversions_l5w            0\n",
      "median_passing_2pt_conversions_l5w         0\n",
      "max_passing_2pt_conversions_l3w            0\n",
      "min_passing_2pt_conversions_l3w            0\n",
      "ewm_passing_epa_l5w                        0\n",
      "median_passing_epa_l5w                     0\n",
      "max_passing_epa_l3w                        0\n",
      "min_passing_epa_l3w                        0\n",
      "ewm_rushing_epa_l5w                        0\n",
      "median_rushing_epa_l5w                     0\n",
      "max_rushing_epa_l3w                        0\n",
      "min_rushing_epa_l3w                        0\n",
      "ewm_receiving_epa_l5w                      0\n",
      "median_receiving_epa_l5w                   0\n",
      "max_receiving_epa_l3w                      0\n",
      "min_receiving_epa_l3w                      0\n",
      "dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/sn/54gnf37x14l2fsfqr_hj0dnc0000gn/T/ipykernel_6060/3064007903.py:192: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_merged[feature_name_3] = rolling_result_3w\n",
      "/var/folders/sn/54gnf37x14l2fsfqr_hj0dnc0000gn/T/ipykernel_6060/3064007903.py:192: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_merged[feature_name_3] = rolling_result_3w\n"
     ]
    }
   ],
   "source": [
    "# Positionsspezifische Stats nicht zusammengefasst (passing, rushing und receiving jeweils eigene features)\n",
    "# Nur ausgew√§hlte Metriken ewm, median/mean, min, max\n",
    "\n",
    "def load_merge_edit_data_3():   \n",
    "\n",
    "    df_ids = nfl.import_ids()\n",
    "    df_weekly = nfl.import_weekly_data(list(range(2018, 2025)))\n",
    "    df_seasonal = nfl.import_seasonal_data(list(range(2017,2024)))\n",
    "    df_schedule = nfl.import_schedules(list(range(2018, 2025)))\n",
    "    df_pass_pfr = nfl.import_weekly_pfr('pass', list(range(2018, 2025)))\n",
    "    df_rush_pfr = nfl.import_weekly_pfr('rush', list(range(2018, 2025)))\n",
    "    df_rec_pfr = nfl.import_weekly_pfr('rec', list(range(2018, 2025)))\n",
    "    df_pass_ngs = nfl.import_ngs_data('passing',list(range(2018, 2025)))\n",
    "    df_rush_ngs = nfl.import_ngs_data('rushing',list(range(2018, 2025)))\n",
    "    df_snap_counts = nfl.import_snap_counts(list(range(2018, 2025)))\n",
    "\n",
    "    df_weekly = df_weekly[(df_weekly['season_type'] == 'REG') & (df_weekly['position'].isin(['QB', 'WR', 'RB', 'TE']))].reset_index()\n",
    "\n",
    "    df_seasonal['season'] = df_seasonal['season'] + 1\n",
    "\n",
    "    df_schedule = df_schedule[['game_id', 'home_team', 'home_score', 'away_score']].drop_duplicates()\n",
    "    df_schedule['game_id'] = df_schedule['game_id'].str.replace('OAK', 'LV', regex=False) # Umzug der Oakland Raiders nach Las Vegas in der Saison 2020\n",
    "    df_schedule['home_team'] = df_schedule['home_team'].str.replace('OAK', 'LV', regex=False) # Umzug der Oakland Raiders nach Las Vegas in der Saison 2020\n",
    "\n",
    "    df_weekly['game_id_home_away'] = df_weekly['season'].astype(str) + '_' + df_weekly['week'].apply(lambda x: f\"{x:02d}\")+'_'+df_weekly['recent_team']+'_'+df_weekly['opponent_team']\n",
    "    df_weekly['game_id_away_home'] = df_weekly['season'].astype(str) + '_' + df_weekly['week'].apply(lambda x: f\"{x:02d}\")+'_'+df_weekly['opponent_team']+'_'+df_weekly['recent_team']\n",
    "\n",
    "    df_merged = pd.melt(\n",
    "        df_weekly,\n",
    "        id_vars=['player_id', 'position', 'season', 'week', 'recent_team', 'opponent_team', 'completions', 'attempts', 'passing_yards', 'passing_tds', 'passing_2pt_conversions', 'interceptions', 'sack_fumbles_lost', 'sacks', 'sack_yards', 'passing_air_yards', 'passing_epa', 'pacr', 'carries', 'rushing_yards', 'rushing_tds', 'rushing_2pt_conversions', 'rushing_fumbles_lost', 'rushing_epa', 'receptions', 'targets', 'receiving_yards', 'receiving_tds', 'receiving_2pt_conversions', 'receiving_fumbles_lost', 'racr', 'wopr', 'receiving_epa', 'fantasy_points'],\n",
    "        value_vars=['game_id_home_away', 'game_id_away_home'],\n",
    "        var_name='game_id_type',\n",
    "        value_name='game_id'\n",
    "    )\n",
    "\n",
    "    df_ids = df_ids.rename(columns={'gsis_id': 'player_id', 'pfr_id': 'pfr_player_id'})\n",
    "    df_pass_ngs = df_pass_ngs.rename(columns={'player_gsis_id': 'player_id'})\n",
    "    df_rush_ngs = df_rush_ngs.rename(columns={'player_gsis_id': 'player_id'})\n",
    "\n",
    "    df_merged = pd.merge(df_merged, df_schedule, on='game_id', how='inner') # Bei ein paar Spielen: recent_team = opponent_team\n",
    "    df_merged = pd.merge(df_merged, df_ids[['player_id', 'pfr_player_id', 'draft_pick', 'draft_year']], on = 'player_id', how = 'inner') # Ein paar Spieler ohne draft_year\n",
    "    df_merged = pd.merge(df_merged, df_seasonal[['player_id', 'season', 'dom']], on = ['player_id', 'season'], how = 'left')\n",
    "    df_merged = pd.merge(df_merged, df_pass_pfr[['pfr_player_id', 'season', 'week', 'passing_bad_throws', 'times_pressured']], on = ['pfr_player_id', 'season', 'week'], how = 'left')\n",
    "    df_merged = pd.merge(df_merged, df_rec_pfr[['pfr_player_id', 'season', 'week', 'receiving_rat']], on = ['pfr_player_id', 'season', 'week'], how = 'left')\n",
    "    df_merged = pd.merge(df_merged, df_rush_pfr[['pfr_player_id', 'season', 'week', 'rushing_broken_tackles']], on = ['pfr_player_id', 'season', 'week'], how = 'left')\n",
    "    df_merged = pd.merge(df_merged, df_pass_ngs[['player_id', 'season', 'week', 'passer_rating', 'aggressiveness']], on = ['player_id', 'season', 'week'], how = 'left')\n",
    "    df_merged = pd.merge(df_merged, df_rush_ngs[['player_id', 'season', 'week', 'efficiency']], on = ['player_id', 'season', 'week'], how = 'left')\n",
    "    df_merged = pd.merge(df_merged, df_snap_counts[['pfr_player_id', 'season', 'week', 'offense_snaps']], on = ['pfr_player_id', 'season', 'week'], how = 'left')\n",
    "\n",
    "    df_merged = df_merged.drop(columns=['game_id_type', 'pfr_player_id'])\n",
    "\n",
    "    df_merged['draft_pick'] = df_merged['draft_pick'].fillna(260)\n",
    "    df_merged = df_merged.fillna(0)\n",
    "\n",
    "    df_merged['rookie_flag'] = (df_merged['season'] == df_merged['draft_year']).astype(int)\n",
    "    df_merged['last_season_data_flag'] = (df_merged['week'] < 6).astype(int)\n",
    "    df_merged['home'] = (df_merged['home_team'] == df_merged['recent_team']).astype(int)\n",
    "    df_merged['player_id'] = df_merged['player_id'].str.replace('00-00', '').astype(int)\n",
    "\n",
    "    # interceptions und fumbles als eigene features statt als turnover aggregiert\n",
    "    # df_merged['turnover'] = (\n",
    "    #     df_merged['interceptions'] +\n",
    "    #     df_merged['sack_fumbles_lost'] +\n",
    "    #     df_merged['rushing_fumbles_lost'] +\n",
    "    #     df_merged['receiving_fumbles_lost']\n",
    "    # )\n",
    "\n",
    "    # tds und 2pt conversions als eigene features statt als total points aggregiert\n",
    "    # df_merged['points_total'] = (\n",
    "    #     (df_merged['rushing_tds'] * 6) + \n",
    "    #     (df_merged['rushing_2pt_conversions'] * 2) + \n",
    "    #     (df_merged['receiving_tds'] * 6) + \n",
    "    #     (df_merged['receiving_2pt_conversions'] * 2) + \n",
    "    #     (df_merged['passing_tds'] * 6) + \n",
    "    #     (df_merged['passing_2pt_conversions'] * 2)\n",
    "    # )\n",
    "\n",
    "    # passing, rushing und receiving epa als eigene features statt als epa aggregiert\n",
    "    # df_merged['epa_total'] = df_merged['passing_epa'] + df_merged['rushing_epa'] + df_merged['receiving_epa']\n",
    "\n",
    "    # passing, rushing und receiving yards einzeln statt total yards aggregiert\n",
    "    # df_merged['yards_total'] = (\n",
    "    #     df_merged['passing_yards'] +\n",
    "    #     df_merged['rushing_yards'] +\n",
    "    #     df_merged['receiving_yards']\n",
    "    # )\n",
    "\n",
    "    # position target-encoded\n",
    "    position_means = df_merged.groupby(['position', 'season', 'week'])['fantasy_points'].mean().reset_index()\n",
    "    position_means.rename(columns={'fantasy_points': 'position_encoded'}, inplace=True)\n",
    "    df_merged = pd.merge(df_merged, position_means, on=['position', 'season', 'week'], how='left')\n",
    "\n",
    "    # points_scored und points_allowed als Ma√üstab f√ºr St√§rke eines Teams\n",
    "    df_merged['recent_team_points_scored'] = df_merged.apply(lambda row: row['home_score'] if row['home'] == 1 else row['away_score'], axis=1)\n",
    "    df_merged['opponent_team_points_allowed'] = df_merged['recent_team_points_scored']\n",
    "\n",
    "    df_unique_opponent_team_points_allowed = df_merged.drop_duplicates(subset=['game_id', 'opponent_team', 'opponent_team_points_allowed'])\n",
    "    df_unique_recent_team_points_scored = df_merged.drop_duplicates(subset=['game_id', 'recent_team', 'recent_team_points_scored'])\n",
    "\n",
    "    df_unique_opponent_team_points_allowed = df_unique_opponent_team_points_allowed.sort_values(by=['opponent_team', 'season', 'week']).reset_index(drop=True)\n",
    "    df_unique_recent_team_points_scored = df_unique_recent_team_points_scored.sort_values(by=['recent_team', 'season', 'week']).reset_index(drop=True)\n",
    "\n",
    "    df_unique_opponent_team_points_allowed['ewm_opponent_team_points_allowed_l5w'] = (\n",
    "        df_unique_opponent_team_points_allowed.groupby('opponent_team')['opponent_team_points_allowed']\n",
    "        .apply(lambda x: x.shift(1).ewm(span=5, min_periods=5).mean())\n",
    "        .reset_index(level=0, drop=True)\n",
    "    )\n",
    "\n",
    "    df_unique_opponent_team_points_allowed[\"median_opponent_team_points_allowed_l5w\"] = (\n",
    "        df_unique_opponent_team_points_allowed.groupby('opponent_team')['opponent_team_points_allowed']\n",
    "        .apply(lambda x: x.shift(1).rolling(window=5, min_periods=5).median())  # shift(1) schlie√üt aktuelle Woche aus\n",
    "        .reset_index(level=0, drop=True)  # Index zur√ºcksetzen\n",
    "    )\n",
    "\n",
    "    for metric in ['min', 'max']:\n",
    "            df_unique_opponent_team_points_allowed[f\"{metric}_opponent_team_points_allowed_l3w\"] = (\n",
    "                df_unique_opponent_team_points_allowed.groupby('opponent_team')['opponent_team_points_allowed']\n",
    "                .apply(lambda x: x.shift(1).rolling(window=3, min_periods=3).agg(metric))  # shift(1) schlie√üt aktuelle Woche aus\n",
    "                .reset_index(level=0, drop=True)  # Index zur√ºcksetzen\n",
    "        )\n",
    "\n",
    "    df_unique_opponent_team_points_allowed = df_unique_opponent_team_points_allowed.drop(columns=['player_id', 'draft_year', 'interceptions', 'sack_fumbles_lost', 'rushing_fumbles_lost', 'receiving_fumbles_lost', 'rushing_tds', 'rushing_2pt_conversions', 'receiving_tds', 'receiving_2pt_conversions', 'passing_tds', 'passing_2pt_conversions', 'passing_epa', 'rushing_epa', 'receiving_epa', 'position', 'season', 'week', 'recent_team', 'home_team', 'completions', 'attempts', 'passing_yards', 'sacks', 'sack_yards', 'passing_air_yards', 'pacr', 'carries', 'rushing_yards', 'receptions', 'targets', 'receiving_yards', 'racr', 'wopr', 'fantasy_points', 'home_score', 'away_score', 'draft_pick', 'dom', 'passing_bad_throws', 'times_pressured', 'receiving_rat', 'rushing_broken_tackles', 'passer_rating', 'aggressiveness', 'efficiency', 'offense_snaps', 'rookie_flag', 'last_season_data_flag', 'home', 'position_encoded', 'recent_team_points_scored', 'opponent_team_points_allowed'])\n",
    "    df_merged = pd.merge(df_merged, df_unique_opponent_team_points_allowed, on=['game_id','opponent_team'], how='inner')\n",
    "\n",
    "    df_unique_recent_team_points_scored['ewm_recent_team_points_scored_l5w'] = (\n",
    "        df_unique_recent_team_points_scored.groupby('recent_team')['recent_team_points_scored']\n",
    "        .apply(lambda x: x.shift(1).ewm(span=5, min_periods=5).mean())\n",
    "        .reset_index(level=0, drop=True)\n",
    "    )\n",
    "\n",
    "    df_unique_recent_team_points_scored[\"median_recent_team_points_scored_l5w\"] = (\n",
    "        df_unique_recent_team_points_scored.groupby('recent_team')['recent_team_points_scored']\n",
    "        .apply(lambda x: x.shift(1).rolling(window=5, min_periods=5).median())  # shift(1) schlie√üt aktuelle Woche aus\n",
    "        .reset_index(level=0, drop=True)  # Index zur√ºcksetzen\n",
    "    )\n",
    "\n",
    "    for metric in ['min', 'max']:\n",
    "            df_unique_recent_team_points_scored[f\"{metric}_recent_team_points_scored_l3w\"] = (\n",
    "                df_unique_recent_team_points_scored.groupby('recent_team')['recent_team_points_scored']\n",
    "                .apply(lambda x: x.shift(1).rolling(window=3, min_periods=3).agg(metric))  # shift(1) schlie√üt aktuelle Woche aus\n",
    "                .reset_index(level=0, drop=True)  # Index zur√ºcksetzen\n",
    "        )\n",
    "\n",
    "    df_unique_recent_team_points_scored = df_unique_recent_team_points_scored.drop(columns=['player_id', 'draft_year', 'interceptions', 'sack_fumbles_lost', 'rushing_fumbles_lost', 'receiving_fumbles_lost', 'rushing_tds', 'rushing_2pt_conversions', 'receiving_tds', 'receiving_2pt_conversions', 'passing_tds', 'passing_2pt_conversions', 'passing_epa', 'rushing_epa', 'receiving_epa', 'position', 'season', 'week', 'opponent_team', 'home_team', 'completions', 'attempts', 'passing_yards', 'sacks', 'sack_yards', 'passing_air_yards', 'pacr', 'carries', 'rushing_yards', 'receptions', 'targets', 'receiving_yards', 'racr', 'wopr', 'fantasy_points', 'home_score', 'away_score', 'draft_pick', 'dom', 'passing_bad_throws', 'times_pressured', 'receiving_rat', 'rushing_broken_tackles', 'passer_rating', 'aggressiveness', 'efficiency', 'offense_snaps', 'rookie_flag', 'last_season_data_flag', 'home', 'position_encoded', 'recent_team_points_scored', 'opponent_team_points_allowed'])\n",
    "    df_merged = pd.merge(df_merged, df_unique_recent_team_points_scored, on=['game_id','recent_team'], how='inner')\n",
    "\n",
    "    # Liste der Spalten mit Spielerspezifischen numerischen Daten, f√ºr die Rolling-Features erstellt werden sollen\n",
    "    columns_to_roll = ['completions', 'attempts', 'passing_yards', 'sacks', 'passer_rating', 'aggressiveness', 'efficiency', 'sack_yards', \n",
    "                    'passing_air_yards', 'pacr', 'carries', 'offense_snaps', 'rushing_yards', 'receptions', 'targets', 'receiving_yards', \n",
    "                    'racr', 'wopr', 'fantasy_points', 'passing_bad_throws', 'times_pressured', 'position_encoded', 'receiving_rat', \n",
    "                    'rushing_broken_tackles',  'interceptions', 'sack_fumbles_lost', 'rushing_fumbles_lost', 'receiving_fumbles_lost', 'rushing_tds', \n",
    "                    'rushing_2pt_conversions', 'receiving_tds', 'receiving_2pt_conversions', 'passing_tds', 'passing_2pt_conversions', 'passing_epa', \n",
    "                    'rushing_epa', 'receiving_epa']\n",
    "\n",
    "\n",
    "    # Sortiere nach player_id, season und week\n",
    "    df_merged = df_merged.sort_values(by=['player_id', 'season', 'week']).reset_index(drop=True)\n",
    "\n",
    "\n",
    "    df_merged['cnt_games_over_20ffpts_l5w'] = (\n",
    "        df_merged.groupby('player_id')['fantasy_points']\n",
    "        .apply(lambda x: x.shift(1).rolling(window=5, min_periods=5).apply(lambda y: (y > 20).sum()))\n",
    "        .reset_index(level=0, drop=True)\n",
    "    )\n",
    "\n",
    "    # Rolling-Features erstellen\n",
    "    for col in columns_to_roll:\n",
    "\n",
    "        feature_name_1 = f\"ewm_{col}_l5w\"\n",
    "        df_merged[feature_name_1] = (\n",
    "            df_merged.groupby('player_id')[col]\n",
    "            .apply(lambda x: x.shift(1).ewm(span=5, min_periods=5).mean())\n",
    "            .reset_index(level=0, drop=True)\n",
    "        )\n",
    " \n",
    "        feature_name_2 = f\"median_{col}_l5w\"\n",
    "        df_merged[feature_name_2] = (\n",
    "            df_merged.groupby('player_id')[col]\n",
    "                .apply(lambda x: x.shift(1).rolling(window=5, min_periods=5).median())  # shift(1) schlie√üt aktuelle Woche aus\n",
    "                .reset_index(level=0, drop=True)  # Index zur√ºcksetzen\n",
    "        )\n",
    "\n",
    "        for metric in ['max', 'min']:\n",
    "            feature_name_3 = f\"{metric}_{col}_l3w\"\n",
    "            # Berechnung der Rolling-Metrik (ohne aktuelle Woche)\n",
    "            rolling_result_3w = (\n",
    "                df_merged.groupby('player_id')[col]\n",
    "                    .apply(lambda x: x.shift(1).rolling(window=3, min_periods=3).agg(metric))  # shift(1) schlie√üt aktuelle Woche aus\n",
    "                    .reset_index(level=0, drop=True)  # Index zur√ºcksetzen\n",
    "            )\n",
    "            # Einf√ºgen der Rolling-Metrik\n",
    "            df_merged[feature_name_3] = rolling_result_3w\n",
    "\n",
    "    df_merged = df_merged.drop(columns=['completions', 'attempts', 'passing_yards', 'sacks', 'sack_yards', 'passing_air_yards', 'pacr', 'carries', \n",
    "                                        'rushing_yards', 'receptions', 'targets', 'receiving_yards', 'racr', 'wopr', 'passing_bad_throws', \n",
    "                                        'times_pressured', 'receiving_rat', 'rushing_broken_tackles', 'draft_year', 'home_team', \n",
    "                                        'passer_rating', 'aggressiveness', 'efficiency', 'offense_snaps', 'game_id',  'interceptions', 'sack_fumbles_lost', \n",
    "                                        'rushing_fumbles_lost', 'receiving_fumbles_lost', 'rushing_tds', 'rushing_2pt_conversions', 'receiving_tds', \n",
    "                                        'receiving_2pt_conversions', 'passing_tds', 'passing_2pt_conversions', 'passing_epa', 'rushing_epa', 'receiving_epa',\n",
    "                                        'position_encoded', 'recent_team', 'opponent_team', 'position', 'home_score', 'away_score',\n",
    "                                        'recent_team_points_scored', 'opponent_team_points_allowed'])\n",
    "\n",
    "    df_merged = df_merged.dropna().reset_index()\n",
    "\n",
    "    return df_merged\n",
    "\n",
    "df_3 = load_merge_edit_data_3()\n",
    "\n",
    "df_3.info()\n",
    "print(df_3.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downcasting floats.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/sn/54gnf37x14l2fsfqr_hj0dnc0000gn/T/ipykernel_6060/3034988867.py:194: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_merged[feature_name_3] = rolling_result_3w\n",
      "/var/folders/sn/54gnf37x14l2fsfqr_hj0dnc0000gn/T/ipykernel_6060/3034988867.py:194: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_merged[feature_name_3] = rolling_result_3w\n",
      "/var/folders/sn/54gnf37x14l2fsfqr_hj0dnc0000gn/T/ipykernel_6060/3034988867.py:172: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_merged[feature_name_1] = (\n",
      "/var/folders/sn/54gnf37x14l2fsfqr_hj0dnc0000gn/T/ipykernel_6060/3034988867.py:179: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_merged[feature_name_2] = (\n",
      "/var/folders/sn/54gnf37x14l2fsfqr_hj0dnc0000gn/T/ipykernel_6060/3034988867.py:194: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_merged[feature_name_3] = rolling_result_3w\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 30183 entries, 0 to 30182\n",
      "Columns: 119 entries, index to min_epa_total_l3w\n",
      "dtypes: float32(1), float64(111), int32(2), int64(5)\n",
      "memory usage: 27.1 MB\n",
      "index                                      0\n",
      "player_id                                  0\n",
      "season                                     0\n",
      "week                                       0\n",
      "fantasy_points                             0\n",
      "draft_pick                                 0\n",
      "dom                                        0\n",
      "rookie_flag                                0\n",
      "last_season_data_flag                      0\n",
      "home                                       0\n",
      "ewm_opponent_team_points_allowed_l5w       0\n",
      "median_opponent_team_points_allowed_l5w    0\n",
      "min_opponent_team_points_allowed_l3w       0\n",
      "max_opponent_team_points_allowed_l3w       0\n",
      "ewm_recent_team_points_scored_l5w          0\n",
      "mean_recent_team_points_scored_l5w         0\n",
      "median_recent_team_points_scored_l5w       0\n",
      "std_recent_team_points_scored_l5w          0\n",
      "cnt_games_over_20ffpts_l5w                 0\n",
      "ewm_completions_l5w                        0\n",
      "median_completions_l5w                     0\n",
      "max_completions_l3w                        0\n",
      "min_completions_l3w                        0\n",
      "ewm_attempts_l5w                           0\n",
      "median_attempts_l5w                        0\n",
      "max_attempts_l3w                           0\n",
      "min_attempts_l3w                           0\n",
      "ewm_sacks_l5w                              0\n",
      "median_sacks_l5w                           0\n",
      "max_sacks_l3w                              0\n",
      "min_sacks_l3w                              0\n",
      "ewm_passer_rating_l5w                      0\n",
      "median_passer_rating_l5w                   0\n",
      "max_passer_rating_l3w                      0\n",
      "min_passer_rating_l3w                      0\n",
      "ewm_aggressiveness_l5w                     0\n",
      "median_aggressiveness_l5w                  0\n",
      "max_aggressiveness_l3w                     0\n",
      "min_aggressiveness_l3w                     0\n",
      "ewm_efficiency_l5w                         0\n",
      "median_efficiency_l5w                      0\n",
      "max_efficiency_l3w                         0\n",
      "min_efficiency_l3w                         0\n",
      "ewm_sack_yards_l5w                         0\n",
      "median_sack_yards_l5w                      0\n",
      "max_sack_yards_l3w                         0\n",
      "min_sack_yards_l3w                         0\n",
      "ewm_passing_air_yards_l5w                  0\n",
      "median_passing_air_yards_l5w               0\n",
      "max_passing_air_yards_l3w                  0\n",
      "min_passing_air_yards_l3w                  0\n",
      "ewm_pacr_l5w                               0\n",
      "median_pacr_l5w                            0\n",
      "max_pacr_l3w                               0\n",
      "min_pacr_l3w                               0\n",
      "ewm_carries_l5w                            0\n",
      "median_carries_l5w                         0\n",
      "max_carries_l3w                            0\n",
      "min_carries_l3w                            0\n",
      "ewm_offense_snaps_l5w                      0\n",
      "median_offense_snaps_l5w                   0\n",
      "max_offense_snaps_l3w                      0\n",
      "min_offense_snaps_l3w                      0\n",
      "ewm_yards_total_l5w                        0\n",
      "median_yards_total_l5w                     0\n",
      "max_yards_total_l3w                        0\n",
      "min_yards_total_l3w                        0\n",
      "ewm_receptions_l5w                         0\n",
      "median_receptions_l5w                      0\n",
      "max_receptions_l3w                         0\n",
      "min_receptions_l3w                         0\n",
      "ewm_targets_l5w                            0\n",
      "median_targets_l5w                         0\n",
      "max_targets_l3w                            0\n",
      "min_targets_l3w                            0\n",
      "ewm_racr_l5w                               0\n",
      "median_racr_l5w                            0\n",
      "max_racr_l3w                               0\n",
      "min_racr_l3w                               0\n",
      "ewm_wopr_l5w                               0\n",
      "median_wopr_l5w                            0\n",
      "max_wopr_l3w                               0\n",
      "min_wopr_l3w                               0\n",
      "ewm_fantasy_points_l5w                     0\n",
      "median_fantasy_points_l5w                  0\n",
      "max_fantasy_points_l3w                     0\n",
      "min_fantasy_points_l3w                     0\n",
      "ewm_passing_bad_throws_l5w                 0\n",
      "median_passing_bad_throws_l5w              0\n",
      "max_passing_bad_throws_l3w                 0\n",
      "min_passing_bad_throws_l3w                 0\n",
      "ewm_times_pressured_l5w                    0\n",
      "median_times_pressured_l5w                 0\n",
      "max_times_pressured_l3w                    0\n",
      "min_times_pressured_l3w                    0\n",
      "ewm_position_encoded_l5w                   0\n",
      "median_position_encoded_l5w                0\n",
      "max_position_encoded_l3w                   0\n",
      "min_position_encoded_l3w                   0\n",
      "ewm_receiving_rat_l5w                      0\n",
      "median_receiving_rat_l5w                   0\n",
      "max_receiving_rat_l3w                      0\n",
      "min_receiving_rat_l3w                      0\n",
      "ewm_rushing_broken_tackles_l5w             0\n",
      "median_rushing_broken_tackles_l5w          0\n",
      "max_rushing_broken_tackles_l3w             0\n",
      "min_rushing_broken_tackles_l3w             0\n",
      "ewm_turnover_l5w                           0\n",
      "median_turnover_l5w                        0\n",
      "max_turnover_l3w                           0\n",
      "min_turnover_l3w                           0\n",
      "ewm_points_total_l5w                       0\n",
      "median_points_total_l5w                    0\n",
      "max_points_total_l3w                       0\n",
      "min_points_total_l3w                       0\n",
      "ewm_epa_total_l5w                          0\n",
      "median_epa_total_l5w                       0\n",
      "max_epa_total_l3w                          0\n",
      "min_epa_total_l3w                          0\n",
      "dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/sn/54gnf37x14l2fsfqr_hj0dnc0000gn/T/ipykernel_6060/3034988867.py:194: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_merged[feature_name_3] = rolling_result_3w\n"
     ]
    }
   ],
   "source": [
    "# Positionsspezifische Stats zusammengefasst (passing, rushing und receiving zu total_features zusammengefasst)\n",
    "# Nur ausgew√§hlte Metriken ewm, median/mean, min, max\n",
    "\n",
    "def load_merge_edit_data_4():  \n",
    "\n",
    "    df_ids = nfl.import_ids()\n",
    "    df_weekly = nfl.import_weekly_data(list(range(2018, 2025)))\n",
    "    df_seasonal = nfl.import_seasonal_data(list(range(2017,2024)))\n",
    "    df_schedule = nfl.import_schedules(list(range(2018, 2025)))\n",
    "    df_pass_pfr = nfl.import_weekly_pfr('pass', list(range(2018, 2025)))\n",
    "    df_rush_pfr = nfl.import_weekly_pfr('rush', list(range(2018, 2025)))\n",
    "    df_rec_pfr = nfl.import_weekly_pfr('rec', list(range(2018, 2025)))\n",
    "    df_pass_ngs = nfl.import_ngs_data('passing',list(range(2018, 2025)))\n",
    "    df_rush_ngs = nfl.import_ngs_data('rushing',list(range(2018, 2025)))\n",
    "    df_snap_counts = nfl.import_snap_counts(list(range(2018, 2025)))\n",
    "\n",
    "    df_weekly = df_weekly[(df_weekly['season_type'] == 'REG') & (df_weekly['position'].isin(['QB', 'WR', 'RB', 'TE']))].reset_index()\n",
    "\n",
    "    df_seasonal['season'] = df_seasonal['season'] + 1\n",
    "\n",
    "    df_schedule = df_schedule[['game_id', 'home_team', 'home_score', 'away_score']].drop_duplicates()\n",
    "    df_schedule['game_id'] = df_schedule['game_id'].str.replace('OAK', 'LV', regex=False) # Umzug der Oakland Raiders nach Las Vegas in der Saison 2020\n",
    "    df_schedule['home_team'] = df_schedule['home_team'].str.replace('OAK', 'LV', regex=False) # Umzug der Oakland Raiders nach Las Vegas in der Saison 2020\n",
    "\n",
    "    df_weekly['game_id_home_away'] = df_weekly['season'].astype(str) + '_' + df_weekly['week'].apply(lambda x: f\"{x:02d}\")+'_'+df_weekly['recent_team']+'_'+df_weekly['opponent_team']\n",
    "    df_weekly['game_id_away_home'] = df_weekly['season'].astype(str) + '_' + df_weekly['week'].apply(lambda x: f\"{x:02d}\")+'_'+df_weekly['opponent_team']+'_'+df_weekly['recent_team']\n",
    "\n",
    "    df_merged = pd.melt(\n",
    "        df_weekly,\n",
    "        id_vars=['player_id', 'position', 'season', 'week', 'recent_team', 'opponent_team', 'completions', 'attempts', 'passing_yards', 'passing_tds', 'passing_2pt_conversions', 'interceptions', 'sack_fumbles_lost', 'sacks', 'sack_yards', 'passing_air_yards', 'passing_epa', 'pacr', 'carries', 'rushing_yards', 'rushing_tds', 'rushing_2pt_conversions', 'rushing_fumbles_lost', 'rushing_epa', 'receptions', 'targets', 'receiving_yards', 'receiving_tds', 'receiving_2pt_conversions', 'receiving_fumbles_lost', 'racr', 'wopr', 'receiving_epa', 'fantasy_points'],\n",
    "        value_vars=['game_id_home_away', 'game_id_away_home'],\n",
    "        var_name='game_id_type',\n",
    "        value_name='game_id'\n",
    "    )\n",
    "\n",
    "    df_ids = df_ids.rename(columns={'gsis_id': 'player_id', 'pfr_id': 'pfr_player_id'})\n",
    "    df_pass_ngs = df_pass_ngs.rename(columns={'player_gsis_id': 'player_id'})\n",
    "    df_rush_ngs = df_rush_ngs.rename(columns={'player_gsis_id': 'player_id'})\n",
    "\n",
    "    df_merged = pd.merge(df_merged, df_schedule, on='game_id', how='inner') # Bei ein paar Spielen: recent_team = opponent_team\n",
    "    df_merged = pd.merge(df_merged, df_ids[['player_id', 'pfr_player_id', 'draft_pick', 'draft_year']], on = 'player_id', how = 'inner') # Ein paar Spieler ohne draft_year\n",
    "    df_merged = pd.merge(df_merged, df_seasonal[['player_id', 'season', 'dom']], on = ['player_id', 'season'], how = 'left')\n",
    "    df_merged = pd.merge(df_merged, df_pass_pfr[['pfr_player_id', 'season', 'week', 'passing_bad_throws', 'times_pressured']], on = ['pfr_player_id', 'season', 'week'], how = 'left')\n",
    "    df_merged = pd.merge(df_merged, df_rec_pfr[['pfr_player_id', 'season', 'week', 'receiving_rat']], on = ['pfr_player_id', 'season', 'week'], how = 'left')\n",
    "    df_merged = pd.merge(df_merged, df_rush_pfr[['pfr_player_id', 'season', 'week', 'rushing_broken_tackles']], on = ['pfr_player_id', 'season', 'week'], how = 'left')\n",
    "    df_merged = pd.merge(df_merged, df_pass_ngs[['player_id', 'season', 'week', 'passer_rating', 'aggressiveness']], on = ['player_id', 'season', 'week'], how = 'left')\n",
    "    df_merged = pd.merge(df_merged, df_rush_ngs[['player_id', 'season', 'week', 'efficiency']], on = ['player_id', 'season', 'week'], how = 'left')\n",
    "    df_merged = pd.merge(df_merged, df_snap_counts[['pfr_player_id', 'season', 'week', 'offense_snaps']], on = ['pfr_player_id', 'season', 'week'], how = 'left')\n",
    "\n",
    "    df_merged = df_merged.drop(columns=['game_id_type', 'pfr_player_id'])\n",
    "\n",
    "    df_merged['draft_pick'] = df_merged['draft_pick'].fillna(260)\n",
    "    df_merged = df_merged.fillna(0)\n",
    "\n",
    "    df_merged['rookie_flag'] = (df_merged['season'] == df_merged['draft_year']).astype(int)\n",
    "    df_merged['last_season_data_flag'] = (df_merged['week'] < 6).astype(int)\n",
    "    df_merged['home'] = (df_merged['home_team'] == df_merged['recent_team']).astype(int)\n",
    "    df_merged['player_id'] = df_merged['player_id'].str.replace('00-00', '').astype(int)\n",
    "\n",
    "    # interceptions und fumbles als eigene features statt als turnover aggregiert\n",
    "    df_merged['turnover'] = (\n",
    "        df_merged['interceptions'] +\n",
    "        df_merged['sack_fumbles_lost'] +\n",
    "        df_merged['rushing_fumbles_lost'] +\n",
    "        df_merged['receiving_fumbles_lost']\n",
    "    )\n",
    "\n",
    "    # total epa aggregiert statt passing, rushing und receiving einzeln\n",
    "    df_merged['epa_total'] = (\n",
    "        df_merged['passing_epa'] + \n",
    "        df_merged['rushing_epa'] + \n",
    "        df_merged['receiving_epa']\n",
    "    )\n",
    "\n",
    "    # total points aggregiert statt passing, rushing und receiving tds und 2pt conversions einzeln\n",
    "    df_merged['points_total'] = (\n",
    "        (df_merged['rushing_tds'] * 6) + \n",
    "        (df_merged['rushing_2pt_conversions'] * 2) + \n",
    "        (df_merged['receiving_tds'] * 6) + \n",
    "        (df_merged['receiving_2pt_conversions'] * 2) + \n",
    "        (df_merged['passing_tds'] * 6) + \n",
    "        (df_merged['passing_2pt_conversions'] * 2)\n",
    "    )\n",
    "\n",
    "    # total yards aggregiert statt passing, rushing und receiving einzeln\n",
    "    df_merged['yards_total'] = (\n",
    "        df_merged['passing_yards'] +\n",
    "        df_merged['rushing_yards'] +\n",
    "        df_merged['receiving_yards']\n",
    "    )\n",
    "\n",
    "    # position target-encoded\n",
    "    position_means = df_merged.groupby(['position', 'season', 'week'])['fantasy_points'].mean().reset_index()\n",
    "    position_means.rename(columns={'fantasy_points': 'position_encoded'}, inplace=True)\n",
    "    df_merged = pd.merge(df_merged, position_means, on=['position', 'season', 'week'], how='left')\n",
    "\n",
    "    # points_scored und points_allowed als Ma√üstab f√ºr St√§rke eines Teams\n",
    "    df_merged['recent_team_points_scored'] = df_merged.apply(lambda row: row['home_score'] if row['home'] == 1 else row['away_score'], axis=1)\n",
    "    df_merged['opponent_team_points_allowed'] = df_merged['recent_team_points_scored']\n",
    "\n",
    "    df_unique_opponent_team_points_allowed = df_merged.drop_duplicates(subset=['game_id', 'opponent_team', 'opponent_team_points_allowed'])\n",
    "    df_unique_recent_team_points_scored = df_merged.drop_duplicates(subset=['game_id', 'recent_team', 'recent_team_points_scored'])\n",
    "\n",
    "    df_unique_opponent_team_points_allowed = df_unique_opponent_team_points_allowed.sort_values(by=['opponent_team', 'season', 'week']).reset_index(drop=True)\n",
    "    df_unique_recent_team_points_scored = df_unique_recent_team_points_scored.sort_values(by=['recent_team', 'season', 'week']).reset_index(drop=True)\n",
    "\n",
    "    df_unique_opponent_team_points_allowed['ewm_opponent_team_points_allowed_l5w'] = (\n",
    "        df_unique_opponent_team_points_allowed.groupby('opponent_team')['opponent_team_points_allowed']\n",
    "        .apply(lambda x: x.shift(1).ewm(span=5, min_periods=5).mean())\n",
    "        .reset_index(level=0, drop=True)\n",
    "    )\n",
    "\n",
    "    df_unique_opponent_team_points_allowed[\"median_opponent_team_points_allowed_l5w\"] = (\n",
    "        df_unique_opponent_team_points_allowed.groupby('opponent_team')['opponent_team_points_allowed']\n",
    "        .apply(lambda x: x.shift(1).rolling(window=5, min_periods=5).median())  # shift(1) schlie√üt aktuelle Woche aus\n",
    "        .reset_index(level=0, drop=True)  # Index zur√ºcksetzen\n",
    "    )\n",
    "\n",
    "    for metric in ['min', 'max']:\n",
    "            df_unique_opponent_team_points_allowed[f\"{metric}_opponent_team_points_allowed_l3w\"] = (\n",
    "                df_unique_opponent_team_points_allowed.groupby('opponent_team')['opponent_team_points_allowed']\n",
    "                .apply(lambda x: x.shift(1).rolling(window=3, min_periods=3).agg(metric))  # shift(1) schlie√üt aktuelle Woche aus\n",
    "                .reset_index(level=0, drop=True)  # Index zur√ºcksetzen\n",
    "        )\n",
    "\n",
    "    df_unique_opponent_team_points_allowed = df_unique_opponent_team_points_allowed.drop(columns=['player_id', 'draft_year', 'turnover', 'interceptions', 'sack_fumbles_lost', 'rushing_fumbles_lost', 'receiving_fumbles_lost', 'points_total', 'rushing_tds', 'rushing_2pt_conversions', 'receiving_tds', 'receiving_2pt_conversions', 'passing_tds', 'passing_2pt_conversions', 'epa_total', 'passing_epa', 'rushing_epa', 'receiving_epa', 'position', 'season', 'week', 'recent_team', 'home_team', 'completions', 'attempts', 'passing_yards', 'sacks', 'sack_yards', 'passing_air_yards', 'pacr', 'carries', 'rushing_yards', 'receptions', 'targets', 'yards_total', 'receiving_yards', 'racr', 'wopr', 'fantasy_points', 'home_score', 'away_score', 'draft_pick', 'dom', 'passing_bad_throws', 'times_pressured', 'receiving_rat', 'rushing_broken_tackles', 'passer_rating', 'aggressiveness', 'efficiency', 'offense_snaps', 'rookie_flag', 'last_season_data_flag', 'home', 'position_encoded', 'recent_team_points_scored', 'opponent_team_points_allowed'])\n",
    "    df_merged = pd.merge(df_merged, df_unique_opponent_team_points_allowed, on=['game_id','opponent_team'], how='inner')\n",
    "\n",
    "    df_unique_recent_team_points_scored['ewm_recent_team_points_scored_l5w'] = (\n",
    "        df_unique_recent_team_points_scored.groupby('recent_team')['recent_team_points_scored']\n",
    "        .apply(lambda x: x.shift(1).ewm(span=5, min_periods=5).mean())\n",
    "        .reset_index(level=0, drop=True)\n",
    "    )\n",
    "\n",
    "    for metric in ['mean', 'median', 'std']:\n",
    "            df_unique_recent_team_points_scored[f\"{metric}_recent_team_points_scored_l5w\"] = (\n",
    "                df_unique_recent_team_points_scored.groupby('recent_team')['recent_team_points_scored']\n",
    "                .apply(lambda x: x.shift(1).rolling(window=5, min_periods=5).agg(metric))  # shift(1) schlie√üt aktuelle Woche aus\n",
    "                .reset_index(level=0, drop=True)  # Index zur√ºcksetzen\n",
    "        )\n",
    "\n",
    "    df_unique_recent_team_points_scored[\"median_recent_team_points_scored_l5w\"] = (\n",
    "        df_unique_recent_team_points_scored.groupby('recent_team')['recent_team_points_scored']\n",
    "        .apply(lambda x: x.shift(1).rolling(window=5, min_periods=5).median())  # shift(1) schlie√üt aktuelle Woche aus\n",
    "        .reset_index(level=0, drop=True)  # Index zur√ºcksetzen\n",
    "    )\n",
    "\n",
    "    df_unique_recent_team_points_scored = df_unique_recent_team_points_scored.drop(columns=['player_id', 'draft_year', 'turnover', 'interceptions', 'sack_fumbles_lost', 'rushing_fumbles_lost', 'receiving_fumbles_lost', 'points_total', 'rushing_tds', 'rushing_2pt_conversions', 'receiving_tds', 'receiving_2pt_conversions', 'passing_tds', 'passing_2pt_conversions', 'epa_total', 'passing_epa', 'rushing_epa', 'receiving_epa', 'position', 'season', 'week', 'opponent_team', 'home_team', 'completions', 'attempts', 'yards_total', 'passing_yards', 'sacks', 'sack_yards', 'passing_air_yards', 'pacr', 'carries', 'rushing_yards', 'receptions', 'targets', 'receiving_yards', 'racr', 'wopr', 'fantasy_points', 'home_score', 'away_score', 'draft_pick', 'dom', 'passing_bad_throws', 'times_pressured', 'receiving_rat', 'rushing_broken_tackles', 'passer_rating', 'aggressiveness', 'efficiency', 'offense_snaps', 'rookie_flag', 'last_season_data_flag', 'home', 'position_encoded', 'recent_team_points_scored', 'opponent_team_points_allowed'])\n",
    "    df_merged = pd.merge(df_merged, df_unique_recent_team_points_scored, on=['game_id','recent_team'], how='inner')\n",
    "\n",
    "    # Liste der Spalten mit Spielerspezifischen numerischen Daten, f√ºr die Rolling-Features erstellt werden sollen\n",
    "    columns_to_roll = ['completions', 'attempts', 'sacks', 'passer_rating', 'aggressiveness', 'efficiency', 'sack_yards', \n",
    "                    'passing_air_yards', 'pacr', 'carries', 'offense_snaps', 'yards_total', 'receptions', 'targets',\n",
    "                    'racr', 'wopr', 'fantasy_points', 'passing_bad_throws', 'times_pressured', 'position_encoded', 'receiving_rat', \n",
    "                    'rushing_broken_tackles', 'turnover', 'points_total', 'epa_total']\n",
    "\n",
    "\n",
    "    # Sortiere nach player_id, season und week\n",
    "    df_merged = df_merged.sort_values(by=['player_id', 'season', 'week']).reset_index(drop=True)\n",
    "\n",
    "\n",
    "    df_merged['cnt_games_over_20ffpts_l5w'] = (\n",
    "        df_merged.groupby('player_id')['fantasy_points']\n",
    "        .apply(lambda x: x.shift(1).rolling(window=5, min_periods=5).apply(lambda y: (y > 20).sum()))\n",
    "        .reset_index(level=0, drop=True)\n",
    "    )\n",
    "\n",
    "    # Rolling-Features erstellen\n",
    "    for col in columns_to_roll:\n",
    "\n",
    "        feature_name_1 = f\"ewm_{col}_l5w\"\n",
    "        df_merged[feature_name_1] = (\n",
    "            df_merged.groupby('player_id')[col]\n",
    "            .apply(lambda x: x.shift(1).ewm(span=5, min_periods=5).mean())\n",
    "            .reset_index(level=0, drop=True)\n",
    "        )\n",
    "\n",
    "        feature_name_2 = f\"median_{col}_l5w\"\n",
    "        df_merged[feature_name_2] = (\n",
    "            df_merged.groupby('player_id')[col]\n",
    "                .apply(lambda x: x.shift(1).rolling(window=5, min_periods=5).median())  # shift(1) schlie√üt aktuelle Woche aus\n",
    "                .reset_index(level=0, drop=True)  # Index zur√ºcksetzen\n",
    "        )\n",
    "\n",
    "        for metric in ['max', 'min']:\n",
    "            feature_name_3 = f\"{metric}_{col}_l3w\"\n",
    "            # Berechnung der Rolling-Metrik (ohne aktuelle Woche)\n",
    "            rolling_result_3w = (\n",
    "                df_merged.groupby('player_id')[col]\n",
    "                    .apply(lambda x: x.shift(1).rolling(window=3, min_periods=3).agg(metric))  # shift(1) schlie√üt aktuelle Woche aus\n",
    "                    .reset_index(level=0, drop=True)  # Index zur√ºcksetzen\n",
    "            )\n",
    "            # Einf√ºgen der Rolling-Metrik\n",
    "            df_merged[feature_name_3] = rolling_result_3w\n",
    "\n",
    "    df_merged = df_merged.drop(columns=['completions', 'attempts', 'passing_yards', 'sacks', 'sack_yards', 'passing_air_yards', 'pacr', 'carries', \n",
    "                                        'rushing_yards', 'receptions', 'targets', 'receiving_yards', 'racr', 'wopr', 'passing_bad_throws', \n",
    "                                        'times_pressured', 'receiving_rat', 'rushing_broken_tackles', 'draft_year', 'home_team', \n",
    "                                        'passer_rating', 'aggressiveness', 'efficiency', 'offense_snaps', 'game_id',  'interceptions', 'sack_fumbles_lost', \n",
    "                                        'rushing_fumbles_lost', 'receiving_fumbles_lost', 'rushing_tds', 'rushing_2pt_conversions', 'receiving_tds', \n",
    "                                        'receiving_2pt_conversions', 'passing_tds', 'passing_2pt_conversions', 'passing_epa', 'rushing_epa', 'receiving_epa',\n",
    "                                        'position_encoded', 'recent_team', 'opponent_team', 'position', 'home_score', 'away_score',\n",
    "                                        'recent_team_points_scored', 'opponent_team_points_allowed', 'turnover', 'points_total', 'yards_total',\n",
    "                                        'epa_total'])\n",
    "\n",
    "    df_merged = df_merged.dropna().reset_index()\n",
    "\n",
    "    return df_merged\n",
    "\n",
    "df_4 = load_merge_edit_data_4()\n",
    "\n",
    "df_4.info()\n",
    "print(df_4.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downcasting floats.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/sn/54gnf37x14l2fsfqr_hj0dnc0000gn/T/ipykernel_6060/1311958323.py:205: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_merged[feature_name_3] = rolling_result_3w\n",
      "/var/folders/sn/54gnf37x14l2fsfqr_hj0dnc0000gn/T/ipykernel_6060/1311958323.py:205: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_merged[feature_name_3] = rolling_result_3w\n",
      "/var/folders/sn/54gnf37x14l2fsfqr_hj0dnc0000gn/T/ipykernel_6060/1311958323.py:180: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_merged[feature_name_1] = (\n",
      "/var/folders/sn/54gnf37x14l2fsfqr_hj0dnc0000gn/T/ipykernel_6060/1311958323.py:194: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_merged[feature_name_2] = rolling_result_5w\n",
      "/var/folders/sn/54gnf37x14l2fsfqr_hj0dnc0000gn/T/ipykernel_6060/1311958323.py:194: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_merged[feature_name_2] = rolling_result_5w\n",
      "/var/folders/sn/54gnf37x14l2fsfqr_hj0dnc0000gn/T/ipykernel_6060/1311958323.py:194: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_merged[feature_name_2] = rolling_result_5w\n",
      "/var/folders/sn/54gnf37x14l2fsfqr_hj0dnc0000gn/T/ipykernel_6060/1311958323.py:205: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_merged[feature_name_3] = rolling_result_3w\n",
      "/var/folders/sn/54gnf37x14l2fsfqr_hj0dnc0000gn/T/ipykernel_6060/1311958323.py:205: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_merged[feature_name_3] = rolling_result_3w\n",
      "/var/folders/sn/54gnf37x14l2fsfqr_hj0dnc0000gn/T/ipykernel_6060/1311958323.py:180: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_merged[feature_name_1] = (\n",
      "/var/folders/sn/54gnf37x14l2fsfqr_hj0dnc0000gn/T/ipykernel_6060/1311958323.py:194: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_merged[feature_name_2] = rolling_result_5w\n",
      "/var/folders/sn/54gnf37x14l2fsfqr_hj0dnc0000gn/T/ipykernel_6060/1311958323.py:194: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_merged[feature_name_2] = rolling_result_5w\n",
      "/var/folders/sn/54gnf37x14l2fsfqr_hj0dnc0000gn/T/ipykernel_6060/1311958323.py:194: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_merged[feature_name_2] = rolling_result_5w\n",
      "/var/folders/sn/54gnf37x14l2fsfqr_hj0dnc0000gn/T/ipykernel_6060/1311958323.py:205: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_merged[feature_name_3] = rolling_result_3w\n",
      "/var/folders/sn/54gnf37x14l2fsfqr_hj0dnc0000gn/T/ipykernel_6060/1311958323.py:205: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_merged[feature_name_3] = rolling_result_3w\n",
      "/var/folders/sn/54gnf37x14l2fsfqr_hj0dnc0000gn/T/ipykernel_6060/1311958323.py:180: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_merged[feature_name_1] = (\n",
      "/var/folders/sn/54gnf37x14l2fsfqr_hj0dnc0000gn/T/ipykernel_6060/1311958323.py:194: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_merged[feature_name_2] = rolling_result_5w\n",
      "/var/folders/sn/54gnf37x14l2fsfqr_hj0dnc0000gn/T/ipykernel_6060/1311958323.py:194: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_merged[feature_name_2] = rolling_result_5w\n",
      "/var/folders/sn/54gnf37x14l2fsfqr_hj0dnc0000gn/T/ipykernel_6060/1311958323.py:194: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_merged[feature_name_2] = rolling_result_5w\n",
      "/var/folders/sn/54gnf37x14l2fsfqr_hj0dnc0000gn/T/ipykernel_6060/1311958323.py:205: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_merged[feature_name_3] = rolling_result_3w\n",
      "/var/folders/sn/54gnf37x14l2fsfqr_hj0dnc0000gn/T/ipykernel_6060/1311958323.py:205: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_merged[feature_name_3] = rolling_result_3w\n",
      "/var/folders/sn/54gnf37x14l2fsfqr_hj0dnc0000gn/T/ipykernel_6060/1311958323.py:180: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_merged[feature_name_1] = (\n",
      "/var/folders/sn/54gnf37x14l2fsfqr_hj0dnc0000gn/T/ipykernel_6060/1311958323.py:194: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_merged[feature_name_2] = rolling_result_5w\n",
      "/var/folders/sn/54gnf37x14l2fsfqr_hj0dnc0000gn/T/ipykernel_6060/1311958323.py:194: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_merged[feature_name_2] = rolling_result_5w\n",
      "/var/folders/sn/54gnf37x14l2fsfqr_hj0dnc0000gn/T/ipykernel_6060/1311958323.py:194: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_merged[feature_name_2] = rolling_result_5w\n",
      "/var/folders/sn/54gnf37x14l2fsfqr_hj0dnc0000gn/T/ipykernel_6060/1311958323.py:205: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_merged[feature_name_3] = rolling_result_3w\n",
      "/var/folders/sn/54gnf37x14l2fsfqr_hj0dnc0000gn/T/ipykernel_6060/1311958323.py:205: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_merged[feature_name_3] = rolling_result_3w\n",
      "/var/folders/sn/54gnf37x14l2fsfqr_hj0dnc0000gn/T/ipykernel_6060/1311958323.py:180: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_merged[feature_name_1] = (\n",
      "/var/folders/sn/54gnf37x14l2fsfqr_hj0dnc0000gn/T/ipykernel_6060/1311958323.py:194: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_merged[feature_name_2] = rolling_result_5w\n",
      "/var/folders/sn/54gnf37x14l2fsfqr_hj0dnc0000gn/T/ipykernel_6060/1311958323.py:194: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_merged[feature_name_2] = rolling_result_5w\n",
      "/var/folders/sn/54gnf37x14l2fsfqr_hj0dnc0000gn/T/ipykernel_6060/1311958323.py:194: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_merged[feature_name_2] = rolling_result_5w\n",
      "/var/folders/sn/54gnf37x14l2fsfqr_hj0dnc0000gn/T/ipykernel_6060/1311958323.py:205: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_merged[feature_name_3] = rolling_result_3w\n",
      "/var/folders/sn/54gnf37x14l2fsfqr_hj0dnc0000gn/T/ipykernel_6060/1311958323.py:205: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_merged[feature_name_3] = rolling_result_3w\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 30183 entries, 0 to 30182\n",
      "Columns: 149 entries, index to min_epa_total_l3w\n",
      "dtypes: float32(1), float64(141), int32(2), int64(5)\n",
      "memory usage: 34.0 MB\n",
      "index                                      0\n",
      "player_id                                  0\n",
      "season                                     0\n",
      "week                                       0\n",
      "fantasy_points                             0\n",
      "draft_pick                                 0\n",
      "dom                                        0\n",
      "rookie_flag                                0\n",
      "last_season_data_flag                      0\n",
      "home                                       0\n",
      "ewm_opponent_team_points_allowed_l5w       0\n",
      "mean_opponent_team_points_allowed_l5w      0\n",
      "median_opponent_team_points_allowed_l5w    0\n",
      "std_opponent_team_points_allowed_l5w       0\n",
      "min_opponent_team_points_allowed_l3w       0\n",
      "max_opponent_team_points_allowed_l3w       0\n",
      "ewm_recent_team_points_scored_l5w          0\n",
      "mean_recent_team_points_scored_l5w         0\n",
      "median_recent_team_points_scored_l5w       0\n",
      "std_recent_team_points_scored_l5w          0\n",
      "min_recent_team_points_scored_l3w          0\n",
      "max_recent_team_points_scored_l3w          0\n",
      "cnt_games_over_20ffpts_l5w                 0\n",
      "ewm_completions_l5w                        0\n",
      "mean_completions_l5w                       0\n",
      "median_completions_l5w                     0\n",
      "std_completions_l5w                        0\n",
      "max_completions_l3w                        0\n",
      "min_completions_l3w                        0\n",
      "ewm_attempts_l5w                           0\n",
      "mean_attempts_l5w                          0\n",
      "median_attempts_l5w                        0\n",
      "std_attempts_l5w                           0\n",
      "max_attempts_l3w                           0\n",
      "min_attempts_l3w                           0\n",
      "ewm_sacks_l5w                              0\n",
      "mean_sacks_l5w                             0\n",
      "median_sacks_l5w                           0\n",
      "std_sacks_l5w                              0\n",
      "max_sacks_l3w                              0\n",
      "min_sacks_l3w                              0\n",
      "ewm_player_rating_total_l5w                0\n",
      "mean_player_rating_total_l5w               0\n",
      "median_player_rating_total_l5w             0\n",
      "std_player_rating_total_l5w                0\n",
      "max_player_rating_total_l3w                0\n",
      "min_player_rating_total_l3w                0\n",
      "ewm_aggressiveness_l5w                     0\n",
      "mean_aggressiveness_l5w                    0\n",
      "median_aggressiveness_l5w                  0\n",
      "std_aggressiveness_l5w                     0\n",
      "max_aggressiveness_l3w                     0\n",
      "min_aggressiveness_l3w                     0\n",
      "ewm_efficiency_l5w                         0\n",
      "mean_efficiency_l5w                        0\n",
      "median_efficiency_l5w                      0\n",
      "std_efficiency_l5w                         0\n",
      "max_efficiency_l3w                         0\n",
      "min_efficiency_l3w                         0\n",
      "ewm_carries_l5w                            0\n",
      "mean_carries_l5w                           0\n",
      "median_carries_l5w                         0\n",
      "std_carries_l5w                            0\n",
      "max_carries_l3w                            0\n",
      "min_carries_l3w                            0\n",
      "ewm_offense_snaps_l5w                      0\n",
      "mean_offense_snaps_l5w                     0\n",
      "median_offense_snaps_l5w                   0\n",
      "std_offense_snaps_l5w                      0\n",
      "max_offense_snaps_l3w                      0\n",
      "min_offense_snaps_l3w                      0\n",
      "ewm_yards_total_l5w                        0\n",
      "mean_yards_total_l5w                       0\n",
      "median_yards_total_l5w                     0\n",
      "std_yards_total_l5w                        0\n",
      "max_yards_total_l3w                        0\n",
      "min_yards_total_l3w                        0\n",
      "ewm_receptions_l5w                         0\n",
      "mean_receptions_l5w                        0\n",
      "median_receptions_l5w                      0\n",
      "std_receptions_l5w                         0\n",
      "max_receptions_l3w                         0\n",
      "min_receptions_l3w                         0\n",
      "ewm_targets_l5w                            0\n",
      "mean_targets_l5w                           0\n",
      "median_targets_l5w                         0\n",
      "std_targets_l5w                            0\n",
      "max_targets_l3w                            0\n",
      "min_targets_l3w                            0\n",
      "ewm_acr_total_l5w                          0\n",
      "mean_acr_total_l5w                         0\n",
      "median_acr_total_l5w                       0\n",
      "std_acr_total_l5w                          0\n",
      "max_acr_total_l3w                          0\n",
      "min_acr_total_l3w                          0\n",
      "ewm_wopr_l5w                               0\n",
      "mean_wopr_l5w                              0\n",
      "median_wopr_l5w                            0\n",
      "std_wopr_l5w                               0\n",
      "max_wopr_l3w                               0\n",
      "min_wopr_l3w                               0\n",
      "ewm_fantasy_points_l5w                     0\n",
      "mean_fantasy_points_l5w                    0\n",
      "median_fantasy_points_l5w                  0\n",
      "std_fantasy_points_l5w                     0\n",
      "max_fantasy_points_l3w                     0\n",
      "min_fantasy_points_l3w                     0\n",
      "ewm_passing_bad_throws_l5w                 0\n",
      "mean_passing_bad_throws_l5w                0\n",
      "median_passing_bad_throws_l5w              0\n",
      "std_passing_bad_throws_l5w                 0\n",
      "max_passing_bad_throws_l3w                 0\n",
      "min_passing_bad_throws_l3w                 0\n",
      "ewm_times_pressured_l5w                    0\n",
      "mean_times_pressured_l5w                   0\n",
      "median_times_pressured_l5w                 0\n",
      "std_times_pressured_l5w                    0\n",
      "max_times_pressured_l3w                    0\n",
      "min_times_pressured_l3w                    0\n",
      "ewm_position_encoded_l5w                   0\n",
      "mean_position_encoded_l5w                  0\n",
      "median_position_encoded_l5w                0\n",
      "std_position_encoded_l5w                   0\n",
      "max_position_encoded_l3w                   0\n",
      "min_position_encoded_l3w                   0\n",
      "ewm_rushing_broken_tackles_l5w             0\n",
      "mean_rushing_broken_tackles_l5w            0\n",
      "median_rushing_broken_tackles_l5w          0\n",
      "std_rushing_broken_tackles_l5w             0\n",
      "max_rushing_broken_tackles_l3w             0\n",
      "min_rushing_broken_tackles_l3w             0\n",
      "ewm_turnover_l5w                           0\n",
      "mean_turnover_l5w                          0\n",
      "median_turnover_l5w                        0\n",
      "std_turnover_l5w                           0\n",
      "max_turnover_l3w                           0\n",
      "min_turnover_l3w                           0\n",
      "ewm_points_total_l5w                       0\n",
      "mean_points_total_l5w                      0\n",
      "median_points_total_l5w                    0\n",
      "std_points_total_l5w                       0\n",
      "max_points_total_l3w                       0\n",
      "min_points_total_l3w                       0\n",
      "ewm_epa_total_l5w                          0\n",
      "mean_epa_total_l5w                         0\n",
      "median_epa_total_l5w                       0\n",
      "std_epa_total_l5w                          0\n",
      "max_epa_total_l3w                          0\n",
      "min_epa_total_l3w                          0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Positionsspezifische Stats zusammengefasst (passing, rushing und receiving zu total_features zusammengefasst)\n",
    "# Alle Metriken (ewm, mean, median, min, max, std)\n",
    "\n",
    "def load_merge_edit_data_5():  \n",
    "\n",
    "    df_ids = nfl.import_ids()\n",
    "    df_weekly = nfl.import_weekly_data(list(range(2018, 2025)))\n",
    "    df_seasonal = nfl.import_seasonal_data(list(range(2017,2024)))\n",
    "    df_schedule = nfl.import_schedules(list(range(2018, 2025)))\n",
    "    df_pass_pfr = nfl.import_weekly_pfr('pass', list(range(2018, 2025)))\n",
    "    df_rush_pfr = nfl.import_weekly_pfr('rush', list(range(2018, 2025)))\n",
    "    df_rec_pfr = nfl.import_weekly_pfr('rec', list(range(2018, 2025)))\n",
    "    df_pass_ngs = nfl.import_ngs_data('passing',list(range(2018, 2025)))\n",
    "    df_rush_ngs = nfl.import_ngs_data('rushing',list(range(2018, 2025)))\n",
    "    df_snap_counts = nfl.import_snap_counts(list(range(2018, 2025)))\n",
    "\n",
    "    df_weekly = df_weekly[(df_weekly['season_type'] == 'REG') & (df_weekly['position'].isin(['QB', 'WR', 'RB', 'TE']))].reset_index()\n",
    "\n",
    "    df_seasonal['season'] = df_seasonal['season'] + 1\n",
    "\n",
    "    df_schedule = df_schedule[['game_id', 'home_team', 'home_score', 'away_score']].drop_duplicates()\n",
    "    df_schedule['game_id'] = df_schedule['game_id'].str.replace('OAK', 'LV', regex=False) # Umzug der Oakland Raiders nach Las Vegas in der Saison 2020\n",
    "    df_schedule['home_team'] = df_schedule['home_team'].str.replace('OAK', 'LV', regex=False) # Umzug der Oakland Raiders nach Las Vegas in der Saison 2020\n",
    "\n",
    "    df_weekly['game_id_home_away'] = df_weekly['season'].astype(str) + '_' + df_weekly['week'].apply(lambda x: f\"{x:02d}\")+'_'+df_weekly['recent_team']+'_'+df_weekly['opponent_team']\n",
    "    df_weekly['game_id_away_home'] = df_weekly['season'].astype(str) + '_' + df_weekly['week'].apply(lambda x: f\"{x:02d}\")+'_'+df_weekly['opponent_team']+'_'+df_weekly['recent_team']\n",
    "\n",
    "    df_merged = pd.melt(\n",
    "        df_weekly,\n",
    "        id_vars=['player_id', 'position', 'season', 'week', 'recent_team', 'opponent_team', 'completions', 'attempts', 'passing_yards', 'passing_tds', 'passing_2pt_conversions', 'interceptions', 'sack_fumbles_lost', 'sacks', 'passing_epa', 'pacr', 'carries', 'rushing_yards', 'rushing_tds', 'rushing_2pt_conversions', 'rushing_fumbles_lost', 'rushing_epa', 'receptions', 'targets', 'receiving_yards', 'receiving_tds', 'receiving_2pt_conversions', 'receiving_fumbles_lost', 'racr', 'wopr', 'receiving_epa', 'fantasy_points'],\n",
    "        value_vars=['game_id_home_away', 'game_id_away_home'],\n",
    "        var_name='game_id_type',\n",
    "        value_name='game_id'\n",
    "    )\n",
    "\n",
    "    df_ids = df_ids.rename(columns={'gsis_id': 'player_id', 'pfr_id': 'pfr_player_id'})\n",
    "    df_pass_ngs = df_pass_ngs.rename(columns={'player_gsis_id': 'player_id'})\n",
    "    df_rush_ngs = df_rush_ngs.rename(columns={'player_gsis_id': 'player_id'})\n",
    "\n",
    "    df_merged = pd.merge(df_merged, df_schedule, on='game_id', how='inner') # Bei ein paar Spielen: recent_team = opponent_team\n",
    "    df_merged = pd.merge(df_merged, df_ids[['player_id', 'pfr_player_id', 'draft_pick', 'draft_year']], on = 'player_id', how = 'inner') # Ein paar Spieler ohne draft_year\n",
    "    df_merged = pd.merge(df_merged, df_seasonal[['player_id', 'season', 'dom']], on = ['player_id', 'season'], how = 'left')\n",
    "    df_merged = pd.merge(df_merged, df_pass_pfr[['pfr_player_id', 'season', 'week', 'passing_bad_throws', 'times_pressured']], on = ['pfr_player_id', 'season', 'week'], how = 'left')\n",
    "    df_merged = pd.merge(df_merged, df_rec_pfr[['pfr_player_id', 'season', 'week', 'receiving_rat']], on = ['pfr_player_id', 'season', 'week'], how = 'left')\n",
    "    df_merged = pd.merge(df_merged, df_rush_pfr[['pfr_player_id', 'season', 'week', 'rushing_broken_tackles']], on = ['pfr_player_id', 'season', 'week'], how = 'left')\n",
    "    df_merged = pd.merge(df_merged, df_pass_ngs[['player_id', 'season', 'week', 'passer_rating', 'aggressiveness']], on = ['player_id', 'season', 'week'], how = 'left')\n",
    "    df_merged = pd.merge(df_merged, df_rush_ngs[['player_id', 'season', 'week', 'efficiency']], on = ['player_id', 'season', 'week'], how = 'left')\n",
    "    df_merged = pd.merge(df_merged, df_snap_counts[['pfr_player_id', 'season', 'week', 'offense_snaps']], on = ['pfr_player_id', 'season', 'week'], how = 'left')\n",
    "\n",
    "    df_merged = df_merged.drop(columns=['game_id_type', 'pfr_player_id'])\n",
    "\n",
    "    df_merged['draft_pick'] = df_merged['draft_pick'].fillna(260)\n",
    "    df_merged = df_merged.fillna(0)\n",
    "\n",
    "    df_merged['rookie_flag'] = (df_merged['season'] == df_merged['draft_year']).astype(int)\n",
    "    df_merged['last_season_data_flag'] = (df_merged['week'] < 6).astype(int)\n",
    "    df_merged['home'] = (df_merged['home_team'] == df_merged['recent_team']).astype(int)\n",
    "    df_merged['player_id'] = df_merged['player_id'].str.replace('00-00', '').astype(int)\n",
    "\n",
    "    # interceptions und fumbles als eigene features statt als turnover aggregiert\n",
    "    df_merged['turnover'] = (\n",
    "        df_merged['interceptions'] +\n",
    "        df_merged['sack_fumbles_lost'] +\n",
    "        df_merged['rushing_fumbles_lost'] +\n",
    "        df_merged['receiving_fumbles_lost']\n",
    "    )\n",
    "\n",
    "    # total epa aggregiert statt passing, rushing und receiving einzeln\n",
    "    df_merged['epa_total'] = (\n",
    "        df_merged['passing_epa'] + \n",
    "        df_merged['rushing_epa'] + \n",
    "        df_merged['receiving_epa']\n",
    "    )\n",
    "\n",
    "    # total points aggregiert statt passing, rushing und receiving tds und 2pt conversions einzeln\n",
    "    df_merged['points_total'] = (\n",
    "        (df_merged['rushing_tds'] * 6) + \n",
    "        (df_merged['rushing_2pt_conversions'] * 2) + \n",
    "        (df_merged['receiving_tds'] * 6) + \n",
    "        (df_merged['receiving_2pt_conversions'] * 2) + \n",
    "        (df_merged['passing_tds'] * 6) + \n",
    "        (df_merged['passing_2pt_conversions'] * 2)\n",
    "    )\n",
    "\n",
    "    # total yards aggregiert statt passing, rushing und receiving einzeln\n",
    "    df_merged['yards_total'] = (\n",
    "        df_merged['passing_yards'] +\n",
    "        df_merged['rushing_yards'] +\n",
    "        df_merged['receiving_yards']\n",
    "    )\n",
    "\n",
    "    # total acr (air conversion ratio) aggregiert statt passing, rushing und receiving einzeln\n",
    "    df_merged['acr_total'] = (df_merged['racr'] + df_merged['pacr'])\n",
    "\n",
    "    # total player_rating aggregiert statt passing, rushing und receiving einzeln\n",
    "    df_merged['player_rating_total'] = (df_merged['passer_rating'] + df_merged['receiving_rat'])\n",
    "\n",
    "    # position target-encoded\n",
    "    position_means = df_merged.groupby(['position', 'season', 'week'])['fantasy_points'].mean().reset_index()\n",
    "    position_means.rename(columns={'fantasy_points': 'position_encoded'}, inplace=True)\n",
    "    df_merged = pd.merge(df_merged, position_means, on=['position', 'season', 'week'], how='left')\n",
    "\n",
    "    # points_scored und points_allowed als Ma√üstab f√ºr St√§rke eines Teams\n",
    "    df_merged['recent_team_points_scored'] = df_merged.apply(lambda row: row['home_score'] if row['home'] == 1 else row['away_score'], axis=1)\n",
    "    df_merged['opponent_team_points_allowed'] = df_merged['recent_team_points_scored']\n",
    "\n",
    "    df_unique_opponent_team_points_allowed = df_merged.drop_duplicates(subset=['game_id', 'opponent_team', 'opponent_team_points_allowed'])\n",
    "    df_unique_recent_team_points_scored = df_merged.drop_duplicates(subset=['game_id', 'recent_team', 'recent_team_points_scored'])\n",
    "\n",
    "    df_unique_opponent_team_points_allowed = df_unique_opponent_team_points_allowed.sort_values(by=['opponent_team', 'season', 'week']).reset_index(drop=True)\n",
    "    df_unique_recent_team_points_scored = df_unique_recent_team_points_scored.sort_values(by=['recent_team', 'season', 'week']).reset_index(drop=True)\n",
    "\n",
    "    df_unique_opponent_team_points_allowed['ewm_opponent_team_points_allowed_l5w'] = (\n",
    "        df_unique_opponent_team_points_allowed.groupby('opponent_team')['opponent_team_points_allowed']\n",
    "        .apply(lambda x: x.shift(1).ewm(span=5, min_periods=5).mean())\n",
    "        .reset_index(level=0, drop=True)\n",
    "    )\n",
    "\n",
    "    for metric in ['mean', 'median', 'std']:\n",
    "            df_unique_opponent_team_points_allowed[f\"{metric}_opponent_team_points_allowed_l5w\"] = (\n",
    "                df_unique_opponent_team_points_allowed.groupby('opponent_team')['opponent_team_points_allowed']\n",
    "                .apply(lambda x: x.shift(1).rolling(window=5, min_periods=5).agg(metric))  # shift(1) schlie√üt aktuelle Woche aus\n",
    "                .reset_index(level=0, drop=True)  # Index zur√ºcksetzen\n",
    "        )\n",
    "\n",
    "    for metric in ['min', 'max']:\n",
    "            df_unique_opponent_team_points_allowed[f\"{metric}_opponent_team_points_allowed_l3w\"] = (\n",
    "                df_unique_opponent_team_points_allowed.groupby('opponent_team')['opponent_team_points_allowed']\n",
    "                .apply(lambda x: x.shift(1).rolling(window=3, min_periods=3).agg(metric))  # shift(1) schlie√üt aktuelle Woche aus\n",
    "                .reset_index(level=0, drop=True)  # Index zur√ºcksetzen\n",
    "        )\n",
    "\n",
    "    df_unique_opponent_team_points_allowed = df_unique_opponent_team_points_allowed.drop(columns=['player_id', 'player_rating_total', 'acr_total', 'draft_year', 'turnover', 'interceptions', 'sack_fumbles_lost', 'rushing_fumbles_lost', 'receiving_fumbles_lost', 'points_total', 'rushing_tds', 'rushing_2pt_conversions', 'receiving_tds', 'receiving_2pt_conversions', 'passing_tds', 'passing_2pt_conversions', 'epa_total', 'passing_epa', 'rushing_epa', 'receiving_epa', 'position', 'season', 'week', 'recent_team', 'home_team', 'completions', 'attempts', 'passing_yards', 'sacks', 'pacr', 'carries', 'rushing_yards', 'receptions', 'targets', 'yards_total', 'receiving_yards', 'racr', 'wopr', 'fantasy_points', 'home_score', 'away_score', 'draft_pick', 'dom', 'passing_bad_throws', 'times_pressured', 'receiving_rat', 'rushing_broken_tackles', 'passer_rating', 'aggressiveness', 'efficiency', 'offense_snaps', 'rookie_flag', 'last_season_data_flag', 'home', 'position_encoded', 'recent_team_points_scored', 'opponent_team_points_allowed'])\n",
    "    df_merged = pd.merge(df_merged, df_unique_opponent_team_points_allowed, on=['game_id','opponent_team'], how='inner')\n",
    "\n",
    "    df_unique_recent_team_points_scored['ewm_recent_team_points_scored_l5w'] = (\n",
    "        df_unique_recent_team_points_scored.groupby('recent_team')['recent_team_points_scored']\n",
    "        .apply(lambda x: x.shift(1).ewm(span=5, min_periods=5).mean())\n",
    "        .reset_index(level=0, drop=True)\n",
    "    )\n",
    "\n",
    "    for metric in ['mean', 'median', 'std']:\n",
    "            df_unique_recent_team_points_scored[f\"{metric}_recent_team_points_scored_l5w\"] = (\n",
    "                df_unique_recent_team_points_scored.groupby('recent_team')['recent_team_points_scored']\n",
    "                .apply(lambda x: x.shift(1).rolling(window=5, min_periods=5).agg(metric))  # shift(1) schlie√üt aktuelle Woche aus\n",
    "                .reset_index(level=0, drop=True)  # Index zur√ºcksetzen\n",
    "        )\n",
    "\n",
    "    for metric in ['min', 'max']:\n",
    "            df_unique_recent_team_points_scored[f\"{metric}_recent_team_points_scored_l3w\"] = (\n",
    "                df_unique_recent_team_points_scored.groupby('recent_team')['recent_team_points_scored']\n",
    "                .apply(lambda x: x.shift(1).rolling(window=3, min_periods=3).agg(metric))  # shift(1) schlie√üt aktuelle Woche aus\n",
    "                .reset_index(level=0, drop=True)  # Index zur√ºcksetzen\n",
    "        )\n",
    "\n",
    "    df_unique_recent_team_points_scored = df_unique_recent_team_points_scored.drop(columns=['player_id', 'player_rating_total', 'acr_total', 'draft_year', 'turnover', 'interceptions', 'sack_fumbles_lost', 'rushing_fumbles_lost', 'receiving_fumbles_lost', 'points_total', 'rushing_tds', 'rushing_2pt_conversions', 'receiving_tds', 'receiving_2pt_conversions', 'passing_tds', 'passing_2pt_conversions', 'epa_total', 'passing_epa', 'rushing_epa', 'receiving_epa', 'position', 'season', 'week', 'opponent_team', 'home_team', 'completions', 'attempts', 'yards_total', 'passing_yards', 'sacks', 'pacr', 'carries', 'rushing_yards', 'receptions', 'targets', 'receiving_yards', 'racr', 'wopr', 'fantasy_points', 'home_score', 'away_score', 'draft_pick', 'dom', 'passing_bad_throws', 'times_pressured', 'receiving_rat', 'rushing_broken_tackles', 'passer_rating', 'aggressiveness', 'efficiency', 'offense_snaps', 'rookie_flag', 'last_season_data_flag', 'home', 'position_encoded', 'recent_team_points_scored', 'opponent_team_points_allowed'])\n",
    "    df_merged = pd.merge(df_merged, df_unique_recent_team_points_scored, on=['game_id','recent_team'], how='inner')\n",
    "\n",
    "    # Liste der Spalten mit Spielerspezifischen numerischen Daten, f√ºr die Rolling-Features erstellt werden sollen\n",
    "    columns_to_roll = ['completions', 'attempts', 'sacks', 'player_rating_total', 'aggressiveness', 'efficiency', \n",
    "                        'carries', 'offense_snaps', 'yards_total', 'receptions', 'targets', 'acr_total',\n",
    "                        'wopr', 'fantasy_points', 'passing_bad_throws', 'times_pressured', 'position_encoded', \n",
    "                        'rushing_broken_tackles', 'turnover', 'points_total', 'epa_total']\n",
    "\n",
    "\n",
    "    # Sortiere nach player_id, season und week\n",
    "    df_merged = df_merged.sort_values(by=['player_id', 'season', 'week']).reset_index(drop=True)\n",
    "\n",
    "\n",
    "    df_merged['cnt_games_over_20ffpts_l5w'] = (\n",
    "        df_merged.groupby('player_id')['fantasy_points']\n",
    "        .apply(lambda x: x.shift(1).rolling(window=5, min_periods=5).apply(lambda y: (y > 20).sum()))\n",
    "        .reset_index(level=0, drop=True)\n",
    "    )\n",
    "\n",
    "    # Rolling-Features erstellen\n",
    "    for col in columns_to_roll:\n",
    "\n",
    "        feature_name_1 = f\"ewm_{col}_l5w\"\n",
    "        df_merged[feature_name_1] = (\n",
    "            df_merged.groupby('player_id')[col]\n",
    "            .apply(lambda x: x.shift(1).ewm(span=5, min_periods=5).mean())\n",
    "            .reset_index(level=0, drop=True)\n",
    "        )\n",
    "\n",
    "        for metric in ['mean', 'median', 'std']:\n",
    "            feature_name_2 = f\"{metric}_{col}_l5w\"\n",
    "            rolling_result_5w = (\n",
    "                df_merged.groupby('player_id')[col]\n",
    "                    .apply(lambda x: x.shift(1).rolling(window=5, min_periods=5).agg(metric))  # shift(1) schlie√üt aktuelle Woche aus\n",
    "                    .reset_index(level=0, drop=True)  # Index zur√ºcksetzen\n",
    "            )\n",
    "            # Einf√ºgen der Rolling-Metrik\n",
    "            df_merged[feature_name_2] = rolling_result_5w\n",
    "\n",
    "        for metric in ['max', 'min']:\n",
    "            feature_name_3 = f\"{metric}_{col}_l3w\"\n",
    "            # Berechnung der Rolling-Metrik (ohne aktuelle Woche)\n",
    "            rolling_result_3w = (\n",
    "                df_merged.groupby('player_id')[col]\n",
    "                    .apply(lambda x: x.shift(1).rolling(window=3, min_periods=3).agg(metric))  # shift(1) schlie√üt aktuelle Woche aus\n",
    "                    .reset_index(level=0, drop=True)  # Index zur√ºcksetzen\n",
    "            )\n",
    "            # Einf√ºgen der Rolling-Metrik\n",
    "            df_merged[feature_name_3] = rolling_result_3w\n",
    "\n",
    "    df_merged = df_merged.drop(columns=['completions', 'attempts', 'passing_yards', 'sacks', 'pacr', 'carries', 'acr_total', 'player_rating_total',\n",
    "                                        'rushing_yards', 'receptions', 'targets', 'receiving_yards', 'racr', 'wopr', 'passing_bad_throws', \n",
    "                                        'times_pressured', 'receiving_rat', 'rushing_broken_tackles', 'draft_year', 'home_team', \n",
    "                                        'passer_rating', 'aggressiveness', 'efficiency', 'offense_snaps', 'game_id',  'interceptions', 'sack_fumbles_lost', \n",
    "                                        'rushing_fumbles_lost', 'receiving_fumbles_lost', 'rushing_tds', 'rushing_2pt_conversions', 'receiving_tds', \n",
    "                                        'receiving_2pt_conversions', 'passing_tds', 'passing_2pt_conversions', 'passing_epa', 'rushing_epa', 'receiving_epa',\n",
    "                                        'position_encoded', 'recent_team', 'opponent_team', 'position', 'home_score', 'away_score',\n",
    "                                        'recent_team_points_scored', 'opponent_team_points_allowed', 'turnover', 'points_total', 'yards_total',\n",
    "                                        'epa_total'])\n",
    "\n",
    "    df_merged = df_merged.dropna().reset_index()\n",
    "\n",
    "    return df_merged\n",
    "\n",
    "df_5 = load_merge_edit_data_5()\n",
    "\n",
    "df_5.info()\n",
    "print(df_5.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downcasting floats.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/sn/54gnf37x14l2fsfqr_hj0dnc0000gn/T/ipykernel_6060/3473606820.py:204: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_merged[feature_name_3] = rolling_result_3w\n",
      "/var/folders/sn/54gnf37x14l2fsfqr_hj0dnc0000gn/T/ipykernel_6060/3473606820.py:204: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_merged[feature_name_3] = rolling_result_3w\n",
      "/var/folders/sn/54gnf37x14l2fsfqr_hj0dnc0000gn/T/ipykernel_6060/3473606820.py:179: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_merged[feature_name_1] = (\n",
      "/var/folders/sn/54gnf37x14l2fsfqr_hj0dnc0000gn/T/ipykernel_6060/3473606820.py:193: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_merged[feature_name_2] = rolling_result_5w\n",
      "/var/folders/sn/54gnf37x14l2fsfqr_hj0dnc0000gn/T/ipykernel_6060/3473606820.py:193: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_merged[feature_name_2] = rolling_result_5w\n",
      "/var/folders/sn/54gnf37x14l2fsfqr_hj0dnc0000gn/T/ipykernel_6060/3473606820.py:193: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_merged[feature_name_2] = rolling_result_5w\n",
      "/var/folders/sn/54gnf37x14l2fsfqr_hj0dnc0000gn/T/ipykernel_6060/3473606820.py:204: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_merged[feature_name_3] = rolling_result_3w\n",
      "/var/folders/sn/54gnf37x14l2fsfqr_hj0dnc0000gn/T/ipykernel_6060/3473606820.py:204: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_merged[feature_name_3] = rolling_result_3w\n",
      "/var/folders/sn/54gnf37x14l2fsfqr_hj0dnc0000gn/T/ipykernel_6060/3473606820.py:179: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_merged[feature_name_1] = (\n",
      "/var/folders/sn/54gnf37x14l2fsfqr_hj0dnc0000gn/T/ipykernel_6060/3473606820.py:193: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_merged[feature_name_2] = rolling_result_5w\n",
      "/var/folders/sn/54gnf37x14l2fsfqr_hj0dnc0000gn/T/ipykernel_6060/3473606820.py:193: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_merged[feature_name_2] = rolling_result_5w\n",
      "/var/folders/sn/54gnf37x14l2fsfqr_hj0dnc0000gn/T/ipykernel_6060/3473606820.py:193: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_merged[feature_name_2] = rolling_result_5w\n",
      "/var/folders/sn/54gnf37x14l2fsfqr_hj0dnc0000gn/T/ipykernel_6060/3473606820.py:204: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_merged[feature_name_3] = rolling_result_3w\n",
      "/var/folders/sn/54gnf37x14l2fsfqr_hj0dnc0000gn/T/ipykernel_6060/3473606820.py:204: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_merged[feature_name_3] = rolling_result_3w\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 30183 entries, 0 to 30182\n",
      "Columns: 131 entries, index to min_epa_total_l3w\n",
      "dtypes: float32(1), float64(123), int32(2), int64(5)\n",
      "memory usage: 29.8 MB\n",
      "index                                      0\n",
      "player_id                                  0\n",
      "season                                     0\n",
      "week                                       0\n",
      "fantasy_points                             0\n",
      "draft_pick                                 0\n",
      "dom                                        0\n",
      "rookie_flag                                0\n",
      "last_season_data_flag                      0\n",
      "home                                       0\n",
      "ewm_opponent_team_points_allowed_l5w       0\n",
      "mean_opponent_team_points_allowed_l5w      0\n",
      "median_opponent_team_points_allowed_l5w    0\n",
      "std_opponent_team_points_allowed_l5w       0\n",
      "min_opponent_team_points_allowed_l3w       0\n",
      "max_opponent_team_points_allowed_l3w       0\n",
      "ewm_recent_team_points_scored_l5w          0\n",
      "mean_recent_team_points_scored_l5w         0\n",
      "median_recent_team_points_scored_l5w       0\n",
      "std_recent_team_points_scored_l5w          0\n",
      "min_recent_team_points_scored_l3w          0\n",
      "max_recent_team_points_scored_l3w          0\n",
      "cnt_games_over_20ffpts_l5w                 0\n",
      "ewm_completions_l5w                        0\n",
      "mean_completions_l5w                       0\n",
      "median_completions_l5w                     0\n",
      "std_completions_l5w                        0\n",
      "max_completions_l3w                        0\n",
      "min_completions_l3w                        0\n",
      "ewm_attempts_l5w                           0\n",
      "mean_attempts_l5w                          0\n",
      "median_attempts_l5w                        0\n",
      "std_attempts_l5w                           0\n",
      "max_attempts_l3w                           0\n",
      "min_attempts_l3w                           0\n",
      "ewm_sacks_l5w                              0\n",
      "mean_sacks_l5w                             0\n",
      "median_sacks_l5w                           0\n",
      "std_sacks_l5w                              0\n",
      "max_sacks_l3w                              0\n",
      "min_sacks_l3w                              0\n",
      "ewm_player_rating_total_l5w                0\n",
      "mean_player_rating_total_l5w               0\n",
      "median_player_rating_total_l5w             0\n",
      "std_player_rating_total_l5w                0\n",
      "max_player_rating_total_l3w                0\n",
      "min_player_rating_total_l3w                0\n",
      "ewm_efficiency_l5w                         0\n",
      "mean_efficiency_l5w                        0\n",
      "median_efficiency_l5w                      0\n",
      "std_efficiency_l5w                         0\n",
      "max_efficiency_l3w                         0\n",
      "min_efficiency_l3w                         0\n",
      "ewm_carries_l5w                            0\n",
      "mean_carries_l5w                           0\n",
      "median_carries_l5w                         0\n",
      "std_carries_l5w                            0\n",
      "max_carries_l3w                            0\n",
      "min_carries_l3w                            0\n",
      "ewm_offense_snaps_l5w                      0\n",
      "mean_offense_snaps_l5w                     0\n",
      "median_offense_snaps_l5w                   0\n",
      "std_offense_snaps_l5w                      0\n",
      "max_offense_snaps_l3w                      0\n",
      "min_offense_snaps_l3w                      0\n",
      "ewm_yards_total_l5w                        0\n",
      "mean_yards_total_l5w                       0\n",
      "median_yards_total_l5w                     0\n",
      "std_yards_total_l5w                        0\n",
      "max_yards_total_l3w                        0\n",
      "min_yards_total_l3w                        0\n",
      "ewm_receptions_l5w                         0\n",
      "mean_receptions_l5w                        0\n",
      "median_receptions_l5w                      0\n",
      "std_receptions_l5w                         0\n",
      "max_receptions_l3w                         0\n",
      "min_receptions_l3w                         0\n",
      "ewm_targets_l5w                            0\n",
      "mean_targets_l5w                           0\n",
      "median_targets_l5w                         0\n",
      "std_targets_l5w                            0\n",
      "max_targets_l3w                            0\n",
      "min_targets_l3w                            0\n",
      "ewm_acr_total_l5w                          0\n",
      "mean_acr_total_l5w                         0\n",
      "median_acr_total_l5w                       0\n",
      "std_acr_total_l5w                          0\n",
      "max_acr_total_l3w                          0\n",
      "min_acr_total_l3w                          0\n",
      "ewm_wopr_l5w                               0\n",
      "mean_wopr_l5w                              0\n",
      "median_wopr_l5w                            0\n",
      "std_wopr_l5w                               0\n",
      "max_wopr_l3w                               0\n",
      "min_wopr_l3w                               0\n",
      "ewm_fantasy_points_l5w                     0\n",
      "mean_fantasy_points_l5w                    0\n",
      "median_fantasy_points_l5w                  0\n",
      "std_fantasy_points_l5w                     0\n",
      "max_fantasy_points_l3w                     0\n",
      "min_fantasy_points_l3w                     0\n",
      "ewm_passing_bad_throws_l5w                 0\n",
      "mean_passing_bad_throws_l5w                0\n",
      "median_passing_bad_throws_l5w              0\n",
      "std_passing_bad_throws_l5w                 0\n",
      "max_passing_bad_throws_l3w                 0\n",
      "min_passing_bad_throws_l3w                 0\n",
      "ewm_position_encoded_l5w                   0\n",
      "mean_position_encoded_l5w                  0\n",
      "median_position_encoded_l5w                0\n",
      "std_position_encoded_l5w                   0\n",
      "max_position_encoded_l3w                   0\n",
      "min_position_encoded_l3w                   0\n",
      "ewm_turnover_l5w                           0\n",
      "mean_turnover_l5w                          0\n",
      "median_turnover_l5w                        0\n",
      "std_turnover_l5w                           0\n",
      "max_turnover_l3w                           0\n",
      "min_turnover_l3w                           0\n",
      "ewm_points_total_l5w                       0\n",
      "mean_points_total_l5w                      0\n",
      "median_points_total_l5w                    0\n",
      "std_points_total_l5w                       0\n",
      "max_points_total_l3w                       0\n",
      "min_points_total_l3w                       0\n",
      "ewm_epa_total_l5w                          0\n",
      "mean_epa_total_l5w                         0\n",
      "median_epa_total_l5w                       0\n",
      "std_epa_total_l5w                          0\n",
      "max_epa_total_l3w                          0\n",
      "min_epa_total_l3w                          0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Positionsspezifische Stats zusammengefasst (passing, rushing und receiving zu total_features zusammengefasst)\n",
    "# passing_air_yards, sack_yards, rushing_broken_tackles, times_pressured und aggressiveness entfernt; Noch mehr stats zusammengefasst\n",
    "# Alle Metriken (ewm, mean, median, min, max, std)\n",
    "\n",
    "def load_merge_edit_data_6():  \n",
    "\n",
    "    df_ids = nfl.import_ids()\n",
    "    df_weekly = nfl.import_weekly_data(list(range(2018, 2025)))\n",
    "    df_seasonal = nfl.import_seasonal_data(list(range(2017,2024)))\n",
    "    df_schedule = nfl.import_schedules(list(range(2018, 2025)))\n",
    "    df_pass_pfr = nfl.import_weekly_pfr('pass', list(range(2018, 2025)))\n",
    "    df_rec_pfr = nfl.import_weekly_pfr('rec', list(range(2018, 2025)))\n",
    "    df_pass_ngs = nfl.import_ngs_data('passing',list(range(2018, 2025)))\n",
    "    df_rush_ngs = nfl.import_ngs_data('rushing',list(range(2018, 2025)))\n",
    "    df_snap_counts = nfl.import_snap_counts(list(range(2018, 2025)))\n",
    "\n",
    "    df_weekly = df_weekly[(df_weekly['season_type'] == 'REG') & (df_weekly['position'].isin(['QB', 'WR', 'RB', 'TE']))].reset_index()\n",
    "\n",
    "    df_seasonal['season'] = df_seasonal['season'] + 1\n",
    "\n",
    "    df_schedule = df_schedule[['game_id', 'home_team', 'home_score', 'away_score']].drop_duplicates()\n",
    "    df_schedule['game_id'] = df_schedule['game_id'].str.replace('OAK', 'LV', regex=False) # Umzug der Oakland Raiders nach Las Vegas in der Saison 2020\n",
    "    df_schedule['home_team'] = df_schedule['home_team'].str.replace('OAK', 'LV', regex=False) # Umzug der Oakland Raiders nach Las Vegas in der Saison 2020\n",
    "\n",
    "    df_weekly['game_id_home_away'] = df_weekly['season'].astype(str) + '_' + df_weekly['week'].apply(lambda x: f\"{x:02d}\")+'_'+df_weekly['recent_team']+'_'+df_weekly['opponent_team']\n",
    "    df_weekly['game_id_away_home'] = df_weekly['season'].astype(str) + '_' + df_weekly['week'].apply(lambda x: f\"{x:02d}\")+'_'+df_weekly['opponent_team']+'_'+df_weekly['recent_team']\n",
    "\n",
    "    df_merged = pd.melt(\n",
    "        df_weekly,\n",
    "        id_vars=['player_id', 'position', 'season', 'week', 'recent_team', 'opponent_team', 'completions', 'attempts', 'passing_yards', 'passing_tds', 'passing_2pt_conversions', 'interceptions', 'sack_fumbles_lost', 'sacks', 'passing_epa', 'pacr', 'carries', 'rushing_yards', 'rushing_tds', 'rushing_2pt_conversions', 'rushing_fumbles_lost', 'rushing_epa', 'receptions', 'targets', 'receiving_yards', 'receiving_tds', 'receiving_2pt_conversions', 'receiving_fumbles_lost', 'racr', 'wopr', 'receiving_epa', 'fantasy_points'],\n",
    "        value_vars=['game_id_home_away', 'game_id_away_home'],\n",
    "        var_name='game_id_type',\n",
    "        value_name='game_id'\n",
    "    )\n",
    "\n",
    "    df_ids = df_ids.rename(columns={'gsis_id': 'player_id', 'pfr_id': 'pfr_player_id'})\n",
    "    df_pass_ngs = df_pass_ngs.rename(columns={'player_gsis_id': 'player_id'})\n",
    "    df_rush_ngs = df_rush_ngs.rename(columns={'player_gsis_id': 'player_id'})\n",
    "\n",
    "    df_merged = pd.merge(df_merged, df_schedule, on='game_id', how='inner') # Bei ein paar Spielen: recent_team = opponent_team\n",
    "    df_merged = pd.merge(df_merged, df_ids[['player_id', 'pfr_player_id', 'draft_pick', 'draft_year']], on = 'player_id', how = 'inner') # Ein paar Spieler ohne draft_year\n",
    "    df_merged = pd.merge(df_merged, df_seasonal[['player_id', 'season', 'dom']], on = ['player_id', 'season'], how = 'left')\n",
    "    df_merged = pd.merge(df_merged, df_pass_pfr[['pfr_player_id', 'season', 'week', 'passing_bad_throws']], on = ['pfr_player_id', 'season', 'week'], how = 'left')\n",
    "    df_merged = pd.merge(df_merged, df_rec_pfr[['pfr_player_id', 'season', 'week', 'receiving_rat']], on = ['pfr_player_id', 'season', 'week'], how = 'left')\n",
    "    df_merged = pd.merge(df_merged, df_pass_ngs[['player_id', 'season', 'week', 'passer_rating']], on = ['player_id', 'season', 'week'], how = 'left')\n",
    "    df_merged = pd.merge(df_merged, df_rush_ngs[['player_id', 'season', 'week', 'efficiency']], on = ['player_id', 'season', 'week'], how = 'left')\n",
    "    df_merged = pd.merge(df_merged, df_snap_counts[['pfr_player_id', 'season', 'week', 'offense_snaps']], on = ['pfr_player_id', 'season', 'week'], how = 'left')\n",
    "\n",
    "    df_merged = df_merged.drop(columns=['game_id_type', 'pfr_player_id'])\n",
    "\n",
    "    df_merged['draft_pick'] = df_merged['draft_pick'].fillna(260)\n",
    "    df_merged = df_merged.fillna(0)\n",
    "\n",
    "    df_merged['rookie_flag'] = (df_merged['season'] == df_merged['draft_year']).astype(int)\n",
    "    df_merged['last_season_data_flag'] = (df_merged['week'] < 6).astype(int)\n",
    "    df_merged['home'] = (df_merged['home_team'] == df_merged['recent_team']).astype(int)\n",
    "    df_merged['player_id'] = df_merged['player_id'].str.replace('00-00', '').astype(int)\n",
    "\n",
    "    # interceptions und fumbles als eigene features statt als turnover aggregiert\n",
    "    df_merged['turnover'] = (\n",
    "        df_merged['interceptions'] +\n",
    "        df_merged['sack_fumbles_lost'] +\n",
    "        df_merged['rushing_fumbles_lost'] +\n",
    "        df_merged['receiving_fumbles_lost']\n",
    "    )\n",
    "\n",
    "    # total epa aggregiert statt passing, rushing und receiving einzeln\n",
    "    df_merged['epa_total'] = (\n",
    "        df_merged['passing_epa'] + \n",
    "        df_merged['rushing_epa'] + \n",
    "        df_merged['receiving_epa']\n",
    "    )\n",
    "\n",
    "    # total points aggregiert statt passing, rushing und receiving tds und 2pt conversions einzeln\n",
    "    df_merged['points_total'] = (\n",
    "        (df_merged['rushing_tds'] * 6) + \n",
    "        (df_merged['rushing_2pt_conversions'] * 2) + \n",
    "        (df_merged['receiving_tds'] * 6) + \n",
    "        (df_merged['receiving_2pt_conversions'] * 2) + \n",
    "        (df_merged['passing_tds'] * 6) + \n",
    "        (df_merged['passing_2pt_conversions'] * 2)\n",
    "    )\n",
    "\n",
    "    # total yards aggregiert statt passing, rushing und receiving einzeln\n",
    "    df_merged['yards_total'] = (\n",
    "        df_merged['passing_yards'] +\n",
    "        df_merged['rushing_yards'] +\n",
    "        df_merged['receiving_yards']\n",
    "    )\n",
    "\n",
    "    # total acr (air conversion ratio) aggregiert statt passing, rushing und receiving einzeln\n",
    "    df_merged['acr_total'] = (df_merged['racr'] + df_merged['pacr'])\n",
    "\n",
    "    # total player_rating aggregiert statt passing, rushing und receiving einzeln\n",
    "    df_merged['player_rating_total'] = (df_merged['passer_rating'] + df_merged['receiving_rat'])\n",
    "\n",
    "    # position target-encoded\n",
    "    position_means = df_merged.groupby(['position', 'season', 'week'])['fantasy_points'].mean().reset_index()\n",
    "    position_means.rename(columns={'fantasy_points': 'position_encoded'}, inplace=True)\n",
    "    df_merged = pd.merge(df_merged, position_means, on=['position', 'season', 'week'], how='left')\n",
    "\n",
    "    # points_scored und points_allowed als Ma√üstab f√ºr St√§rke eines Teams\n",
    "    df_merged['recent_team_points_scored'] = df_merged.apply(lambda row: row['home_score'] if row['home'] == 1 else row['away_score'], axis=1)\n",
    "    df_merged['opponent_team_points_allowed'] = df_merged['recent_team_points_scored']\n",
    "\n",
    "    df_unique_opponent_team_points_allowed = df_merged.drop_duplicates(subset=['game_id', 'opponent_team', 'opponent_team_points_allowed'])\n",
    "    df_unique_recent_team_points_scored = df_merged.drop_duplicates(subset=['game_id', 'recent_team', 'recent_team_points_scored'])\n",
    "\n",
    "    df_unique_opponent_team_points_allowed = df_unique_opponent_team_points_allowed.sort_values(by=['opponent_team', 'season', 'week']).reset_index(drop=True)\n",
    "    df_unique_recent_team_points_scored = df_unique_recent_team_points_scored.sort_values(by=['recent_team', 'season', 'week']).reset_index(drop=True)\n",
    "\n",
    "    df_unique_opponent_team_points_allowed['ewm_opponent_team_points_allowed_l5w'] = (\n",
    "        df_unique_opponent_team_points_allowed.groupby('opponent_team')['opponent_team_points_allowed']\n",
    "        .apply(lambda x: x.shift(1).ewm(span=5, min_periods=5).mean())\n",
    "        .reset_index(level=0, drop=True)\n",
    "    )\n",
    "\n",
    "    for metric in ['mean', 'median', 'std']:\n",
    "            df_unique_opponent_team_points_allowed[f\"{metric}_opponent_team_points_allowed_l5w\"] = (\n",
    "                df_unique_opponent_team_points_allowed.groupby('opponent_team')['opponent_team_points_allowed']\n",
    "                .apply(lambda x: x.shift(1).rolling(window=5, min_periods=5).agg(metric))  # shift(1) schlie√üt aktuelle Woche aus\n",
    "                .reset_index(level=0, drop=True)  # Index zur√ºcksetzen\n",
    "        )\n",
    "\n",
    "    for metric in ['min', 'max']:\n",
    "            df_unique_opponent_team_points_allowed[f\"{metric}_opponent_team_points_allowed_l3w\"] = (\n",
    "                df_unique_opponent_team_points_allowed.groupby('opponent_team')['opponent_team_points_allowed']\n",
    "                .apply(lambda x: x.shift(1).rolling(window=3, min_periods=3).agg(metric))  # shift(1) schlie√üt aktuelle Woche aus\n",
    "                .reset_index(level=0, drop=True)  # Index zur√ºcksetzen\n",
    "        )\n",
    "\n",
    "    df_unique_opponent_team_points_allowed = df_unique_opponent_team_points_allowed.drop(columns=['player_id', 'player_rating_total', 'acr_total', 'draft_year', 'turnover', 'interceptions', 'sack_fumbles_lost', 'rushing_fumbles_lost', 'receiving_fumbles_lost', 'points_total', 'rushing_tds', 'rushing_2pt_conversions', 'receiving_tds', 'receiving_2pt_conversions', 'passing_tds', 'passing_2pt_conversions', 'epa_total', 'passing_epa', 'rushing_epa', 'receiving_epa', 'position', 'season', 'week', 'recent_team', 'home_team', 'completions', 'attempts', 'passing_yards', 'sacks', 'pacr', 'carries', 'rushing_yards', 'receptions', 'targets', 'yards_total', 'receiving_yards', 'racr', 'wopr', 'fantasy_points', 'home_score', 'away_score', 'draft_pick', 'dom', 'passing_bad_throws', 'receiving_rat', 'passer_rating', 'efficiency', 'offense_snaps', 'rookie_flag', 'last_season_data_flag', 'home', 'position_encoded', 'recent_team_points_scored', 'opponent_team_points_allowed'])\n",
    "    df_merged = pd.merge(df_merged, df_unique_opponent_team_points_allowed, on=['game_id','opponent_team'], how='inner')\n",
    "\n",
    "    df_unique_recent_team_points_scored['ewm_recent_team_points_scored_l5w'] = (\n",
    "        df_unique_recent_team_points_scored.groupby('recent_team')['recent_team_points_scored']\n",
    "        .apply(lambda x: x.shift(1).ewm(span=5, min_periods=5).mean())\n",
    "        .reset_index(level=0, drop=True)\n",
    "    )\n",
    "\n",
    "    for metric in ['mean', 'median', 'std']:\n",
    "            df_unique_recent_team_points_scored[f\"{metric}_recent_team_points_scored_l5w\"] = (\n",
    "                df_unique_recent_team_points_scored.groupby('recent_team')['recent_team_points_scored']\n",
    "                .apply(lambda x: x.shift(1).rolling(window=5, min_periods=5).agg(metric))  # shift(1) schlie√üt aktuelle Woche aus\n",
    "                .reset_index(level=0, drop=True)  # Index zur√ºcksetzen\n",
    "        )\n",
    "\n",
    "    for metric in ['min', 'max']:\n",
    "            df_unique_recent_team_points_scored[f\"{metric}_recent_team_points_scored_l3w\"] = (\n",
    "                df_unique_recent_team_points_scored.groupby('recent_team')['recent_team_points_scored']\n",
    "                .apply(lambda x: x.shift(1).rolling(window=3, min_periods=3).agg(metric))  # shift(1) schlie√üt aktuelle Woche aus\n",
    "                .reset_index(level=0, drop=True)  # Index zur√ºcksetzen\n",
    "        )\n",
    "\n",
    "    df_unique_recent_team_points_scored = df_unique_recent_team_points_scored.drop(columns=['player_id', 'player_rating_total', 'acr_total', 'draft_year', 'turnover', 'interceptions', 'sack_fumbles_lost', 'rushing_fumbles_lost', 'receiving_fumbles_lost', 'points_total', 'rushing_tds', 'rushing_2pt_conversions', 'receiving_tds', 'receiving_2pt_conversions', 'passing_tds', 'passing_2pt_conversions', 'epa_total', 'passing_epa', 'rushing_epa', 'receiving_epa', 'position', 'season', 'week', 'opponent_team', 'home_team', 'completions', 'attempts', 'yards_total', 'passing_yards', 'sacks', 'pacr', 'carries', 'rushing_yards', 'receptions', 'targets', 'receiving_yards', 'racr', 'wopr', 'fantasy_points', 'home_score', 'away_score', 'draft_pick', 'dom', 'passing_bad_throws', 'receiving_rat', 'passer_rating', 'efficiency', 'offense_snaps', 'rookie_flag', 'last_season_data_flag', 'home', 'position_encoded', 'recent_team_points_scored', 'opponent_team_points_allowed'])\n",
    "    df_merged = pd.merge(df_merged, df_unique_recent_team_points_scored, on=['game_id','recent_team'], how='inner')\n",
    "\n",
    "    # Liste der Spalten mit Spielerspezifischen numerischen Daten, f√ºr die Rolling-Features erstellt werden sollen\n",
    "    columns_to_roll = ['completions', 'attempts', 'sacks', 'player_rating_total', 'efficiency', \n",
    "                        'carries', 'offense_snaps', 'yards_total', 'receptions', 'targets', 'acr_total',\n",
    "                        'wopr', 'fantasy_points', 'passing_bad_throws', 'position_encoded', \n",
    "                        'turnover', 'points_total', 'epa_total']\n",
    "\n",
    "\n",
    "    # Sortiere nach player_id, season und week\n",
    "    df_merged = df_merged.sort_values(by=['player_id', 'season', 'week']).reset_index(drop=True)\n",
    "\n",
    "\n",
    "    df_merged['cnt_games_over_20ffpts_l5w'] = (\n",
    "        df_merged.groupby('player_id')['fantasy_points']\n",
    "        .apply(lambda x: x.shift(1).rolling(window=5, min_periods=5).apply(lambda y: (y > 20).sum()))\n",
    "        .reset_index(level=0, drop=True)\n",
    "    )\n",
    "\n",
    "    # Rolling-Features erstellen\n",
    "    for col in columns_to_roll:\n",
    "\n",
    "        feature_name_1 = f\"ewm_{col}_l5w\"\n",
    "        df_merged[feature_name_1] = (\n",
    "            df_merged.groupby('player_id')[col]\n",
    "            .apply(lambda x: x.shift(1).ewm(span=5, min_periods=5).mean())\n",
    "            .reset_index(level=0, drop=True)\n",
    "        )\n",
    "\n",
    "        for metric in ['mean', 'median', 'std']:\n",
    "            feature_name_2 = f\"{metric}_{col}_l5w\"\n",
    "            rolling_result_5w = (\n",
    "                df_merged.groupby('player_id')[col]\n",
    "                    .apply(lambda x: x.shift(1).rolling(window=5, min_periods=5).agg(metric))  # shift(1) schlie√üt aktuelle Woche aus\n",
    "                    .reset_index(level=0, drop=True)  # Index zur√ºcksetzen\n",
    "            )\n",
    "            # Einf√ºgen der Rolling-Metrik\n",
    "            df_merged[feature_name_2] = rolling_result_5w\n",
    "\n",
    "        for metric in ['max', 'min']:\n",
    "            feature_name_3 = f\"{metric}_{col}_l3w\"\n",
    "            # Berechnung der Rolling-Metrik (ohne aktuelle Woche)\n",
    "            rolling_result_3w = (\n",
    "                df_merged.groupby('player_id')[col]\n",
    "                    .apply(lambda x: x.shift(1).rolling(window=3, min_periods=3).agg(metric))  # shift(1) schlie√üt aktuelle Woche aus\n",
    "                    .reset_index(level=0, drop=True)  # Index zur√ºcksetzen\n",
    "            )\n",
    "            # Einf√ºgen der Rolling-Metrik\n",
    "            df_merged[feature_name_3] = rolling_result_3w\n",
    "\n",
    "    df_merged = df_merged.drop(columns=['completions', 'attempts', 'passing_yards', 'sacks', 'pacr', 'carries', 'acr_total', 'player_rating_total',\n",
    "                                        'rushing_yards', 'receptions', 'targets', 'receiving_yards', 'racr', 'wopr', 'passing_bad_throws', \n",
    "                                        'receiving_rat', 'draft_year', 'home_team', \n",
    "                                        'passer_rating', 'efficiency', 'offense_snaps', 'game_id',  'interceptions', 'sack_fumbles_lost', \n",
    "                                        'rushing_fumbles_lost', 'receiving_fumbles_lost', 'rushing_tds', 'rushing_2pt_conversions', 'receiving_tds', \n",
    "                                        'receiving_2pt_conversions', 'passing_tds', 'passing_2pt_conversions', 'passing_epa', 'rushing_epa', 'receiving_epa',\n",
    "                                        'position_encoded', 'recent_team', 'opponent_team', 'position', 'home_score', 'away_score',\n",
    "                                        'recent_team_points_scored', 'opponent_team_points_allowed', 'turnover', 'points_total', 'yards_total',\n",
    "                                        'epa_total'])\n",
    "\n",
    "    df_merged = df_merged.dropna().reset_index()\n",
    "\n",
    "    return df_merged\n",
    "\n",
    "df_6 = load_merge_edit_data_6()\n",
    "\n",
    "df_6.info()\n",
    "print(df_6.isnull().sum())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
